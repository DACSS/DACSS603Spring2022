[
  {
    "path": "posts/httpsrpubscomchester870152/",
    "title": "Homework One",
    "description": "DACSS 603",
    "author": [
      {
        "name": "Cynthia Hester",
        "url": {}
      }
    ],
    "date": "2022-02-24",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nQuestion 1\r\nSolution:\r\nAnalysis:\r\n\r\nQuestion 2\r\nSolution:\r\nResults\r\nConfidence interval interpretation\r\n\r\nQuestion 3\r\nSolution\r\n\r\nQuestion 4\r\nSolutions\r\n\r\nQuestion 5\r\nSolutions:\r\n\r\nQuestion 6\r\nSolution\r\n\r\n\r\nQuestion 1\r\nThe time between the date a patient was recommended for heart surgery and the surgery date for cardiac patients in Ontario was collected by the Cardiac Care Network (“Wait Times Data Guide,” Ministry of Health and Long-Term Care, Ontario, Canada, 2006). The sample mean and sample standard deviation for wait times (in days) of patients for two cardiac procedures are given in the accompanying table. Assume that the sample is representative of the Ontario population.\r\nConstruct the 90% confidence interval to estimate the actual mean wait time for each of the two procedures. Is the confidence interval narrower for angiography or bypass surgery?\r\nSolution:\r\nFirst we assign variable names to the sample summary statistics\r\n\r\n\r\n\r\nWe then calculate the t-confidence interval or t-score of each sample. To do this we start by calculating the degrees of freedom of each sample (bypass and angiography)\r\nCalculating degrees of freedom of the bypass and angiography samples\r\n\r\n\r\nbypass_df<-bypass_sample - 1  #bypass degrees of freedom\r\nangio_df<-angio_sample - 1    #angiography degrees of freedom\r\n\r\n\r\n\r\nNow that we have degrees of freedom we can calculate the t-critical values or t-score for the respective 90% intervals of each sample.\r\n\r\n\r\n# Calculating the t-critical value for the **angiography ** sample\r\n\r\nangio_sample<-847\r\nangio_df<-angio_sample - 1\r\nt_score_angio<-qt(p=0.05, df=angio_df,lower.tail=F)\r\nprint(t_score_angio)\r\n\r\n\r\n[1] 1.646657\r\n\r\n# Calculating the t-critical value for the **bypass** sample\r\n\r\nbypass_sample<-539\r\nbypass_df<-bypass_sample - 1\r\nt_score_bypass<-qt(p=0.05, df=bypass_df,lower.tail=F)\r\nprint(t_score_bypass)\r\n\r\n\r\n[1] 1.647691\r\n\r\n# We now find the margin of error for both samples\r\n\r\n\r\nmargin_angio<- qt(0.05,df=angio_df)*9/sqrt(847)    #margin of error angiography\r\nprint(margin_angio)\r\n\r\n\r\n[1] -0.5092182\r\n\r\nmargin_bypass<-qt(0.05,df=bypass_df)*10/sqrt(539)   #margin of error bypass\r\nprint(margin_bypass)\r\n\r\n\r\n[1] -0.7097107\r\n\r\n# To calculate the lower bound  and upper bound of the angiography sample\r\n\r\nlower_bound_angio<-angio_mean-margin_angio\r\nprint(lower_bound_angio)\r\n\r\n\r\n[1] 18.50922\r\n\r\nupper_bound_angio<-angio_mean+margin_angio\r\nprint(upper_bound_angio)\r\n\r\n\r\n[1] 17.49078\r\n\r\n # To calculate the lower bound and upper bound of the bypass sample\r\n\r\nlower_bound_bypass<-bypass_mean-margin_bypass\r\nprint(lower_bound_bypass)\r\n\r\n\r\n[1] 19.70971\r\n\r\nupper_bound_bypass<-bypass_mean+margin_bypass\r\nprint(upper_bound_bypass)\r\n\r\n\r\n[1] 18.29029\r\n\r\nTo determine which confidence interval is narrower I subtract the upper bound from the lower bound of each respective procedure.\r\nAngiography : [17.49,18.51] 18.51-17.49 = 1.02 \r\nBypass : [18.29,19.71] 19.71-18.29 = 1.42 \r\nThe angiography 90% confidence interval is narrower at 1.02 compared to the bypass of 1.42\r\nAnalysis:\r\nWe see the mean wait time of the 90% confidence interval is from 17.49 to 18.51 days for the angiography procedure. Whereas the mean wait time of the 90% confidence interval is from 18.29 to 19.71 for the bypass procedure. This results in a narrower wait time of 1.02 days for the angiography compared to the bypass of 1.42 days. This could be attributed to the larger sample size for the angiography of 847 compared to a sample of 539 for the bypass. As well as a smaller standard deviation of 9 for the angiography compared to a standard deviation of 10 for the bypass.\r\nQuestion 2\r\nA survey of 1031 adult Americans was carried out by the National Center for Public Policy. Assume that the sample is representative of adult Americans. Among those surveyed, 567 believed that college education is essential for success.\r\nFind the point estimate, p, of the proportion of all adult Americans who believe that a college education is essential for success.\r\nConstruct and interpret a 95% confidence interval for p.\r\nSolution:\r\nFirst we find the point estimate,p, of the proportion.\r\n\r\n\r\n# Specify sample occurrences (x), sample size(n), and confidence_level\r\n\r\n\r\nx<- 567                     #survey respondents  (successes)\r\nn<- 1031                    # total surveyed\r\nconfidence_level<-0.95     #confidence level\r\npoint_estimate<-x/n        # the point estimate is the sample proportion\r\n\r\n\r\n\r\nNow to determine the 90% confidence interval I must find the alpha,the critical z-value, standard error and the margin of error.\r\n\r\n\r\nalpha<-(1-confidence_level)\r\ncritical_z<-qnorm(1-alpha/2)\r\nstandard_error<-sqrt(point_estimate*(1-point_estimate)/n)\r\nmargin_of_error<-critical_z*standard_error \r\n\r\n\r\n\r\nThe lower bound and upper bound of the confidence interval are calculated.\r\n\r\n\r\nlower_bound<-point_estimate-margin_of_error \r\nupper_bound<-point_estimate+margin_of_error\r\n\r\n\r\n\r\nResults\r\n\r\n\r\nsprintf(\"Point Estimate: %0.3f\", point_estimate)\r\n\r\n\r\n[1] \"Point Estimate: 0.550\"\r\n\r\nsprintf(\"Critical Z-value: %0.3f\", critical_z)\r\n\r\n\r\n[1] \"Critical Z-value: 1.960\"\r\n\r\nsprintf(\"Margin of Error: %0.3f\", margin_of_error)\r\n\r\n\r\n[1] \"Margin of Error: 0.030\"\r\n\r\nsprintf(\"Confidence Interval: [%0.3f,%0.3f]\", lower_bound,upper_bound)\r\n\r\n\r\n[1] \"Confidence Interval: [0.520,0.580]\"\r\n\r\nsprintf(\"The %0.1f%% confidence interval for the population proportion is:\", confidence_level*100)\r\n\r\n\r\n[1] \"The 95.0% confidence interval for the population proportion is:\"\r\n\r\nsprintf(\"between %0.4f and %0.4f\",lower_bound,upper_bound)\r\n\r\n\r\n[1] \"between 0.5196 and 0.5803\"\r\n\r\nConfidence interval interpretation\r\nWe have 95% confidence that the interval from the lower bound to the upper bound,[0.5196,0.5803] actually contains the true value of the population proportion of those in the sample believing a college education is valuable.\r\nQuestion 3\r\nSuppose that the financial aid office of UMass Amherst seeks to estimate the mean cost of textbooks per quarter for students. The estimate will be useful if it is within $5 of the true population mean (i.e. they want the confidence interval to have a length of $10 or less). The financial aid office is pretty sure that the amount spent on books varies widely, with most values between $30 and $200. They think that the population standard deviation is about a quarter of this range. Assuming the significance level to be 5%, what should be the size of the sample?\r\nSolution\r\nHere’s what we know:\r\nmean population error = +/-5\r\nrange of the data - upper range - lower range = 200-30 = 170\r\npopulation standard deviation = Range/a quarter 170/4=42.5 which is sigma\r\nsignificance level or alpha = 0.05\r\nfrom this we can calculate the z-score or critical value\r\n\r\n\r\ncritical_z<-qnorm(1-0.05/2) #using the significance level or alpha we calculate z-score                 \r\nprint(critical_z)\r\n\r\n\r\n[1] 1.959964\r\n\r\n\r\n\r\nn_sample_size<-((1.96*42.5)/5)**2      #n=(z-score*standard deviation)/margin of error)**2\r\nprint(n_sample_size)                   #sample size\r\n\r\n\r\n[1] 277.5556\r\n\r\nThus, we see that we would need a minimum sample of 277.5556 or 278\r\nQuestion 4\r\n(Exercise 6.7, Chapter 6 of SMSS, Agresti 2018) According to a union agreement, the mean income for all senior-level workers in a large service company equals $500 per week. A representative of a women’s group decides to analyze whether the mean income μ for female employees matches this norm. For a random sample of nine female employees, ȳ = $410 and s = 90.\r\na)Test whether the mean income of female employees differs from $500 per week. Include assumptions, hypotheses, test statistic, and P-value. Interpret the result.\r\nb)Report the P-value for Ha : μ < 500. Interpret.\r\nc)Report and interpret the P-value for H a: μ > 500.\r\n(Hint: The P-values for the two possible one-sided tests must sum to 1.)\r\nSolutions\r\na)Test whether the mean income of female employees differs from $500 per week. Include assumptions, hypotheses, test statistic, and P-value. Interpret the result.\r\nHere’s what we know:\r\n\\(\\mu\\) mean income for all senior level workers = $500/ week\r\n\\(\\bar{y}\\) random sample of 9 female employees income = $410/week\r\ns standard deviation = 90\r\nn random sample female employees = 9\r\nHypotheses\r\nThe null and alternative hypotheses are:-\r\n\\(H_0\\): \\(\\mu\\) = $500 per week The null hypothesis weekly income for all senior-level workers is $500 per week\r\n\\(H_a\\): \\(\\mu\\) ≠ $500 per week\r\nThe alternative hypothesis suggests the mean weekly income is ≠ $500 (two-sided)\r\nTest Statistic\r\n\r\n\r\nt_test_income<-(410-500)/(90/sqrt(9))    #Test statistic using t-test\r\nprint(t_test_income)\r\n\r\n\r\n[1] -3\r\n\r\nP-Value\r\n\r\n[1] 0.01707168\r\n\r\nInterpretation:\r\npart a\r\nAssuming alpha α = 0.05 and we know the p-value is 0.0171 The p-value 0.0171 < 0.05 , we reject the null hypothesis There is therefore sufficient evidence to claim the mean differs from the weekly income of $500.\r\npart b:\r\nReport the P-value for Ha : μ < 500. Interpret.\r\n\\(H_0\\): \\(\\mu\\) = $500 per week\r\n\\(H_a\\): \\(\\mu\\) < $500 per week (left-tail test)\r\np-value = p(t < t_test_income) p(t < -3)\r\nP-value for \\(H_a\\) < $500 per week (left-tail test)\r\n\r\n\r\n#using the formula: pt(q,df,lower.tail=TRUE,log.p=FALSE) to find the p-value\r\n\r\n\r\nq<-(-3)\r\nn_random_sample<-9\r\ndf_sample<-(n_random_sample-1)                            #degrees of freedom \r\nleft_p_value<-pt(q,df_sample,lower.tail = T,log.p = F)    #p value for alternative hypothesis\r\nprint(left_p_value)         \r\n\r\n\r\n[1] 0.008535841\r\n\r\nInterpretation:\r\npart b\r\nSince the P-value 0.0085 is less than the presumed significance level,alpha α = 0.05 I reject the null hypothesis,\\(H_0\\). What this suggests is that there is sufficient evidence to conclude that the mean is < less than 500.\r\npart c:\r\nReport and interpret the P-value for Ha: μ > 500. (Hint: The P-values for the two possible one-sided tests must sum to 1.)\r\n\\(H_0\\): \\(\\mu\\) = $500 per week\r\n\\(H_a\\): \\(\\mu\\) > $500 per week (right-tail test)\r\np-value = p(t > t_test_income) p(t > -3)\r\nP-value for \\(H_a\\) >$500 per week (right-tail test)\r\n\r\n\r\n#using the formula: pt(q,df,lower.tail=TRUE,log.p=FALSE) to find the p-value\r\n\r\n\r\nq<-(-3)\r\nn_random_sample<-9\r\ndf_sample<-(n_random_sample-1)                                     #degrees of freedom \r\nright_p_value<-pt(q,df_sample,lower.tail = F,log.p = F)            #p value for alternative hypothesis\r\nprint(right_p_value)   \r\n\r\n\r\n[1] 0.9914642\r\n\r\n#verification sum of left and right tail p-values equal 1\r\n\r\nleft_p_value<-pt(q,df_sample,lower.tail = T,log.p = F) \r\nright_p_value<-pt(q,df_sample,lower.tail = F,log.p = F)\r\nleft_right_sum<-(left_p_value+right_p_value)\r\nprint(left_right_sum)\r\n\r\n\r\n[1] 1\r\n\r\nInterpretation:\r\npart c\r\nSince the p-value 0.9915 is greater than the presumed significance level alpha α = 0.05 \\(H_a\\) > 500,therefore we do not reject the null hypothesis \\(H_0\\). There is insufficient evidence to support the claim \\(\\mu\\) mean is > 500.\r\nQuestion 5\r\n(Exercise 6.23, Chapter 6 of SMSS, Agresti 2018) Jones and Smith separately conduct studies to test H0: μ = 500 against Ha : μ ≠ 500, each with n = 1000. Jones gets ȳ = 519.5, with se = 10.0. Smith gets ȳ = 519.7,with se = 10.0.\r\nShow that t = 1.95 and P-value = 0.051 for Jones. Show that t = 1.97 and P-value = 0.049 for Smith.\r\nUsing α = 0.05, for each study indicate whether the result is “statistically significant.”\r\nUsing this example, explain the misleading aspects of reporting the result of a test as “P ≤ 0.05” versus “P > 0.05,” or as “reject H0” versus “Do not reject H0 ,” without reporting the actual P-value.\r\nSolutions:\r\nShow that t = 1.95 and P-value = 0.051 for Jones. Show that t = 1.97 and P-value = 0.049 for Smith.\r\nHere’s what we know:\r\nsample_n = 1000 each for Jones and Smith\r\ndf_sample_n<-(1000-1) degrees of freedom\r\n\\(\\bar{y}\\) = 519.5 (Jones)\r\nt = 1.95 (Jones)\r\np - value = 0.051 (Jones)\r\nse = 10.0 (Jones)\r\n\\(\\bar{y}\\) = 519.7 (Smith)\r\nt = 1.97 (Smith)\r\np-value = 0.049 (Smith)\r\nse = 10.0 (Smith)\r\n\\(H_0\\): \\(\\mu\\) = 500\r\n\\(H_a\\): \\(\\mu\\) ≠ 500\r\nJones\r\nWe were already given both the test statistic 1.95 and p-value 0.051 for Jones so we are just verifying both.\r\nTest_statistic = (\\(\\bar{y}\\) - \\(\\mu\\))/10\r\n\r\n\r\ndf_sample_n<-(1000-1)  #degrees of freedom\r\n\r\nt_test_jones<-(519.5-500)/10    #Test statistic using t-test\r\nprint(t_test_jones)\r\n\r\n\r\n[1] 1.95\r\n\r\np_value_jones<-pt(t_test_jones,df_sample_n,lower.tail = F,log.p = F)*2\r\nprint(p_value_jones)\r\n\r\n\r\n[1] 0.05145555\r\n\r\nSmith\r\nWe were already given both the test statistic 1.97 and p-value 0.049 for Smith so we are verifying both.\r\nTest_statistic = (\\(\\bar{y}\\) - \\(\\mu\\))/10\r\n\r\n\r\ndf_sample_n<-(1000-1)  #degrees of freedom\r\n\r\nt_test_smith<-(519.7-500)/10    #Test statistic using t-test\r\nprint(t_test_smith)\r\n\r\n\r\n[1] 1.97\r\n\r\np_value_smith<-pt(t_test_smith,df_sample_n,lower.tail = F,log.p = F)*2      #p-value for smith\r\nprint(p_value_smith)                                              #output smith\r\n\r\n\r\n[1] 0.04911426\r\n\r\nUsing α = 0.05, for each study indicate whether the result is “statistically significant.”\r\nFor α = 0.05 we reject the null hypothesis \\(H_0\\) if the p-value is greater than 0.05 and do not reject if the p-value is equal or greater to => \\(H_0\\). So in the case of Jones since the p-value 0.051 is negligibly larger than alpha, it is not statistically significant and we fail to reject the null hypothesis \\(H_0\\). In the case of Smith, the p-value of 0.049 is less than alpha, α = 0.05 which is less than the level of significance, we reject the null hypothesis since a smaller p-value suggests statistical significance.\r\nUsing this example, explain the misleading aspects of reporting the result of a test as “P ≤ 0.05” versus “P > 0.05,” or as “reject H0” versus “Do not reject H0 ,” without reporting the actual P-value.\r\nIn this study the p-values are negligibly the same between Jones and Smith. However, in spite of this because our predetermined significance p-value is ≤ 0.05 in the case of Smith, the null hypothesis is rejected and we conclude there is statistical evidence for the alternative hypothesis \\(H_a\\). Conversely, if our predetermined significance p-value is greater than 0.05 as in the case of Jones then we fail to reject the null hypothesis. There is insufficient evidence to draw any conclusions.\r\nQuestion 6\r\nAre the taxes on gasoline very high in the United States? According to the American Petroleum Institute, the per gallon federal tax that was levied on gasoline was 18.4 cents per gallon. However, state and local taxes vary over the same period. The sample data of gasoline taxes for 18 large cities is given below in the variable called gas_taxes.\r\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\r\nIs there enough evidence to conclude at a 95% confidence level that the average tax per gallon of gas in the US in 2005 was less than 45 cents? Explain.\r\nSolution\r\nHere’s what we know:\r\nsample_gas_taxes<-18\r\ndf_gas_taxes<-sample_gas_taxes-1\r\n95% confidence level (presumptive)\r\nsignificance level alpha = 0.05 based on a 95% confidence level\r\nz-score = 1.96 based on 95% confidence level\r\nFrom this information we can determine the following:\r\n\r\n[1] 44.67946\r\n[1] 37.0461\r\n\r\nThe 95% confidence interval is [37.0461 ,44.6795] using manual calculations.\r\nBecause the average tax per gallon is less than 45 cents, it is within the lower and upper bounds of the 95% confidence interval.We can therefore reasonably conclude that there is sufficient evidence that the confidence interval contains taxes less than 45 cents.\r\nAlternative outcome using t.test:\r\n\r\n\r\ngas_taxes<- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\r\n\r\nmean(gas_taxes)\r\n\r\n\r\n[1] 40.86278\r\n\r\nt.test(gas_taxes,conf.level = 0.95)   # one sample t-test\r\n\r\n\r\n\r\n    One Sample t-test\r\n\r\ndata:  gas_taxes\r\nt = 18.625, df = 17, p-value = 9.555e-13\r\nalternative hypothesis: true mean is not equal to 0\r\n95 percent confidence interval:\r\n 36.23386 45.49169\r\nsample estimates:\r\nmean of x \r\n 40.86278 \r\n\r\nThe 95% confidence interval is [36.23386 ,45.49169]\r\nThere is not enough evidence to conclude at a 95% confidence level that the average tax per gallon of gas in the US in 2005 was less than 45 cents because 45 cents is inside the confidence interval. The confidence interval contains taxes greater than 45 cents.\r\nPlease note I am not sure why there is a difference between 95% confidence intervals when calculated manually versus the t.test function. I therefore include both outcomes.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-24T15:25:31-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomclairebattagliahomework-1-603/",
    "title": "Homework 1",
    "description": "Statistical Inference",
    "author": [
      {
        "name": "Claire Battaglia",
        "url": "https://rpubs.com/clairebattaglia"
      }
    ],
    "date": "2022-02-24",
    "categories": [],
    "contents": "\n\nContents\nQuestion 1\nQuestion\nAnswer\nSolution\n\nQuestion 2\nQuestion\nAnswer\nSolution\n\nQuestion 3\nQuestion\nAnswer\nSolution\n\nQuestion 4\nQuestion\nAnswer\nSolution\n\nQuestion 5\nQuestion\nSolution\n\nQuestion 6\nQuestion\nAnswer\nSolution\n\n\nQuestion 1\nQuestion\nThe time between the date a patient was recommended for heart surgery and the surgery date for cardiac patients in Ontario was collected by the Cardiac Care Network (“Wait Times Data Guide,” Ministry of Health and Long-Term Care, Ontario, Canada, 2006). The sample mean and sample standard deviation for wait times (in days) of patients for two cardiac procedures are given in the accompanying table. Assume that the sample is representative of the Ontario population.\nSurgical Procedure\nSample Size (\\(n\\))\nMean Wait Time (\\(\\overline{x}\\))\nStandard Deviation (\\(s\\))\nbypass\n539\n19\n10\nangiography\n847\n18\n9\nConstruct the 90% confidence interval to estimate the actual mean wait time for each of the two procedures. Is the confidence interval narrower for angiography or bypass surgery?\nAnswer\nFor those undergoing bypass surgery the estimated mean wait time is between 18.29 and 19.71 days (19 \\(\\pm\\) .71 days).\nFor those undergoing angiography surgery the estimated mean wait time is between 17.49 and 18.51 days (18 \\(\\pm\\) .51 days).\nThe confidence interval is narrower for the population of patients undergoing angiography surgery.\nSolution\nThere are two populations: patients who have undergone bypass surgery and those who have undergone angiography surgery. I have a sample from each population and the mean and standard deviation of each sample.\nWhile I don’t know the sampling method(s), I am told each sample is representative of its corresponding population and I can see that each is large (\\(n>30\\)). Because the variable wait time is measured in days, I am working with discrete interval data, which I need to know in order to construct the confidence interval correctly.\nA confidence interval is essentially a “best guess” of a population parameter (called the point estimate), plus or minus a margin of error. The confidence level, which is frequently expressed as a percentage, is the proportion of trials in which the confidence interval would contain the true population mean. As a statement of proportion in the long run, it is only meaningful within the frequentist approach to statistics.\nThe confidence interval (\\(CI\\)) is a \\[{point\\;estimate}\\pm{margin\\;of\\;error}\\] where the \\[{margin\\;of\\;error} = t*{standard\\;error}\\] and the \\[{standard\\;error} = \\frac{\\sigma}{\\sqrt{n}}\\] Because I don’t know the true population mean (\\(\\mu\\)), I’ll use the sample mean (\\(\\overline{x}\\)) as my estimator (\\(\\hat{\\mu}\\)) of the population mean. Similarly, because I don’t know the true population standard deviation (\\(\\sigma\\)), I’ll use the sample standard deviation (\\(s\\)) as my estimator (\\(\\hat{\\sigma}\\)) of the population standard deviation. Because I don’t know the population standard deviation and am instead using the sample standard deviation as an estimate, I’m going to use the \\(t\\) distribution, which means I’ll be using a \\(t\\)-score instead of a \\(z\\)-score. It’s worth noting, however, that both samples are large enough that the \\(t\\) distribution will be essentially identical to the standard normal distribution.\nThis finally gives me the formula \\[CI=\\overline{x}\\;\\pm\\;\\left(t*\\frac{s}{\\sqrt{n}}\\right)\\] To calculate the \\(t\\)-score for a 90% confidence interval, I’m going to use R. Because the confidence interval is 90% (.9), the error probability (\\(\\alpha\\)) is .1. \\(\\alpha/2=5\\)%, or .05 on the right tail and .05 on the left tail.\n\n\nShow code\n\n# calculate quantile for t distribution\ntScoreBypass <- qt(p = .95, df = 538)\n\n# view\ntScoreBypass\n\n\n[1] 1.647691\n\nSo the final equation is \\[CI_{90}={19}\\;\\pm\\;\\left(1.647691*\\frac{10}{\\sqrt{539}}\\right)\\]\n\n\nShow code\n\n# calculate lower bound\nlowerBypass <- 19 - (1.647691*(10/sqrt(539)))\n\n# calculate upper bound\nupperBypass <- 19 + (1.647691*(10/sqrt(539)))\n\n# calculate range\nrangeBypass <- upperBypass - lowerBypass\n\n\n\nThe lower bound is 18.29029 and upper bound is 19.70971, making the range 1.41942.\nI’ll do the same calculations for my second population (patients who have undergone angiography surgery).\n\n\nShow code\n\n# calculate quantile for t distribution\ntScoreAngio <- qt(p = .95, df = 846)\n\n# view\ntScoreAngio\n\n\n[1] 1.646657\n\nSo the final equation is \\[CI_{90}={18}\\;\\pm\\;\\left(1.646657*\\frac{9}{\\sqrt{847}}\\right)\\]\n\n\nShow code\n\n# calculate lower bound\nlowerAngio <- 18 - (1.646657*(9/sqrt(847)))\n\n# calculate upper bound\nupperAngio <- 18 + (1.646657*(9/sqrt(847)))\n\n# calculate range\nrangeAngio <- upperAngio - lowerAngio\n\n\n\nThe lower bound is 17.49078 and the upper bound is 18.50922, making the range 1.01844.\nThis means that if I were to sample repeatedly from these two populations, 90% of the intervals created with these models would contain the true populations means.\nThe confidence interval is narrower for the angiography population (1.01844 \\(<\\) 1.41942). This is to be expected because the angiography sample size is larger and the standard deviation is smaller.\nQuestion 2\nQuestion\nA survey of 1031 adult Americans was carried out by the National Center for Public Policy. Assume that the sample is representative of adult Americans. Among those surveyed, 567 believed that college education is essential for success. Find the point estimate, p, of the proportion of all adult Americans who believe that a college education is essential for success. Construct and interpret a 95% confidence interval for p.\nAnswer\nThe point estimate is 0.55 and the 95% confidence interval is 0.52 to 0.58. That is, the estimated proportion of adult Americans who believe that college education is essential for success is 55% \\(\\pm\\) 3%.\nSolution\nThe population is all adult Americans and I have a representative sample (\\(n\\)) of 1031. Of those sampled, 567 believe that a college education is essential for success. This is enough information to calculate the sample proportion (\\(\\hat{\\pi}\\)), which I’ll then use to construct a 95% confidence interval for the true population proportion.\nTo construct the confidence interval, I’ll be using the formula \\[CI=\\hat{\\pi}\\;\\pm\\;z\\sqrt{\\left(\\frac{\\hat{\\pi}\\;(1-\\hat{\\pi})}{n}\\right)}\\] First, I’ll calculate the sample proportion, which will serve as my estimator for the true population proportion.\n\n\nShow code\n\n# calculate sample proportion\nsampProp <- 567/1031\n\n\n\nThus the sample proportion is 0.5499515\nIn a standard normal distribution 95% of all values fall within 1.96 standard deviations of the mean. Because I’m constructing a 95% confidence interval, then, the \\(z\\)-score I’ll be using is 1.96.\nThus \\[CI_{95}=0.5499515\\;\\pm\\;1.96\\sqrt{\\left(\\frac{0.5499515\\;(1-0.5499515)}{1031}\\right)}\\]\n\n\nShow code\n\n# calculate lower bound\nlowerBound <- sampProp - (1.96 * sqrt(((sampProp * (1-sampProp)/1031))))\n\n# calculate upper bound\nupperBound <- sampProp + (1.96 * sqrt(((sampProp * (1-sampProp)/1031))))\n\n\n\nThus the lower bound of the confidence interval is 0.52 and the upper bound is 0.58.\nThis means that using the sample proportion of 0.5499515 as the estimator (\\(\\hat{\\pi}\\)) for the true population proportion and constructing a 95% confidence interval, I can expect that 95% of trials would contain the true population mean within the interval of 0.52 and 0.58 (\\(\\pi\\pm.0304\\)).\nAlternatively, I can use the R function prop.test to calculate everything needed to answer this question. Since I’ve already calculated everything, I’ll simply use it to validate my calculations.\n\n\nShow code\n\n# calculate prop test\nprop.test(567, 1031, p = 0.5499515)\n\n\n\n    1-sample proportions test with continuity correction\n\ndata:  567 out of 1031, null probability 0.5499515\nX-squared = 0, df = 1, p-value = 1\nalternative hypothesis: true p is not equal to 0.5499515\n95 percent confidence interval:\n 0.5194543 0.5800778\nsample estimates:\n        p \n0.5499515 \n\nQuestion 3\nQuestion\nSuppose that the financial aid office of UMass Amherst seeks to estimate the mean cost of textbooks per quarter for students. The estimate will be useful if it is within $5 of the true population mean (i.e. they want the confidence interval to have a length of $10 or less). The financial aid office is pretty sure that the amount spent on books varies widely, with most values between $30 and $200. They think that the population standard deviation is about a quarter of this range. Assuming the significance level to be 5%, what should be the size of the sample?\nAnswer\nThe sample size should be 278.\nSolution\nThe formula for determining the sample size for estimating a population mean (\\(\\mu\\)) is \\[n=\\sigma^2\\left(\\frac{z}{M}\\right)^2\\] where \\(n\\) is the sample size (what I’m trying to find), \\(\\sigma\\) is the population standard deviation, \\(z\\) is the \\(z\\)-score for the chosen confidence level, and \\(M\\) is the margin of error.\nWhile I don’t know the true population standard deviation (\\(\\sigma\\)), I am given an estimate, which will suffice. The suspected range is 170 and I am told the population standard deviation is estimated to be about a quarter of that, which is 42.50.\nIf the significance level (\\(\\alpha\\)) is 5%, then the confidence level is 95% (\\(1-{confidence\\;level}=\\alpha\\)). Assuming a normal distribution, the \\(z\\)-score for a 95% confidence level is 1.96.\nThe margin of error is 5.\nThus \\[n=42.5^2\\left(\\frac{1.96}{5}\\right)^2\\]\n\n\nShow code\n\n# calculate sample size\nn <- (42.5^2)*((1.96/5)^2)\n\n\n\nwhich indicates that a sample size of 277.5556 is required to estimate the population mean with a 95% confidence interval.\nBecause the units in the sample are people (i.e. a discrete unit), I’ll round up to the nearest whole number, giving me a total of 278.\n\nBecause I need a minimum of 277.5556, I would round up to the nearest whole number regardless of what the normal rule for rounding would indicate.\nThis means that I would need to sample a minimum of 278 people to estimate the mean cost of textbooks per student per quarter within plus or minus $5. If I repeatedly sample at least this number of people, 95% of the intervals constructed would contain the true population mean.\nQuestion 4\nQuestion\nAccording to a union agreement, the mean income for all senior-level workers in a large service company equals $500 per week. A representative of a women’s group decides to analyze whether the mean income μ for female employees matches this norm. For a random sample of nine female employees, ȳ = $410 and s = 90.\nTest whether the mean income of female employees differs from $500 per week. Include assumptions, hypotheses, test statistic, and P-value. Interpret the result.\nReport the P-value for Ha : μ < 500. Interpret.\nReport and interpret the P-value for Ha: μ > 500. (Hint: The P-values for the two possible one-sided tests must sum to 1.)\nAnswer\nThere is sufficient evidence to reject the null hypothesis and thereby accept the alternative hypothesis that the mean income for female employees does not equal $500 per week. The test statistic is -3. The \\(P\\)-value is .017.\nFor \\(H_a:\\mu<500\\), the \\(P\\)-value is .009. Because the \\(P\\)-value is less than the most stringent significance level of .01, we can reject the null hypothesis (\\(H_0:\\mu\\ge500\\)) and thereby accept the alternative hypothesis.\nFor \\(H_a:\\mu>500\\), the \\(P\\)-value is .991. Because the \\(P\\)-value is greater than the significance level of .01 (and even the more lenient .05), we cannot reject the null hypothesis (\\(H_0:\\mu\\le500\\)) at this time.\nSolution\nTo solve this problem, I’m going to assume:\nA normal population distribution.\nThe sample of female employees is sufficiently large.\nTo begin, I’ll identify the null hypothesis (\\(H_0\\)) and alternative hypothesis (\\(H_a\\)).\nThe null hypothesis is that there is no difference between the mean for female employees and the mean for all employees. That is, the mean for female employees is also 500.\n\\[{H_0:}\\;\\mu = 500\\] The alternative hypothesis is that there is a difference. That is, the mean for female employees is not 500. Because I’m interested in any kind of difference (\\(\\mu < 500\\) or \\(\\mu > 500\\)), I’ll be using a two-sided test.\n\\[{H_a:}\\;\\mu\\neq 500\\] Conducting a hypothesis test asks whether what we’ve observed (\\(\\overline{y}=410\\)) would be so unlikely if the null hypothesis (\\(H_0=500\\)) were true that we are obligated to reject it. If we find that what we observed is not that unlikely and could reasonably be explained by sample variability, we will not be able to reject the null hypothesis at this time.\nThe formula for calculating the test statistic is \\[t=\\frac{\\overline{y}-\\mu_0}{se}\\] where \\[se=\\frac{s}{\\sqrt{n}}\\] Thus the standard error is \\[se=\\frac{90}{\\sqrt{9}}\\] and \\[t=\\frac{410-500}{30}\\]\n\n\nShow code\n\n# calculate estimated standard error\nse <- 90/sqrt(9)\n\n# calculate test statistic\ntestStat <- (410-500)/se\n\n\n\n\\(t=\\) -3 and \\(|t|=\\) 3\nNext I’ll calculate the \\(P\\)-value.\n\n\nShow code\n\n# calculate 2-sided P value\npValue <- 2 * (1-pt(q = 3, df = 8))\n\n\n\nThus the \\(P\\)-value \\(=\\) 0.0170717\nThis indicates a 0.0170717 probability that we would observe the sample mean (\\(\\overline{y}\\)) of 410 if the null hypothesis were true. That is, if the mean for female employees (\\(\\mu\\)) were really 500. While this finding isn’t significant at the .01 level, it is significant at the .05 level and I can conclude that if the mean for female employees were 500, I’d be rather unlikely to end up with a sample mean of 410. I feel comfortable, then, in rejecting the null hypothesis and accepting the alternative hypothesis.\nNow I’ll look at the probabilities that the sample mean would be above or below the population mean separately.\n\n\nShow code\n\n# calculate P value for Ha > 500, right-tail\npValueG <- 1-pt(q = 3, df = 8, lower.tail = FALSE)\n\n# calculate P value for Ha < 500, left-tail\npValueL <- 1-pValueG\n\n\n\nFor \\(H_a:\\mu<500\\), \\(P=\\) 0.009. This indicates a 0.009 probability that we would have observed a \\(t\\)-score equal to or lesser than what we what we did in fact observe if the null hypothesis (\\(H_0:\\mu\\ge500\\)) were true. Put more simply, if the null hypothesis were true, it is highly unlikely we would have observed what we observed. We can reject the null hypothesis.\nFor \\(H_a:\\mu>500\\), \\(P=\\) 0.991. This indicates a 0.991 probability that we would have observed a \\(t\\)-score equal to or greater than what we did in fact observe if the null hypothesis (\\(H_0:\\mu\\le500\\)) were true. That is, if the null hypothesis were true, it is highly likely we would have observed what we observed. We can accept the null hypothesis.\nTaken together these lend strong support to the claim that the mean income for female employees is less than the mean for all employees.\nQuestion 5\nQuestion\nJones and Smith separately conduct studies to test H0: μ = 500 against Ha : μ ≠ 500, each with n = 1000. Jones gets ȳ = 519.5, with se = 10.0. Smith gets ȳ = 519.7, with se = 10.0.\nShow that t = 1.95 and P-value = 0.051 for Jones. Show that t = 1.97 and P-value = 0.049 for Smith.\nUsing α = 0.05, for each study indicate whether the result is “statistically significant.”\nUsing this example, explain the misleading aspects of reporting the result of a test as “P ≤ 0.05” versus “P > 0.05,” or as “reject H0” versus “Do not reject H0 ,” without reporting the actual P-value.\nSolution\nThe formula for calculating the test statistic is \\[t=\\frac{\\overline{y}-\\mu_0}{se}\\] Since they both assume the population mean (\\(\\mu\\)) to be 500 (the null hypothesis) and they both got a standard error of 10, the only difference between their tests is the mean of each of their samples (\\(\\overline{y}\\)).\nThus Jones’s test statistic is \\[t=\\frac{{519.5}-{500}}{10}\\] and Smith’s is \\[t=\\frac{{519.7}-{500}}{10}\\]\n\n\nShow code\n\n# calculate test stat Jones\ntStatJ <- (519.5-500)/10\n\n# calculate test stat Smith\ntStatS <- (519.7-500)/10\n\n\n\nFor Jones, \\(t=\\) 1.95\nFor Smith, \\(t=\\) 1.97\nNow I’ll calculate the \\(P\\)-value for each of them. This will tell me the probability of observing the data they actually observed if the null hypothesis is true. Since the alternative hypothesis is non-directional, I’ll calculate the two-sided probability.\n\n\nShow code\n\n# calculate P value Jones\npJones <- 2*pt(q = tStatJ, df = 999, lower.tail=FALSE)\n\n# calculate P value Smith\npSmith <- 2*pt(q = tStatS, df = 999, lower.tail=FALSE)\n\n\n\nFor Jones, \\(P=\\) 0.051\nFor Smith, \\(P=\\) 0.049\nSince the significance level (\\(\\alpha\\)) is .05, Jones is unable to reject the null hypothesis at this time (\\(.051>.05\\)) and his/her results are not statistically significant. Smith, however, is able to reject the null hypothesis (\\(.049<.05\\)) and can claim that his/her results are statistically significant (at the level of .05).\nThis example illustrates the danger of living and dying by whether or not the \\(P\\)-value is statistically significant. For example, if a statistically significant finding is requisite for publishing, then only Smith’s finding would make its way to a larger audience. If the \\(P\\)-value were not included, the reader might wrongly assume that the evidence for rejecting the null hypothesis is strong, when in reality it only nudges us towards that conclusion.\nAlternatively, if both findings were published and the \\(P\\)-values were not included, the reader would see that Jones does not reject the null hypothesis but that Smith does and might wrongly believe that their findings were contradictory. Including the \\(P\\)-values, however, would allow the reader to see that the findings are actually not contradictory.\nIt’s important to remember that the significance level is an arbitrary demarcation. This is ultimately a problem of using a binary framework (reject/fail to reject) in a world in which very few things (if any) are actually binary. Maintaining a larger perspective is paramount—statistics can and should inform our understanding of the world but significance testing is not a substitute for critical thinking.\nQuestion 6\nQuestion\nAre the taxes on gasoline very high in the United States? According to the American Petroleum Institute, the per gallon federal tax that was levied on gasoline was 18.4 cents per gallon. However, state and local taxes vary over the same period. The sample data of gasoline taxes for 18 large cities is given below in the variable called gas_taxes.\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\nIs there enough evidence to conclude at a 95% confidence level that the average tax per gallon of gas in the US in 2005 was less than 45 cents? Explain.\nAnswer\nYes, there is sufficient evidence to reject the null hypothesis and thereby accept the alternative hypothesis that in 2005 the average gas tax in the United States was less than 45.00 cents.\nSolution\nTo answer this question, I’m going to conduct a one-sided significance test. To do so, I’m going to assume a random sample and normal distribution.\nThe null hypothesis is that the average tax per gallon is 45.00 cents. \\[H_0:\\mu=45.00\\] The alternative hypothesis is that the average tax per gallon is less than 45.00 cents. \\[H_a:\\mu<45.00\\] Conducting a hypothesis test asks whether the observed data (the gas taxes for the 18 cities in our sample) would be so unlikely if the null hypothesis were true that we are forced to reject it.\nFirst I’ll load the given sample data and calculate some summary statistics.\n\n\nShow code\n\n# create vector of sample data\ngasTaxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\n\n# calculate mean\nsampMean <- mean(gasTaxes)\n\n# calculate sd\nsampSD <- sd(gasTaxes)\n\n\n\nThe sample mean (\\(\\overline{y}\\)) is 40.8627778 and the sample standard deviation (\\(s\\)) is 9.3083168.\nThe formula for calculating the test statistic is \\[t=\\frac{\\overline{y}-\\mu_0}{se}\\] where \\[se=\\frac{s}{\\sqrt{n}}\\] Thus \\[se=\\frac{9.3083168}{\\sqrt{18}}\\] and \\[t=\\frac{40.8627778-45.00}{2.193991}\\]\n\n\nShow code\n\n# calculate standard error\nse <- 9.3083168/sqrt(18)\n\n# calculate t statistic\ntStatGas <- (40.8627778-45.00)/se\n\n\n\nThus the test statistic is -1.8857058.\nFinally, I’ll calculate the \\(P\\)-value.\n\n\nShow code\n\n# calculate P value\npGas <- pt(q = tStatGas, df = 17, lower.tail=TRUE)\n\n\n\nThus the \\(P\\)-value is 0.038\nThis means that if the null hypothesis were true there is a 0.038 probability of observing the data we observed or data more extreme.\nA 95% confidence interval means a significance level of .05 (\\(1-{confidence\\;level}=\\alpha\\)). Given that the \\(P\\)-value is less than the significance level of .05, I can say that, yes, given a 95% confidence interval there is sufficient evidence to reject the null hypothesis and accept the alternative hypothesis that in 2005 the average gas tax in the United States was less than 45.00 cents.\nAlternatively, I can use the R function t.test to calculate everything needed to answer this question. Since I’ve already calculated everything, I’ll simply use it to validate my calculations.\n\n\nShow code\n\nt.test(gasTaxes, mu = 45.00, alternative = \"less\")\n\n\n\n    One Sample t-test\n\ndata:  gasTaxes\nt = -1.8857, df = 17, p-value = 0.03827\nalternative hypothesis: true mean is less than 45\n95 percent confidence interval:\n     -Inf 44.67946\nsample estimates:\nmean of x \n 40.86278 \n\nAnother approach to hypothesis testing is constructing the appropriate confidence interval and determining whether the mean of the null hypothesis is contained within that interval or not.\nThe t.test function has returned the confidence interval and since I’m looking at it only to confirm my decision to reject the null hypothesis, I won’t calculate it manually. Because the alternative hypothesis is directional, the confidence interval is likewise one-sided. In this case it is [-\\(\\infty\\), 44.67946]. This interval does not contain the mean of the null hypothesis, which confirms my decision to reject the null hypothesis.\n\nIt’s worth noting that the upper bound of the interval is close to 45.00. This raises the question of whether the difference has any practical significance. I don’t follow conversations about gas tax policy so I can’t comment on how meaningful it is to say that the average tax is less than 45.00 cents if it could reasonably be 44.68 cents.\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-24T15:25:17-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomjflattery870090/",
    "title": "Homework 1",
    "description": "My HW 1 for 603",
    "author": [
      {
        "name": "Justin Flattery",
        "url": {}
      }
    ],
    "date": "2022-02-24",
    "categories": [],
    "contents": "\n\n\nknitr::opts_chunk$set(echo = TRUE)\n\n\n\nQuestion 1\nFor each procedure we will construct a confidence interval around our estimate of the actual mean by fitting the sample about a t distribution. We can do this since we have the sample mean, sample size (thus degrees of freedom) and sample standard deviation\nBYPASS Confidence Interval\nFirst we will find the T score associated with the degrees of freedom and level of confidence\n\n\nqt(p = .9, df = 538)\n\n\n[1] 1.283127\n\nWe will now plug this t score into the formula to find the standard error,\n\n\n(1.283127 * (10/(sqrt(539))))\n\n\n[1] 0.5526819\n\nWe will now add/subtract the sample mean from the standard error to produce our 90% confidence interval\n\n\n19 + (1.283127 * (10/(sqrt(539))))\n\n\n[1] 19.55268\n\n\n\n19 - (1.283127 * (10/(sqrt(539))))\n\n\n[1] 18.44732\n\nTherefore the 90% confidence interval for bypass surgery is [18.45,19.55]\nAngiography Procedure\nAgain we will find the T score associated with the degrees of freedom and level of confidence)\n\n\nqt(p = .9, df = 846)\n\n\n[1] 1.282553\n\nWe will now plug this t score into the formula to find the standard error\n\n\n(1.282553 * (9/(sqrt(847))))\n\n\n[1] 0.3966214\n\nWe will now add/subtract the sample mean from the standard error to produce our 90% confidence interval\n\n\n18 + (1.282553 * (9/(sqrt(847))))\n\n\n[1] 18.39662\n\n18 - (1.282553 * (9/(sqrt(847))))\n\n\n[1] 17.60338\n\nTherefore the 90% confidence interval for angiography surgery is [17.6,18.40]\nWhich is narrower?\nAngiography - 17.60 - 18.39 Bypass - 18.45 - 19.55\nAngiography surgery because it has a smaller range to its interval (0.79 vs 1.1)\nQuestion 2 n=1031 567=success 95% confidence\n\n\n567/1031\n\n\n[1] 0.5499515\n\nPoint estimate: 0.55 - 55% of americans believe\nI will use r’s prop test formula to find the 95% confidence interval for p, using the knowledge of 567 believed in a 1031 sample.\n\n\nprop.test(567,1031,conf.level = 0.95)$conf.int\n\n\n[1] 0.5189682 0.5805580\nattr(,\"conf.level\")\n[1] 0.95\n\nQuestion 3 First I will find the population standard deviation based on information about range\n\n\nsigma = (200-30)/4\n\n\n\nNext, given the information above, assuming we have the population standard deviation, we can assume a normal distribution of the sample. So I will find the z value based on a significance level of 5%. Since this will be a two tailed sample, this will leave 2.5% on each side, so I will find for (0.975)\n\n\nzstar = qnorm(.975)\n#I will input 42.5 as my sigma (population sd variable)\nsigma = 42.5\n#E is my desired width/range of my confidence interval\nE = 10\n\n\n\nI will now input these variables into the appropriate formula - z^2 * sigma^2 / (E^2) to find the necessary sample size\n\n\n(zstar*zstar) * (sigma*sigma)/ (E*E)\n\n\n[1] 69.38635\n\nSince the value is 69.38, we will round up to the next whole number, 70 in order to ensure we have a large enough sample to estimate the mean\nQuestion 4 In order to evaluate if the mean income is different for female employees, we must set up a hypothesis test. In order to evaluate whether it is NOT $500 we will set a null hypothesis that the mean income = $500 per week. The alternative hypothesis will be the opposite of this, that it is different from $500 a week so:\nH0: mu= $500 Ha mu not = 500\nTest assumes data obtained through randomization and sample is representative of larger population.\nFirst we will find the value of the test statistic (tscore), (how far the sample distance is from the mean in a t distribution)\n\n\n(410 - 500)/((90/3))\n\n\n[1] -3\n\nWe will next use r to find the value of p (the probability of observing this occurrence assuming the null hypothesis)for a two tailed test, inputting our test statistic of -3 and df (9-1)\n\n\n2*pt(q=-3, df=8, log = FALSE)\n\n\n[1] 0.01707168\n\nThis produces a p value of 0.017. Since this is a very small number ( less than 0.05), it indicates a very small probability of occurrence and that we can reject the null hypothesis that the population mean is 500 at the 5% significance level.\nB For part b) We will set up a different hypothesis: H0: mu> $500 Ha mu < $500\nWe will plug in the same values (t statistic, df) but use a one tailed test:\n\n\npt(q=-3, df=8,lower.tail = TRUE)\n\n\n[1] 0.008535841\n\nThis produces a p value of 0.008. Since this is a very small number ( less than 0.05), it indicates a very small probability of occurrence and that we can reject the null hypothesis that the population mean is greater than 500 at the 5% significance level.\nC\nFor part c) We will set up a different hypothesis:\nH0: mu< $500 Ha mu > $500\n\n\npt(q=-3, df=8, lower.tail = FALSE)\n\n\n[1] 0.9914642\n\nThis produces a p value of 0.99. Since this is a very large number/close to one and greater than significance level of 0.05, it indicates a very high probability of occurrence and therefore we cannot reject the null hypothesis that the population mean is less than 500 at the 5% significance level.\nQuestion 5 H0: μ = 500 Ha : μ = 500, each with n = 1000. Jones has ȳ = 519.5, with se = 10.0. Smith has ȳ = 519.7, with se = 10.0.\nFirst I will find the t statistic for Jones using formula used in previous questions\n\n\n(519.5 - 500)/(10)\n\n\n[1] 1.95\n\nJones calculating p value\n\n\n2*pt(q=1.95, df=499, lower.tail=FALSE)\n\n\n[1] 0.05173574\n\nNow I will find the t statistic for Smith using formula used in previous questions\n\n\n(519.7 - 500)/(10)\n\n\n[1] 1.97\n\nSmithh calcultaing p value\n\n\n2*pt(q=1.97, df=499, lower.tail=FALSE)\n\n\n[1] 0.04939092\n\nThe result for Smith is statistically significant at the 5% level (since the value of p is 0.049 <.05), the result for Jones it is not statistically significant at 5% level (p = 0.051>.05)\nWithout reporting the actual p value , data can be manipulated to state the sample is significant for example, for Jones, it would be misleading to round down 0.051 to 0.05 and report that p is less than or equal to 0.05, and thus statistically significant. By reporting instead as the reality that P>0.05 (with p included) is much more transparent. Additionally, the p value should be reported along with the significance level when making a statement around rejecting the null hypothesis. For example, we could reject the null hypothesis at the 10% level for Smith - but this would be manipulating the data from our original planned significance level.\nQuestion 6\nFirst I will load in the dataset of gas_taxes based on the sample\n\n\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\n\n\n\nNext, I used r to calculate a t test of the data set under a 95% confidence level\n\n\nt.test(gas_taxes, conf.level = 0.95)$conf.int\n\n\n[1] 36.23386 45.49169\nattr(,\"conf.level\")\n[1] 0.95\n\nConclusion - No - the upper bound of a 95% confidence interval is over 45 cents, therefore we can not definitively say that the average tax per gallon was less than 45C.\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-24T15:25:20-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomkbec864954/",
    "title": "Homework 1 DACSS 603",
    "description": "Descriptive Statistics, Probability, Statistical Inference, and Comparing Two Means",
    "author": [
      {
        "name": "Kristina Becvar",
        "url": {}
      }
    ],
    "date": "2022-02-24",
    "categories": [],
    "contents": "\r\nQuestion 1\r\nSurgical Procedure - Representative Sample\r\nSurgical Procedure\r\nSample Size\r\nMean Wait Time\r\nStandard Deviation\r\nBypass\r\n539\r\n19\r\n10\r\nAngiography\r\n847\r\n18\r\n9\r\nConstruct the 90% confidence interval to estimate the actual mean wait time for each of the two procedures.\r\nIs the confidence interval narrower for angiography or bypass surgery?\r\nAnswer 1\r\nI calculated the answer by first calculating the standard error for each procedure given the mean, standard deviation, and sample size for each. I do so using 0.95 for the qnorm function so that I can determine the 5% confidence level for both the right and left side of the normal distribution, since the sample is larger than n=30. By calculating the 5% margin for each side of the distribution, this gives me the effective 90% confidence interval overall.\r\n\r\n\r\n#Calculate the actual mean wait time for the bypass:\r\n\r\nxbar1 <- 19 #sample mean\r\nsd1a <- 10 #sample standard deviation\r\nn1a <- 539 #sample size\r\n\r\nerror1a <- qnorm(0.95)*sd1a/sqrt(n1a)\r\nerror1a\r\n\r\n\r\n[1] 0.7084886\r\n\r\nlower1a <- xbar1-error1a\r\nupper1a <- xbar1+error1a\r\n\r\nlower1a\r\n\r\n\r\n[1] 18.29151\r\n\r\nupper1a\r\n\r\n\r\n[1] 19.70849\r\n\r\n\r\n\r\n#Calculate the actual mean wait time for the angiography:\r\n\r\nxbar1b <- 18 #sample mean\r\nsd1b <- 9 #sample standard deviation\r\nn1b <- 847 #sample size\r\n\r\nerror1b <- qnorm(0.95)*sd1b/sqrt(n1b)\r\nerror1b\r\n\r\n\r\n[1] 0.5086606\r\n\r\nlower1b <- xbar1b-error1b\r\nupper1b <- xbar1b+error1b\r\n\r\nlower1b\r\n\r\n\r\n[1] 17.49134\r\n\r\nupper1b\r\n\r\n\r\n[1] 18.50866\r\n\r\nNext, I created a data frame with the information.\r\n\r\n\r\nShow code\r\n\r\n#Create a data frame with the information:\r\n\r\ndf1 <- data.frame( c('Bypass', 'Angiography')\r\n                   ,c(19, 18)\r\n                   ,c(539, 847)\r\n                   ,c(10, 9)\r\n                   ,c(18.29151, 17.49134)\r\n                   ,c(19.70849, 18.50866))\r\nnames(df1) <- c('Procedure', 'Mean', 'Sample', 'SD', 'Lower', 'Upper')\r\n\r\ndf1\r\n\r\n\r\n    Procedure Mean Sample SD    Lower    Upper\r\n1      Bypass   19    539 10 18.29151 19.70849\r\n2 Angiography   18    847  9 17.49134 18.50866\r\n\r\nFinally, I created a plot to visualize the results. The visualization communicates that for each procedure, there is a range of values where we can expect 90% of the estimates to include the population mean given the sample mean and standard deviation.\r\n\r\n\r\nShow code\r\n\r\ngg1 <- ggplot(data = df1)\r\ngg1 <- gg1 + geom_point(aes(x = Procedure, y = Mean), size = 5, color = \"blue\")\r\ngg1 <- gg1 + geom_errorbar(aes(x = Procedure, y = Mean, ymin=Lower, ymax=Upper), width=.1, color = \"blue\")\r\ngg1 <- gg1 + geom_text(aes(x = Procedure, y = Lower, label = round(Lower, 2)), hjust = -1)\r\ngg1 <- gg1 + geom_text(aes(x = Procedure, y = Upper, label = round(Upper, 2)), hjust = -1)\r\ngg1 <- gg1 + geom_text(aes(x = Procedure, y = Mean, label = round(Mean, 2)), hjust = -0.5)\r\ngg1 <- gg1 + labs(x = \"Procedure\", y = \"Mean\")\r\ngg1 <- gg1 + labs(title = \"Chart Showing Mean With Upper and Lower Confidence Intervals at 90%\")\r\ngg1 <- gg1 + theme_classic()\r\n\r\ngg1\r\n\r\n\r\n\r\n\r\nFor the angiography, we can be 90% sure that the population mean for the wait time to the procedure falls between 17.49 and 18.51 days.\r\nFor the bypass, we can be 90% sure that the population mean for the wait time to the procedure falls between 18.29 and 19.71 days.\r\nThe confidence interval was narrower for the angiography surgery.\r\nQuestion 2\r\nA survey of 1031 adult Americans was carried out by the National Center for Public Policy. Assume that the sample is representative of adult Americans. Among those surveyed, 567 believed that college education is essential for success.\r\nFind the point estimate, p, of the proportion of all adult Americans who believe that a college education is essential for success.\r\nConstruct and interpret a 95% confidence interval for p.\r\nAnswer 2\r\nTo construct the 95% confidence interval, I began by calculating the point sample estimate of the population proportion:\r\n\r\n\r\n#Calculate the point sample estimate of the population proportion using (p = x/n)\r\n\r\nx2 = 567 #affirmative response size\r\nn2 = 1031 #sample size - survey participants\r\n\r\np2 <- x2/n2\r\np2\r\n\r\n\r\n[1] 0.5499515\r\n\r\nThis tells me that the sample proportion of those who believe a college education is essential for success is ~45%.\r\nSince np >= 5 and n(1-p) >= 5, I know that I will calculate the confidence interval of that population proportion as follows: p +/- z * square root of (p) x (1-p)/n\r\n\r\n\r\n#Calculate the confidence interval for p:\r\n\r\nerror2 <-qnorm(0.975)*sqrt(p2*(1-p2)/n2)\r\nerror2\r\n\r\n\r\n[1] 0.03036761\r\n\r\nlower2 <- p2-error2\r\nupper2 <- p2+error2\r\n\r\nlower2\r\n\r\n\r\n[1] 0.5195839\r\n\r\nupper2\r\n\r\n\r\n[1] 0.5803191\r\n\r\nThis tells me that we can be 95% confident that the proportion of adult Americans who believe that a college education is essential for success lies between 51.96% and 58.03% of the population.\r\nAlternatively, using the R prop.test function, I can compare the calculation to my manual calculation and find it is the same for finding the point, but slightly different (at 4 decimal points) on the calculation of the confidence interval.\r\n\r\n\r\nprop.test(x2, n2)\r\n\r\n\r\n\r\n    1-sample proportions test with continuity correction\r\n\r\ndata:  x2 out of n2, null probability 0.5\r\nX-squared = 10.091, df = 1, p-value = 0.00149\r\nalternative hypothesis: true p is not equal to 0.5\r\n95 percent confidence interval:\r\n 0.5189682 0.5805580\r\nsample estimates:\r\n        p \r\n0.5499515 \r\n\r\nQuestion 3\r\nSuppose that the financial aid office of UMass Amherst seeks to estimate the mean cost of textbooks per quarter for students. The estimate will be useful if it is within $5 of the true population mean (i.e. they want the confidence interval to have a length of $10 or less). The financial aid office is pretty sure that the amount spent on books varies widely, with most values between $30 and $200. They think that the population standard deviation is about a quarter of this range.\r\nAssuming the significance level to be 5%, what should be the size of the sample?\r\nAnswer 3\r\nI will start by taking the information given and calculating the variables I need to know.\r\nIf the aid office believes the amount spent on books is between $30 and $200, I have a range of $170 to consider.\r\nI want to be 95% confident that the interval estimate contains the population mean, so my z = 1.96.\r\nI also know that the margin of error should be no more than +/- $5 on each end of the estimate, so my margin of error = 5\r\n\r\n\r\nerror3 <- (5)\r\n\r\n#I need to calculate the standard deviation at the given estimate that it is a quarter of the range:\r\n\r\nsd3 <- 170*0.25 #range * 25%\r\nsd3 #standard deviation = 42.5\r\n\r\n\r\n[1] 42.5\r\n\r\n#Now I can calculate the sample size with the formula n=(zσ/M)2.\r\n\r\nss3 <- ((1.96*sd3)/error3)^2\r\nss3 #sample size\r\n\r\n\r\n[1] 277.5556\r\n\r\nUsing these calculations, I can estimate that the financial aid office will need to use a sample size of 278 people.\r\nQuestion 4\r\nAccording to a union agreement, the mean income for all senior-level workers in a large service company equals $500 per week. A representative of a women’s group decides to analyze whether the mean income μ for female employees matches this norm. For a random sample of nine female employees, ȳ = $410 and s = 90.\r\nA. Test whether the mean income of female employees differs from $500 per week. Include assumptions, hypotheses, test statistic, and P-value. Interpret the result.\r\nB. Report the P-value for Ha : μ < 500. Interpret.\r\nC. Report and interpret the P-value for H a: μ > 500.\r\n(Hint: The P-values for the two possible one-sided tests must sum to 1.)\r\nAnswer 4\r\nA. I will start by taking the information given and determining my hypotheses:\r\nH0: The mean weekly earnings for the population of women at the company is μ=$500#\r\nHa: The mean weekly earnings for the population of women at the company is μ≠$500\r\nI cannot assume that the population distribution is normal as I have a low sample size of 9 and it is not stated it is a random sample, but a representative sample.\r\nMy other assumptions are:\r\npopulation mean (mu4) = 500\r\nsample size (n4) = 9\r\nsample mean (xbar4) = 410\r\nsample standard deviation (sd4) = 90\r\nI also need to make a decision about using a significance level of 5%.\r\nI will use the test statistic formula to find the t-value: [t = (x̄) - (μ) / (sd/sqrt(n)]\r\n\r\n\r\na4 <- 500\r\nn4 <- 9\r\nxbar4 <- 410\r\nsd4 <- 90\r\n\r\n#Test statistic:\r\n\r\nt4 <-(xbar4-a4)/(sd4/sqrt(n4))\r\n\r\nt4\r\n\r\n\r\n[1] -3\r\n\r\nGiven that my test statistic = (-3), I can determine the p-value is .00135*2 (to get the sum of both tail probabilities) or 0.0027.\r\nSince my confidence level is 0.05 and my p-value of 0.0027 < 0.05, I can reject the null hypothesis that the mean weekly earnings for the population of women at the company is μ=$500.\r\n\r\n\r\n#Then I take the t-statistic result (-3) and the degrees of freedom by taking \"sample size - 1\" or (\"9\" - 1) = 8.\r\n\r\npval4a <- pt(-3, 8)\r\n\r\npval4a\r\n\r\n\r\n[1] 0.008535841\r\n\r\nB. For the alternative hypothesis Ha: μ < 500:\r\n\r\n\r\npval4b <- pt(-3, 8, lower.tail=FALSE)\r\n\r\npval4b\r\n\r\n\r\n[1] 0.9914642\r\n\r\nPer the hint, I can confirm that these are logical answers by adding the two probabilities together and confirming they equal 1:\r\n\r\n\r\npval4a+pval4b\r\n\r\n\r\n[1] 1\r\n\r\nQuestion 5\r\nJones and Smith separately conduct studies to test H0: μ = 500 against Ha : μ ≠ 500, each with n = 1000.\r\nJones gets ȳ = 519.5, with se = 10.0. Smith gets ȳ = 519.7.\r\nA. Show that t = 1.95 and P-value = 0.051 for Jones. Show that t = 1.97 and P-value = 0.049 for Smith.\r\nB. Using α = 0.05, for each study indicate whether the result is “statistically significant.”\r\nC. Using this example, explain the misleading aspects of reporting the result of a test as “P ≤ 0.05” versus “P > 0.05,” or as “reject H0” versus “Do not reject H0 ,” without reporting the actual P-value.\r\nAnswer 5\r\nA. To show the t-scores, I will use the test statistic [t = (ybar) - (μ) / (se)] given the results for each:\r\n\r\n\r\n#Test statistic for Jones:\r\n\r\nybar5a <- 519.5\r\nn5 <- 1000\r\na5 <- 500\r\nse5 <- 10.0\r\n\r\nt5a <-(ybar5a-a5)/(se5)\r\n\r\nt5a\r\n\r\n\r\n[1] 1.95\r\n\r\n#Test statistic for Smith:\r\n\r\nybar5b <- 519.7\r\nn5 <- 1000\r\na5 <- 500\r\nse5 <- 10.0\r\n\r\nt5b <-(ybar5b-a5)/(se5)\r\n\r\nt5b\r\n\r\n\r\n[1] 1.97\r\n\r\nTo show the p-values, I will use the pt() function and use the t-statistic results from each of the tests and the degrees of freedom by taking “sample size - 1” or (“100” - 1) = 999. I will need to multiply each result by 2 to account for the probabilities in each tail of the normal distribution.\r\n\r\n\r\n#For Jones' results:\r\n\r\npval5a <- pt(1.95, 999, lower.tail = FALSE) * 2\r\n\r\npval5a\r\n\r\n\r\n[1] 0.05145555\r\n\r\n#For Smith's results:\r\n\r\npval5b <- pt(1.97, 999, lower.tail = FALSE) * 2\r\n\r\npval5b\r\n\r\n\r\n[1] 0.04911426\r\n\r\nB. To use α = 0.05 and look at each result and whether it is “statistically significant”, I can compare the p-values directly to the confidence level of 0.5. Jones’ results gave a p-value of 0.5145, which is just over the threshold of the confidence level given of 0.5. Smith’s results gave a p-value of 0.4911, which is just under the threshold of the confidence level given of 0.5.\r\nHypothesis tests tell us that if the p-value < α, we reject H0 and if p-value ≥ α, we do not reject H0. Given this general statistical guidance, only Smith’s results would be considered “statistically significant”.\r\nC. The results in this example could be very misleading if only whether the results were reported as simply “rejecting” or “not rejecting” H0 or being “statistically significant” or not because that is leaving out vital information on how close the results were to the confidence level used. If the actual p-values were reported instead, they would reflect how marginally “significant” the results really were. The confidence is an artificial threshold that is subjectively applied, and in this case, the results were close enough that they should not be statistically reported as significally different. This is why we need to be sure we report the full p-values and confidence intervals.\r\nQuestion 6\r\nAre the taxes on gasoline very high in the United States? According to the American Petroleum Institute, the per gallon federal tax that was levied on gasoline was 18.4 cents per gallon. However, state and local taxes vary over the same period. The sample data of gasoline taxes for 18 large cities is given below in the variable called gas_taxes.\r\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\r\nIs there enough evidence to conclude at a 95% confidence level that the average tax per gallon of gas in the US in 2005 was less than 45 cents? Explain.\r\nAnswer\r\nTo answer whether there is enough evidence to conclude at a 95% confidence level that the average tax per gallon of gas in the US in 2005 was less than 45 cents, we need to use a left-tailed t-test. We will use the sample data in the variable “gas_taxes” in the t.test function. We know that the t.test() function uses the 95% confidence interval as a default, but it also uses a two-sided test as the default, so we need to provide the alternative argument “less”, indicating a left-sided test.\r\n\r\n\r\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\r\n\r\nt.test(gas_taxes, alternative = \"less\")\r\n\r\n\r\n\r\n    One Sample t-test\r\n\r\ndata:  gas_taxes\r\nt = 18.625, df = 17, p-value = 1\r\nalternative hypothesis: true mean is less than 0\r\n95 percent confidence interval:\r\n     -Inf 44.67946\r\nsample estimates:\r\nmean of x \r\n 40.86278 \r\n\r\nThis t-test gives us a confidence interval of [inf - 44.67946]. Since the confidence interval includes amounts that are all less than 45 cents, we have enough evidence to conclude that, at that confidence level, the average tax was less than 45 cents.\r\n\r\n\r\n\r\n",
    "preview": "posts/httpsrpubscomkbec864954/distill-preview.png",
    "last_modified": "2022-02-24T15:25:24-05:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/httpsrpubscomowenvespa865400/",
    "title": "Statistical Inference II & Comparing two means",
    "description": "DACSS 603 Homework 1",
    "author": [
      {
        "name": "Rhowena Vespa",
        "url": {}
      }
    ],
    "date": "2022-02-24",
    "categories": [],
    "contents": "\r\nQuestion 1\r\nThe time between the date a patient was recommended for heart surgery and the surgery date for cardiac patients in Ontario was collected by the Cardiac Care Network (“Wait Times Data Guide,” Ministry of Health and Long-Term Care, Ontario, Canada, 2006). The sample mean and sample standard deviation for wait times (in days) of patients for two cardiac procedures are given in the accompanying table. Assume that the sample is representative of the Ontario population\r\n\r\n\r\nlibrary(distill)\r\nlibrary(dplyr)\r\nlibrary(tidyverse)\r\nProblem1<- read.csv('homework1_prob1.csv',TRUE,',',na.strings = \"N/A\")\r\nProblem1\r\n\r\n\r\n  ï..Surgical.Procedure Sample.Size Mean.Wait.Time Standard.Deviation\r\n1                Bypass         539             19                 10\r\n2           Angiography         847             18                  9\r\n\r\nConstruct the 90% confidence interval to estimate the actual mean wait time for each of the two procedures. Is the confidence interval narrower for angiography or bypass surgery?\r\nFor Bypass group:\r\n\r\n\r\n#Our values are: \r\nBypass.mean<- 19\r\nBypass.sd<-10\r\nBypass.n<-539\r\nBypass.se <- Bypass.sd/sqrt(Bypass.n) #This is standard error of the mean\r\n\r\n\r\n\r\n\r\n\r\n#Find the t.score for CI 90%\r\nalpha = 0.1\r\ndegrees.freedom = Bypass.n - 1\r\nBypass.t.score = qt(p=alpha/2, df=degrees.freedom,lower.tail=F)\r\nprint(Bypass.t.score)\r\n\r\n\r\n[1] 1.647691\r\n\r\n\r\n\r\n#Calculate margin of error\r\nBypass.margin.error <- Bypass.t.score * Bypass.se\r\nprint(Bypass.margin.error)\r\n\r\n\r\n[1] 0.7097107\r\n\r\n\r\n\r\n#Calculate the 90% confidence interval for Bypass\r\n  lower.bound <- Bypass.mean - Bypass.margin.error\r\n  upper.bound <- Bypass.mean + Bypass.margin.error\r\n  print(c(lower.bound,upper.bound))\r\n\r\n\r\n[1] 18.29029 19.70971\r\n\r\nFor Angiography group:\r\n\r\n\r\n#Our values are: \r\nAngio.mean<- 18\r\nAngio.sd<-9\r\nAngio.n<-847\r\nAngio.se <- Angio.sd/sqrt(Angio.n) #This is standard error of the mean\r\n\r\n\r\n\r\n\r\n\r\n#Find the t.score for CI 90%\r\nalpha = 0.1\r\ndegrees.freedomA = Angio.n - 1\r\nAngio.t.score = qt(p=alpha/2, df=degrees.freedomA,lower.tail=F)\r\nprint(Angio.t.score)\r\n\r\n\r\n[1] 1.646657\r\n\r\n\r\n\r\n#Calculate margin of error\r\nAngio.margin.error <- Angio.t.score * Angio.se\r\nprint(Angio.margin.error)\r\n\r\n\r\n[1] 0.5092182\r\n\r\n\r\n\r\n#Calculate the 90% confidence interval for Angiography\r\n  lower.boundA <- Angio.mean - Angio.margin.error\r\n  upper.boundA <- Angio.mean + Angio.margin.error\r\n  print(c(lower.boundA,upper.boundA))\r\n\r\n\r\n[1] 17.49078 18.50922\r\n\r\nAnswer for Question #1-Is the confidence interval narrower for angiography or bypass surgery?:\r\nAngiography patients, at 90% confidence interval, had between (17.49078 and 18.50922) wait time in days which is NARROWER compared to the bypass patients wait time which is between (18.29029 and 19.70971)\r\nQuestion 2\r\nA survey of 1031 adult Americans was carried out by the National Center for Public Policy. Assume that the sample is representative of adult Americans. Among those surveyed, 567 believed that college education is essential for success. Find the point estimate, p, of the proportion of all adult Americans who believe that a college education is essential for success. Construct and interpret a 95% confidence interval for p.\r\n\r\n\r\n#Point Estimate, p\r\nn<-1031\r\nk<-567\r\np<-k/n\r\np\r\n\r\n\r\n[1] 0.5499515\r\n\r\nInterpretation of point estimate p:\r\nThe sample proportion of adult Americans who believed that college education is essential for success is 0.5499515 or 55%. This represents our point estimate for the population (adult Americans) proportion.\r\n\r\n\r\n#Construct 95% confidence interval for p\r\n\r\nS.margin <- qnorm(0.975)*sqrt(p*(1-p)/n)  #calculate margin of error\r\n  S.lower.bound <- p-S.margin\r\n  S.upper.bound <- p+S.margin\r\n  print(c(S.lower.bound,S.upper.bound))\r\n\r\n\r\n[1] 0.5195839 0.5803191\r\n\r\nInterpretation of 95% confidence interval for p:\r\nThe 95% confidence interval for the population (adult Americans) proportion is [0.5195839 0.5803191]. This means between 51.9% to 58% of adult Americans believed that college education is essential for success.\r\nQuestion 3\r\nSuppose that the financial aid office of UMass Amherst seeks to estimate the mean cost of textbooks per quarter for students. The estimate will be useful if it is within $5 of the true population mean (i.e. they want the confidence interval to have a length of $10 or less). The financial aid office is pretty sure that the amount spent on books varies widely, with most values between $30 and $200. They think that the population standard deviation is about a quarter of this range. Assuming the significance level to be 5%, what should be the size of the sample?\r\nn= square of ((Z 0.05/2 * sd of pop)/within $5 of true pop mean\r\n\r\n\r\nsd_of_pop =(200-30)/4 #This is standard deviation of population\r\nsd_of_pop\r\n\r\n\r\n[1] 42.5\r\n\r\nsample_size=((1.96*sd_of_pop)/5)**2  #Using Z score 1.96 for significance level 5%\r\nsample_size\r\n\r\n\r\n[1] 277.5556\r\n\r\nANSWER: Sample size needed to achieve significance level of 95% is 278.\r\nQuestion 4\r\n(Exercise 6.7, Chapter 6 of SMSS, Agresti 2018) According to a union agreement, the mean income for all senior-level workers in a large service company equals $500 per week. A representative of a women’s group decides to analyze whether the mean income μ for female employees matches this norm. For a random sample of nine female employees, ȳ = $410 and s = 90.\r\nTest whether the mean income of female employees differs from $500 per week. Include assumptions, hypotheses, test statistic, and P-value. Interpret the result.\r\nassumption: seed set at 123, using rnorm\r\nHo mu=500\r\nHa mu≠500\r\nMean y_hat =410\r\nsd = 90\r\nn =9\r\n\r\n\r\nset.seed(123)\r\nMean_income <- c(rnorm(9, mean = 410, sd = 90)) \r\nMean_income\r\n\r\n\r\n[1] 359.5572 389.2840 550.2837 416.3458 421.6359 564.3558 451.4825\r\n[8] 296.1445 348.1832\r\n\r\n\r\n\r\nt.test(Mean_income, mu = 500) # Ho: mu=500\r\n\r\n\r\n\r\n    One Sample t-test\r\n\r\ndata:  Mean_income\r\nt = -2.6213, df = 8, p-value = 0.03059\r\nalternative hypothesis: true mean is not equal to 500\r\n95 percent confidence interval:\r\n 353.2313 490.6071\r\nsample estimates:\r\nmean of x \r\n 421.9192 \r\n\r\nInterpretation of one sample t-test result:\r\nAt p-value 0.03, considered statistically significant, we reject the null hypothesis. We can conclude that mean income for female employees is not 500.\r\nReport the P-value for Ha : μ < 500. Interpret.\r\n\r\n\r\nt.test(Mean_income, mu=500, alternative = 'less') # Ha: mu<500\r\n\r\n\r\n\r\n    One Sample t-test\r\n\r\ndata:  Mean_income\r\nt = -2.6213, df = 8, p-value = 0.01529\r\nalternative hypothesis: true mean is less than 500\r\n95 percent confidence interval:\r\n     -Inf 477.3087\r\nsample estimates:\r\nmean of x \r\n 421.9192 \r\n\r\nInterpretation of Ha : μ < 500:\r\nAt p-value 0.01529, considered statistically significant, we reject the null hypothesis and accept the alternative hypothesis. We can conclude that mean income for female employees is less than 500.\r\nReport and interpret the P-value for Ha: μ > 500.\r\n\r\n\r\nt.test(Mean_income, mu=500, alternative = \"greater\") # Ha: mu>500\r\n\r\n\r\n\r\n    One Sample t-test\r\n\r\ndata:  Mean_income\r\nt = -2.6213, df = 8, p-value = 0.9847\r\nalternative hypothesis: true mean is greater than 500\r\n95 percent confidence interval:\r\n 366.5297      Inf\r\nsample estimates:\r\nmean of x \r\n 421.9192 \r\n\r\nInterpretation of Ha: μ > 500:\r\nAt p-value 0.9847, considered statistically NOT significant, we fail to reject the null hypothesis. We can reject the alternative hypothesis that mean income for female employees is greater than 500.\r\n(Hint: The P-values for the two possible one-sided tests must sum to 1.)\r\n\r\n\r\ntotal_p_value=0.9847+0.01529\r\nprint(c(\"Total p-values for the two possible one-sided tests is\",total_p_value))\r\n\r\n\r\n[1] \"Total p-values for the two possible one-sided tests is\"\r\n[2] \"0.99999\"                                               \r\n\r\nQuestion 5\r\n(Exercise 6.23, Chapter 6 of SMSS, Agresti 2018) Jones and Smith separately conduct studies to test H0: μ = 500 against Ha : μ ≠ 500, each with n = 1000. Jones gets ȳ = 519.5, with se = 10.0. Smith gets ȳ = 519.7, with se = 10.0.\r\n\r\n\r\ntab <- matrix(c(519.5, 519.7, 10, 10), ncol=2, byrow=TRUE)\r\ncolnames(tab) <- c(\"Jones\",\"Smith\")\r\nrownames(tab) <- c(\"y_hat\",\"se\")\r\ntab <- as.table(tab)\r\nprint(tab)\r\n\r\n\r\n      Jones Smith\r\ny_hat 519.5 519.7\r\nse     10.0  10.0\r\n\r\nCalculate t and p-value\r\nt.stat <- (y_hat - mu)/sample.se\r\np.value = pt(q=abs(t.stat), df=degrees.freedom,lower.tail=F) 2 *\r\nShow that t = 1.95 and P-value = 0.051 for Jones.\r\n\r\n\r\nt.stat <- (519.5 - 500)/10\r\nprint(c(\"t.stat\",t.stat))\r\n\r\n\r\n[1] \"t.stat\" \"1.95\"  \r\n\r\n\r\n\r\ndegrees.freedom = 1000 - 1\r\np.value = pt(q=abs(t.stat), df=degrees.freedom,lower.tail=F) * 2\r\nprint(c(\"Two-sided p-value\",p.value))\r\n\r\n\r\n[1] \"Two-sided p-value\"  \"0.0514555476459477\"\r\n\r\nShow that t = 1.97 and P-value = 0.049 for Smith.\r\n\r\n\r\nSmith.t.stat <- (519.7 - 500)/10\r\nprint(c(\"t.stat\",Smith.t.stat))\r\n\r\n\r\n[1] \"t.stat\" \"1.97\"  \r\n\r\n\r\n\r\ndegrees.freedom = 1000 - 1\r\nSmith.p.value = pt(q=abs(Smith.t.stat), df=degrees.freedom,lower.tail=F) * 2\r\nprint(c(\"Two-sided p-value\",Smith.p.value))\r\n\r\n\r\n[1] \"Two-sided p-value\"  \"0.0491142565416521\"\r\n\r\nUsing α = 0.05, for each study indicate whether the result is “statistically significant.”\r\n  α = 0.05\r\n  H0: μ = 500\r\n  Ha : μ ≠ 500\r\n  \r\nFor Jones Data: Since p=0.051, we fail to reject the null hypothesis (H0: μ = 500) and reject the alternative hypothesis (Ha : μ ≠ 500). The p-value is NOT statistically significant.\r\nFor Smith Data: Since p=0.049, we reject the null hypothesis (H0: μ = 500) and accept the alternative hypothesis. We conclude that μ ≠ 500. P-value is statistically significant.\r\nUsing this example, explain the misleading aspects of reporting the result of a test as “P ≤ 0.05” versus “P > 0.05,” or as “reject H0” versus “Do not reject H0 ,” without reporting the actual P-value.\r\n\r\n\r\nprint(tab)\r\n\r\n\r\n      Jones Smith\r\ny_hat 519.5 519.7\r\nse     10.0  10.0\r\n\r\n#α = 0.05\r\n#H0: μ = 500\r\n#Ha : μ ≠ 500\r\n#Zc= 1.96\r\n\r\n\r\n\r\nCalculate z-score= (y_hat -μ )/ se\r\n\r\n\r\nJones.z <- (519.5-500)/10\r\nJones.z\r\n\r\n\r\n[1] 1.95\r\n\r\n\r\n\r\nSmith.z <- (519.7-500)/10\r\nSmith.z\r\n\r\n\r\n[1] 1.97\r\n\r\nInterpretation without reporting the actual P-value:\r\nReporting the result of a test using p-values could be misleading. We can avoid this by using z-score to report the results, using z-score =1.96 as the same 95% confidence level. Jones z-score of 1.95 < 1.96 means we fail to reject the null hypothesis (H0: μ = 500) and reject the alternative hypothesis (Ha : μ ≠ 500). Smith z-score of 1.97 > 1.96 we reject the null hypothesis (H0: μ = 500) and accept the alternative hypothesis(Ha : μ ≠ 500).\r\nQuestion 6\r\nAre the taxes on gasoline very high in the United States? According to the American Petroleum Institute, the per gallon federal tax that was levied on gasoline was 18.4 cents per gallon. However, state and local taxes vary over the same period. The sample data of gasoline taxes for 18 large cities is given below in the variable called gas_taxes.\r\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\r\nIs there enough evidence to conclude at a 95% confidence level that the average tax per gallon of gas in the US in 2005 was less than 45 cents? Explain.\r\n#H0: μ = 45\r\n#Ha : μ ≠ 45, specifically μ < 45 assuming one-sided using argument alternative= \"lesser\"\r\n\r\n\r\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\r\nt.test(gas_taxes,mu=45, alternative = 'less')\r\n\r\n\r\n\r\n    One Sample t-test\r\n\r\ndata:  gas_taxes\r\nt = -1.8857, df = 17, p-value = 0.03827\r\nalternative hypothesis: true mean is less than 45\r\n95 percent confidence interval:\r\n     -Inf 44.67946\r\nsample estimates:\r\nmean of x \r\n 40.86278 \r\n\r\nInterpretation of one sample t-test:\r\nYes, there is enough evidence to conclude at a 95% confidence level that the average tax per gallon of gas in the US in 2005 was less than 45 cents. With the p-value of 0.03827 < α = 0.05, we reject the null hypothesis that μ = 45 and accept the alternative hypothesis that μ < 45 cents.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-24T15:25:10-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomrhyslong96870303/",
    "title": "Homework 1",
    "description": "Here is my submission for homework 1.",
    "author": [
      {
        "name": "Rhys Long",
        "url": {}
      }
    ],
    "date": "2022-02-24",
    "categories": [],
    "contents": "\n\n\n##QUESTION 1##\n#Sample Size\nAngiography_Sample=847\nBypass_Sample=539\n\n#Mean\nAngiography_Mean=18\nBypass_Mean=19\n\n#Standard Deviation\nAngiography_STD=9\nBypass_STD=10\n\n#Standard Error\nAngiography_SE=Angiography_STD/sqrt(Angiography_Sample)\nBypass_SE=Bypass_STD/sqrt(Bypass_Sample)\n\n#Tail Area\nConfidence_Level=0.9\nTail_Area=(1-Confidence_Level)/2\n\n#T Scores\nAngiography_T=qt(p=0.95,df=(Angiography_Sample-1))\nBypass_T=qt(p=0.95,df=(Bypass_DF=Bypass_Sample-1))\n\n#Margin Of Error\nAngiography_MOE=Angiography_T*Angiography_SE\nBypass_MOE=Bypass_T*Bypass_SE\n\n#Angiography Confidence Interval\nLower_Angiography=Angiography_Mean-Angiography_MOE\nUpper_Angiography=Angiography_Mean+Angiography_MOE\nAngiography_CI=c(Lower_Angiography, Upper_Angiography)\nc(\"Angiography Confidence Interval:\", Angiography_CI)\n\n\n[1] \"Angiography Confidence Interval:\"\n[2] \"17.4907818376895\"                \n[3] \"18.5092181623105\"                \n\n#Bypass Confidence Interval\nLower_Bypass=Bypass_Mean-Bypass_MOE\nUpper_Bypass=Bypass_Mean+Bypass_MOE\nBypass_CI=c(Lower_Bypass, Upper_Bypass)\nc(\"Bypass Confidence Interval:\", Bypass_CI)\n\n\n[1] \"Bypass Confidence Interval:\" \"18.2902893200424\"           \n[3] \"19.7097106799576\"           \n\n#Comparing The Confidence Interval Widths\nAngiography_Width=Upper_Angiography-Lower_Angiography\nBypass_Width=Upper_Bypass-Lower_Bypass\nc(\"Angiography Confidence Interval Width:\", Angiography_Width)\n\n\n[1] \"Angiography Confidence Interval Width:\"\n[2] \"1.01843632462099\"                      \n\nc(\"Bypass Confidence Interval Width:\", Bypass_Width)\n\n\n[1] \"Bypass Confidence Interval Width:\"\n[2] \"1.41942135991513\"                 \n\nThe actual mean wait for angiographies is around 17.4907818376895 to 18.5092181623105 days and the actual mean wait for bypasses is 18.2902893200424 to 19.7097106799576. To find out the confidence interval for both procedures, I first found the standard error, since I already knew the sample sizes and standard deviations. From there I determined the t scores for both procedures. Even though the samples for both procedures exceeded 30, I used a t score instead of a z score because the sample standard deviations were different and the population standard deviation was unspecified. In order to figure out the correct t score, I used qt() with p set to 0.95 because each tail has an area of 0.05 when the confidence level is 90%. Once I had the t scores, I determined the margin of error and confidence intervals. To figure out which procedure has the narrower confidence interval, I subtracted the upper bound value by the lower bound value for each respective procedure. The angiography has a narrower confidence interval than the bypass.\n\n\n##QUESTION 2##\n#Sample Size\nSample=1031\n\n#Pro-College vs Anti-College Proportions\nPro_College=567/Sample\nAnti_College=1-Pro_College\n\n#Z Score, Standard Error, And Margin Of Error\nZ=1.96\nSE=sqrt((Pro_College*Anti_College)/Sample)\nMOE=Z*SE\n\n#Confidence Interval\nLower_Bound=Pro_College-MOE\nUpper_Bound=Pro_College+MOE\nConfidence_Interval <- c(Lower_Bound,Upper_Bound)\nConfidence_Interval \n\n\n[1] 0.5195833 0.5803197\n\nThe 95% confidence interval for p is 51.95833-58.03197%. Based on the fact that 567/1031 adults in the survey believed that college education is essential for success, I was able to conclude that 464/1031 adults in the survey disagreed with that mindset. From there, I used sqrt((Pro College Proportion*Anti College Proportion)/Sample Size) to find the standard error since I don’t need a standard deviation to find the standard error of a proportion. Next, I multiplied the standard error by 1.96, otherwise known as the 95% confidence level z score, to find the margin of error. The reason why I used a z score instead of a t score is because the instructions specify that I should assume that the results are reflective of the entire population. Finally, I subtracted the margin of error from the pro-college proportion to find the lower bound confidence interval limit and I added the margin of error to the pro-college proportion to find the upper bound confidence interval limit.\n\n\n##QUESTION 3##\n#Determining Standard Deviation\nRange=200-30\nSTD=Range/4\nSTD\n\n\n[1] 42.5\n\n#Determnining Margin Of Error And Z Score\nM=5\nZ=1.96\n\n#Determnining Sample Size\nZ_Div_M=Z/M\nSize=(STD*STD)*(Z_Div_M*Z_Div_M)\nSize\n\n\n[1] 277.5556\n\n#Checking Work\nM_Check=Z*(STD/sqrt(278))\nM_Check\n\n\n[1] 4.996002\n\nThe ideal sample size for an experiment with the specifications of question 3 is at least 278. Before figuring out the ideal sample size, I had to find the standard deviation and the margin of error. Based on the question 3 instructions, I could conclude that the standard deviation is 42.5 the spending range is 170 (200-30) and the population standard deviation is the spending range divided by 4. I could also conclude that the margin of error is 5 because the confidence interval length should be 10 dollars or less and the margin of error is half the confidence interval length. In order to determine the ideal sample size, I first divided the margin of error by 1.96, otherwise known as the 5% significance level z score. I used a z score instead of a t score because the population standard deviation is known. From there, I multiplied the standard deviation squared by (Margin of Error/Z Score) squared and got 277.5556, which can be rounded up to 278. To check my work, I used the M=Z*(STD/sqrt(N)).\n\n\n##QUESTION 4##\n#Mean And Standard Deviation\nPopulation_Mean=500\nWomen=9\nWoman_Mean=410\nSTD=90\nSE=STD/sqrt(Women)\n\n#T-Score\nT_Score=(Woman_Mean-Population_Mean)/SE\nT_Score\n\n\n[1] -3\n\n#A: Find Two Tail P Value\nTwo_Tail_P=2*pt(q=T_Score,df=(Women-1))\nTwo_Tail_P\n\n\n[1] 0.01707168\n\n#B: Left Tail P Value\nLeft_Tail_P=pt(q=T_Score,df=(Women-1),lower.tail=TRUE)\nLeft_Tail_P\n\n\n[1] 0.008535841\n\n#C: Right Tail P Value\nRight_Tail_P=pt(q=T_Score,df=(Women-1),lower.tail=FALSE)\nRight_Tail_P\n\n\n[1] 0.9914642\n\nFor question 4 part A, I concluded that there is a statistically significant difference between the income of women and the mean income. The null hypothesis is that the income of women is equal to that of everyone else. The alternative hypothesis is that hypothesis is that the income of women isn’t equal to that of everyone else. In order to figure out whether there is a statistically significant difference, I had to figure out the T-Score. The T-Score I got from dividing the difference between the women’s mean and the population mean by the standard error is -3. Even though I know that a T-Score of -3 is probably reflective of statistically significant differences, I still determined the two tailed p value by using 2*pt(q=T_Score,df=(Women-1)). I multiplied pt(q=T_Score,df=(Women-1)) by 2 because the pt() function is used for determining 1 tail p values and I was interested in finding the 2 tail p value. The p value I got was p=0.01707168, which is considered statistically significant when using the p<0.05 significance level. To find the left tail P value, I used pt(q=T_Score,df=(Amount of Women-1),lower.tail=TRUE) and I got p=0.008535841, which supports the alternative hypothesis of mu<500 to a highly significant extent. To find the right tail P value, I used Right_Tail_P=pt(q=T_Score,df=(Women-1),lower.tail=FALSE) and I got 0.9914642, which is indicative of mu>500 being false.\n\n\n##QUESTION 5##\n#Null Mean And Sample Size\nNull_Mean=500\nN=1000\n\n#Jones Mean And Standard Error\nJones_Mean=519.5\nJones_SE=10.0\n\n#Jones T\nJones_T=(Jones_Mean-Null_Mean)/Jones_SE\nJones_T\n\n\n[1] 1.95\n\n#Jones P\nJones_P=2*pt(q=Jones_T,df=(N-1),lower.tail=FALSE)\nJones_P\n\n\n[1] 0.05145555\n\n#Smith Mean And Standard Error\nSmith_Mean=519.7\nSmith_SE=10.0\n\n#Smith T\nSmith_T=(Smith_Mean-Null_Mean)/Jones_SE\nSmith_T\n\n\n[1] 1.97\n\n#Smith P\nSmith_P=2*pt(q=Smith_T,df=(N-1),lower.tail=FALSE)\nSmith_P\n\n\n[1] 0.04911426\n\nAccording to alpha=0.05, Smith’s results are statistically significant, but Jones’s results are not. The reason why neglecting to report the p value is so misleading when reporting results is because there is no indication of how close the results are to being statistically significant. Jones’s p value of 0.05145555 comes extremely close to being statistically significant when the significance level is set to p<=0.05 and if the significance level was set to p<=0.1, Jones’s results would undoubtedly be classified as statistically significant. If I say Jones’s results are not statistically significant with p<=0.05 and that I can’t reject the null hypothesis, nobody will know that Jones’s results come extremely close to being statistically significance and that could lead to type 2 errors.\n\n\n##QUESTION 6##\n#Dataset\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\n#T-Test\nt.test(gas_taxes, mu=45, alternative=\"less\")\n\n\n\n    One Sample t-test\n\ndata:  gas_taxes\nt = -1.8857, df = 17, p-value = 0.03827\nalternative hypothesis: true mean is less than 45\n95 percent confidence interval:\n     -Inf 44.67946\nsample estimates:\nmean of x \n 40.86278 \n\nEven though the sample size is only 18, there is enough evidence to conclude that the gas prices in 2005 were less than 45 cents with a 95% confidence interval. Given that the data is provided, I was able to use the t test function to figure out the answer. In this context, the null hypothesis is that the average tax per gallon is equal to 45 cents, so I set mu to mu=45. For the alternative= component, I used alternative=“less” because the alternative hypothesis is that the true mean of the gas prices is less than 45 cents. When I ran the t-test, I got a p value of 0.03827, which is considered statistically significant because a 95% confidence interval calls for a p value that is less than or equal to 0.05.\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-24T15:25:35-05:00",
    "input_file": {}
  },
  {
    "path": "posts/welcome/",
    "title": "Welcome to DACSS 601",
    "description": "Welcome to DACSS 603! We hope you enjoy the class!",
    "author": [
      {
        "name": "Omer Yalcin",
        "url": "http://umass.edu/sbs/dacss"
      }
    ],
    "date": "2022-02-24",
    "categories": [
      "welcome"
    ],
    "contents": "\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-24T15:14:40-05:00",
    "input_file": {}
  }
]
