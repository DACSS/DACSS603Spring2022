[
  {
    "path": "posts/603-homework-1/",
    "title": "603, Homework 1",
    "description": "First homework assignment for DACSS 603",
    "author": [
      {
        "name": "Joe Davis",
        "url": {}
      }
    ],
    "date": "2022-02-27",
    "categories": [],
    "contents": "\nQuestion 1\nConstruct the 90% confidence interval to estimate the actual mean wait time for each of the two procedures. Is the confidence interval narrower for angiography or bypass surgery?\nI wanted to do this one a bit longer-form than necessary, but I also appreciate the chance to practice organizing my R code neatly while solving. I need some good repetition to build those good habits.\nFor this question I assigned all of the values in the table to objects to use in the calculations of each treatment’s t-scores, margins of error, and confidence intervals. I did a quick check of the qnorm(.95) to see if the t-scores had converged to the normal distribution given the relatively high sample sizes of each treatment. Surprisingly, to me at least, rounding at the .000 level they still had very slightly different levels both to the normal distribution and to each others’ scores.\nI know I have the standard deviations, wait time would be a continuous variable, and these samples are larger than n = 30 so I can use qnorm and the 1.645 z critical value clearing those assumptions. But, it seems like I should use the distribution with fatter tails relative to the sample size values from qt regardless if I could assume normality from the other conditions, as to err on the side of caution for analyzing and communicating medical procedure data. I have a note in my code on that point, mostly for my own reference and will solve for the normal distribution values as well. After running the calculations the practical effect would be introducing slightly more uncertainty in the mean wait time for the angiography procedure while still keeping that procedures’ interval narrower, as we’d expect, than that of the bypass procedure. Especially if this was to be used to set patient expectations on wait times, the wider range would be the option a hospital or doctor would communicate, but we do appear to be in the range where t and z distributions are becoming quite similar.\n\n\n## Means, Total N,  and SDs from full question text. B = Bypass A = Angiography\n  #mean wait times for each procedure\n  mean_b <- 19 \n  mean_a <- 18 \n  \n  #standard deviations\n  sd_b <- 10\n  sd_a <- 9\n  \n  #total N\n  n_b <- 539\n  n_a <- 847\n\n## 90% CI score finding. .90 = 1 - a and I need  a/2 for the two tails since I have no theory on why the direction of the error would be important. Did a little side exploring of the t distribution and normal distribution scores below.\n  \n\n#Rounded to 1.645 but not used for calculations. I thought it was a sufficiently large sample size that that qt and qnorm should have returned the same values at .000 rounding, but after checking those, each T rounded up differently at the 3rd digits and for medical data I would rather err on the side of caution  \n\n    #normal z score\n  z_heart <- qnorm(.95) \n  round(z_heart, digits = 3)\n\n\n[1] 1.645\n\n  #check this for t scores\nb_t <- round(qt(.95, df = n_b -1), digits = 3)\na_t <-  round(qt(.95, df = n_a -1), digits = 3)\n  \n  #print them\n  b_t\n\n\n[1] 1.648\n\n  a_t\n\n\n[1] 1.647\n\n## 90% CI standard error of mean/ margin of error\n  #Take the score multiplied by standard deviations and sqrt of Ns, t value\n  mofe_bypass <- b_t*(sd_b/sqrt(n_b))\n  mofe_angiography <- a_t*(sd_a/sqrt(n_b))\n  \n  #doing this with z 1.645\n  mofe_bypass_z <- 1.645*(sd_b/sqrt(n_b))\n  mofe_angiography_z <- 1.645*(sd_a/sqrt(n_a))\n  \n  #print the normal distribution score MoE\n  mofe_bypass_z\n\n\n[1] 0.7085517\n\n  mofe_angiography_z\n\n\n[1] 0.5087058\n\n  # Print them using t value\n  mofe_bypass\n\n\n[1] 0.7098439\n\n  mofe_angiography\n\n\n[1] 0.6384718\n\n## +/- from the data set mean for the range\n  \n  #bypass upper and lower\n  bypass_lower <- mean_b - mofe_bypass\n  bypass_upper <- mean_b + mofe_bypass\n  \n  #combine the upper and lower to list interval\n  ci_bypass <- print(c(bypass_lower, bypass_upper))\n\n\n[1] 18.29016 19.70984\n\n  #angiography upper and lower\n  angio_lower <- mean_a - mofe_angiography\n  angio_upper <- mean_a + mofe_angiography\n  \n\n  \n  #combine the upper and lower to list interval\n  ci_angiography <- print(c(angio_lower, angio_upper))\n\n\n[1] 17.36153 18.63847\n\n#Normal distribution 90% CI\n  #bypass Z\n  bypass_lower_z <- mean_b - mofe_bypass_z\n  bypass_upper_z <- mean_b + mofe_bypass_z\n  \n  ci_bypass_z <- (print(c(bypass_lower_z, bypass_upper_z)))\n\n\n[1] 18.29145 19.70855\n\n  #angiography Z\n  angiography_lower_z <- mean_a - mofe_angiography_z\n  angiography_upper_z <- mean_a + mofe_angiography_z\n  \n  ci_angiography_z <- (print(c(angiography_lower_z, angiography_upper_z)))\n\n\n[1] 17.49129 18.50871\n\nThe confidence interval is narrower for angiography, as we have a larger sample size for that procedure’s wait time and a smaller standard deviation. We would expect this as in theory as the larger sample size mean should be closer to the true population mean, and the smaller standard deviation means we have less variation to begin with. That expectation is shown in both the smaller numerator and the larger denominator produced during the margin or error calculation. For comparison on the denominators, since the standard deviations were already listed in the table: 23.2163735 for bypass and 29.1032644 for angiography. For completeness, the normal distribution CI’s are 17.4912942, 18.5087058 for angiography and 18.2914483, 19.7085517 for the bypass procedure.\nQuestion 2\nA survey of 1031 adult Americans was carried out by the National Center for Public Policy. Assume that the sample is representative of adult Americans. Among those surveyed, 567 believed that college education is essential for success. Find the point estimate, p, of the proportion of all adult Americans who believe that a college education is essential for success. Construct and interpret a 95% confidence interval for p.\nSince we are looking to construct this interval around a proportion, I used the prop.test function to construct the interval using the total sample size as the n input and the 567 raw respondents for college “being essential for success” as the success vector in the function. I decided to use this function versus hand calculating as in question 1.\n\n\nprop_coll_success <- prop.test(567, 1031, conf.level = .95)\nprop_coll_success\n\n\n\n    1-sample proportions test with continuity correction\n\ndata:  567 out of 1031, null probability 0.5\nX-squared = 10.091, df = 1, p-value = 0.00149\nalternative hypothesis: true p is not equal to 0.5\n95 percent confidence interval:\n 0.5189682 0.5805580\nsample estimates:\n        p \n0.5499515 \n\nnames(prop_coll_success)\n\n\n[1] \"statistic\"   \"parameter\"   \"p.value\"     \"estimate\"   \n[5] \"null.value\"  \"conf.int\"    \"alternative\" \"method\"     \n[9] \"data.name\"  \n\nThe point estimate from the survey data is 0.55 The 95% confidence The interval is 0.52, 0.58. This interval means that we could say we are 95% confident that the proportion of American adults who believe that “college education is essential for success” is somewhere between the lower and upper end of our confidence interval – assuming the initial survey was indeed random and representative. Representativeness (and randomness, but that’s already extremely difficult with surveying) would be especially important for this question depending on what variables were used to determine that the initial sample was representative, as beliefs around college education are increasingly subject to the impacts political polarization and thus we could be breaking some of our assumptions needed for our analysis to be accurate depending on which variables were used.\nQuestion 3\nSuppose that the financial aid office of UMass Amherst seeks to estimate the mean cost of textbooks per quarter for students. The estimate will be useful if it is within $5 of the true population mean (i.e. they want the confidence interval to have a length of $10 or less). The financial aid office is pretty sure that the amount spent on books varies widely, with most values between $30 and $200. They think that the population standard deviation is about a quarter of this range. Assuming the significance level to be 5%, what should be the size of the sample?\nFor this problem, I started off assigning all of the elements of the problem to objects as I did for the prior two. The standard deviation problem is shown in sd_books below, as 1/4 of the difference between $200 and $30. The critical z for 5% significance level is shown in finding the qnorm result for half of the alpha level. The margin of error we need to aim for is 5 dollars and that is assigned to book_moe. I assumed it would take a decent sized sample, at least larger than 30, to get within 5 dollars with that large of a standard deviation and the we would be able to randomly collect this sample, so I used the large sample size for estimating mean equation to find the sample size n. It took too long to figure out the fancy letters in Rmarkdown, so I used abbreviations for standard deviation and such, unfortunately. \\[n =  sd ^ {2} (z /  M) ^ {2}\\]\n\n\n#Assign all of the elements of the problem to objects\nsd_books <- (200-30)*.25\nsd_books\n\n\n[1] 42.5\n\nbook_z <- qnorm(.975) \nbook_z\n\n\n[1] 1.959964\n\nbook_moe <- 5\n\n# Formula for n from margin of error calculation, large sample is n = sd^2 * z a/2 / M. Calculate by hand first.\nbook_n_by_hand <- sd_books ^ 2 * (book_z / book_moe) ^ 2\n\nbook_n_by_hand\n\n\n[1] 277.5454\n\n#Use the samplingbook package to confirm.\nbook_n_package <- sample.size.mean(e = book_moe, S = sd_books, level = .95)\n\nbook_n_package\n\n\n\nsample.size.mean object: Sample size for mean estimate\nWithout finite population correction: N=Inf, precision e=5 and standard deviation S=42.5\n\nSample size needed: 278\n\nAfter finding the answer of 278 –rounded up– students in the sample by hand calculating n, I wanted to check my work using the samplingbook package and putting the same elements from the problem into the function. That answer, shown above in book_n_package matched my “hand” calculation of 278 students in the sample needed to have a mean estimate within 5 dollars of the true population mean of textbook costs.\nQuestion 4\nAccording to a union agreement, the mean income for all senior-level workers in a large service company equals $500 per week. A representative of a women’s group decides to analyze whether the mean income μ for female employees matches this norm. For a random sample of nine female employees, ȳ = $410 and s =90. \n-A)Test whether the mean income of female employees differs from $500 per week. Include assumptions, hypotheses, test statistic, and P-value. Interpret the result.\n-B) Report the P-value for Ha : μ < 500. Interpret.\n-C) Report and interpret the P-value for H a: μ > 500. (Hint: The P-values for the two possible one-sided tests must sum to 1.)\nSince this question has several follow up questions to report out, I’m going to dive right in to the code portion of the work, and I’ll have all of the narrative explanations and steps of work described there.\n\n\n#question elements assigned to objects, will use alpha = .05\n  \n  #population\n  all_union_mean <- 500\n  \n  #sample\n  women_mean <- 410\n  women_sd <- 90\n  women_n <- 9\n\n#get the test statistic t\n\n  #estimated standard error\n  women_se <- women_sd / sqrt(women_n)\n  women_se\n\n\n[1] 30\n\n  #test statistic\n  women_t <- (women_mean - all_union_mean) / women_se\n  women_t\n\n\n[1] -3\n\n#find two tail p-value, round to two digits\n  women_p <- round(2*pt(-abs(women_t), df = 8, lower.tail = FALSE ), digits = 2)\n  women_p\n\n\n[1] 1.98\n\n#p for < 500, round to two digits\n  women_lower_p <- round(pt(-abs(women_t), df = 8, lower.tail = TRUE), digits = 2)\n  women_lower_p\n\n\n[1] 0.01\n\n#p for > 500, round to two digits\n  women_greater_p <- round(pt(-abs(women_t), df = 8, lower.tail = FALSE), digits = 2)\n  women_greater_p\n\n\n[1] 0.99\n\nAssumptions: Because this is a small sample, I’m using the two-sided t-test as it is robust when the data may not clear the normality assumptions. Given the smaller sample size of the study, highly skewed data could impact one-tailed tests and the question didn’t explicitly state that they were looking higher or lower than the overall union average\nHypotheses: Null hypothesis is that the mean wage for women = 500 dollars, the same as the contract required mean for all senior workers at the union. The alternative hypothesis is that the mean wage for women =/= 500 dollars.\nTest statistic: The test statistic women_t has a value of -3. Since this is a negative value due to the sample mean being lower than the population mean, it’s important to remember that the absolute value should be used in calculating the p value.\nP value: The two-sided P value from women_t with 8 degrees of freedom equals 1.98.\nInterpreting the results: Since the two-tailed P value is lower than our pre-selected alpha level of .05 by some distance, we can reject the null hypothesis that the mean wage for women is equal to 500 dollars, and accept the alternative hypothesis that it is not equal to 500. The below data points make it seem as though it is very likely below the overall union mean, which lines up with the mean and sd data from their study. If only the very outer bounds of the deviation hits the overall mean, it seems like this all confirms that the female employee mean is < 500 dollars. I would suggest initiating the process of review, confirmation of the study, and the grievance process.\nQuestion B: The P value for the womens’ mean weekly wage being less than 500 is 0.01. This means that if our null hypothesis was true, we would have a 99% chance of getting a value below 500 for our sample mean. Being that the contract specifies an overall mean of 500 and it’s stated that this is a large company so we can assume normality through the Central Limit Theorem, we have a lot of evidence that the mean weekly wage for women is likely lower than what the contract specifies. Being that we have a small sample size it is possible for the one-tailed value to be off with highly skewed data, however. Given the rejection of the null and the one tail results here and below for greater than 500, I think the women’s group would have a strong case that their mean wage is not 500 and most likely lower than 500 dollars.\nQuestion C: The P value for the mean weekly wage for women being greater than 500 is 0.99. This means that if the null hypothesis was true, we would expect to get a mean weekly wage for women greater than the population mean wage 1% of the time. With the same small sample size caveat as above on one tailed results, this split in P values which would have us fail to reject and then reject the null hypothesis respectively, for above and below the population mean is quite extreme and would be another supporting point in the group filing a grievance.\nQuestion 5\nJones and Smith separately conduct studies to test H0: μ = 500 against Ha : μ ≠ 500, each with n = 1000. Jones gets ȳ = 519.5, with se = 10.0. Smith gets ȳ = 519. 7,with se = 10.0.\nA) Show that t = 1.95 and P-value = 0.051 for Jones. Show that t = 1.97 and P-value = 0.049 for Smith. \nB) Using α = 0.05, for each study indicate whether the result is “statistically significant.” \nC)Using this example, explain the misleading aspects of reporting the result of a test as “P ≤ 0.05” versus “P > 0.05,” or as “reject H0” versus “Do not reject H0 ,” without reporting the actual P-value.\nSame as above, I’m going to assign out the objects and then go through the solution steps below the R code chunk. The answer for question A will be in the R code chunk, while I will answer the narrative aspects of the other questions in the text below.\n\n\n#Question Elements\n  #both studies with same n\n  study_n <- 1000\n\n  #null mean = 500\n  #alt mean =/= 500\n\n  #jones study elements\n  jones_mean <- 519.5\n  jones_se <- 10.0\n\n  #smith study elements\n  smith_mean <- 519.7\n  smith_se <- 10.0\n\n\n#Solve for Smith\n  \n  #t for Smith, use two digits and it must equal 1.97\n  smith_t <- round((smith_mean - 500) / smith_se,  digits = 2)\n  smith_t #It's 1.97 like it's supposed to be,  yay!\n\n\n[1] 1.97\n\n  #P for Smith, use three digits and two-tailed \n  smith_p <- round(2 * pt(-abs(smith_t), df = 999), digits = 3)\n  smith_p # It's .049 like it's supposed to be!\n\n\n[1] 0.049\n\n#Solve for Jones\n  \n  #t for Jones, use two digits and it must equal 1.95.\n  jones_t <- round((jones_mean - 500) / jones_se, digits = 2)\n  jones_t #It's 1.95 like it's suppost to be, yay!\n\n\n[1] 1.95\n\n  #P for Jones, use three digits and it must equal .051\n  jones_p <- round(2 * pt(-abs(jones_t), df = 999), digits = 3)\n  jones_p #It's .051 like it's supposed to be!\n\n\n[1] 0.051\n\nQuestion B and C: I thought it made sense to answer these questions in one response versus splitting them up by bullet point. Technically, both studies would be “statistically significant” at the .05 level as rounding .049 and .051 to two digits would take them both to less than or equal to .05. Rounding them without disclosing that would be no good. This is also quite misleading to attribute practical significance to a difference in P values of .002 to our arbitrarily set level of significance. Practically speaking, there is no real difference in the outcomes of these studies.\nWithout rounding, only Smith’s .049 would be below the alpha level and Jones’ .051 would be above. With these fine margins, reporting only whether the null was rejected or if we failed to reject it, or even just listing the “p less than or equal to .05 or p greater than .05” statement without the raw p values included would also ascribe practical significance in difference to these two studies even though they are very nearly identical. The differences could very well be random noise and chance, and reporting out the statement alone would make it harder to asses that.\nChoosing to publish Smith’s study just because it cleared the threshold and not Jones’ as well could make it harder to see the full picture of the parameter they studied or analyze the overall random variability in the experimental findings in a meta analysis setting.\nQuestion 6\nAre the taxes on gasoline very high in the United States? According to the American Petroleum Institute, the per gallon federal tax that was levied on gasoline was 18.4 cents per gallon. However, state and local taxes vary over the same period.\nThe sample data of gasoline taxes for 18 large cities is given below in the variable called gas_taxes.\nIs there enough evidence to conclude at a 95% confidence level that the average tax per gallon of gas in the US in 2005 was less than 45 cents? Explain.\nAfter reading the question, I don’t think our initial sample was collected in a way that would allow us to be confident in a confidence interval constructed from it to look at the average price in the nation as a whole in 2005. If the federal tax is constant at 18.4, it looks like most of the variability from city to city in the sample data is driven by state and local tax levy decisions. The mean for the gas_tax data is 40.86, so over half of our mean amount comes from state and local variables that do not look to be accounted for in the sampling description as is. Most Americans in 2005 (and still today), did not live in very large cities, the amount depending of course on the exact definition of “large.”\nOur sample is only from 18 large cities in the country, and I think it’s reasonable to assume large cities have, or the very least could have, systemically different gas tax policies than other population densities. Some states could have caps or specific legislation that could impact the overall national average, and there’s not enough information about how the 18 large cities were selected or sampled to clear all of the assumptions, even if we didn’t think large cities varied from suburban, exurban or rural geographies in a way that would skew the small sample of data that we do have. Exploring bootstrapping or other approaches would also be impacted by this fact.\nNow, if I’m reading entirely too much into this set up and I should just show that I can evaluate if our mean is below a set level using a confidence interval, I’ll proceed to do that, too! To answer this question, I’ll use the psych package to get the descriptive statistics and look those over for fun and possible use to calculate by hand if the t.test result looks funny. Then I’ll use t.test(gas_tax) and look at the 95% CI range.\nIf the entire confidence interval is below 45 cents we would have enough evidence to say we think it’s 95% likely that the mean gas tax is below the 45 cent level, the equivalent of rejecting the null hypothesis and accepting the alternative hypothesis of gas taxes were likely lower than 45 cents. If the interval includes 45 and/or above that level we don’t have enough information, and would be doing the equivalent of failing to reject the null hypothesis.\n\n\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\n\n#Use describe from the psych package for overview of gas_tax data, could use the variables here to hand calculate the CI.\ngas_tax_summary <- describe(gas_taxes)\ngas_tax_summary\n\n\n   vars  n  mean   sd median trimmed  mad   min   max range  skew\nX1    1 18 40.86 9.31  41.47   41.41 9.72 18.49 54.41 35.92 -0.58\n   kurtosis   se\nX1    -0.32 2.19\n\n#Use t.test on gas_taxes to see the 95% CI\nt.test(gas_taxes)\n\n\n\n    One Sample t-test\n\ndata:  gas_taxes\nt = 18.625, df = 17, p-value = 9.555e-13\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 36.23386 45.49169\nsample estimates:\nmean of x \n 40.86278 \n\nThe 95% interval does contain 45 cents, so we cannot say that we have enough evidence at this confidence level and interval to do the equivalent of rejecting the null hypothesis. Since the null value is at the very very top of the interval, and putting aside the other issues with the sample to begin with, it seems like the sort of result where we could say in practice it was likely lower than 45 cents. Since gas taxes and prices go to the third digit at the pump, our result would have a maximum 95% CI level “at the pump” reading of .455. It feels safe to describe in actual practice with that interval that we’re confident it was 45 cents or lower, even if we’d need a bit more data to say it in specific statistical terms.\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-27T23:53:41-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httprpubscomemersonflemi870425/",
    "title": "DACSS 603 HW 1",
    "description": "The following document contains my first homework assignment.",
    "author": [
      {
        "name": "Emerson Fleming",
        "url": null
      }
    ],
    "date": "2022-02-27",
    "categories": [],
    "contents": "\nQuestion 1\nThe time between the date a patient was recommended for heart surgery and the surgery date for cardiac patients in Ontario was collected by the Cardiac Care Network (“Wait Times Data Guide,” Ministry of Health and Long-Term Care, Ontario, Canada, 2006). The sample mean and sample standard deviation for wait times (in days) of patients for two cardiac procedures are given in the accompanying table. Assume that the sample is representative of the Ontario population.\nConstruct the 90% confidence interval to estimate the actual mean wait time for each of the two procedures. Is the confidence interval narrower for angiography or bypass surgery?\nAnswer:\nRemember that we are trying to create a confidence interval for the average weight time for each surgical procedure. We are trying to predict the mean in the population ideally. We find the upper and lower bonds in order to be able to find our confidence level between 2 bands if you will.\nFor here, we want to use qt() as it gives us the lower tail value. Remember that you are saying you want R to give you the area underneath of the left OR lower tail.\nt=-qt(0.05, 538)\nRemember, we start here as we are trying to find the area underneath 0.05 and the degrees of freedom would be n-1.\nUB=19+t*10/sqrt(539) 19.7091\nlB= 19-t*10/sqrt(539) 18.2902\nUltimately we get that we are 90% confident that true wait time for bypass patients is between 18.3 and 19.71 days. Remember that there is a chance we are wrong, we are only 90% confident. We are saying that we are 90% confident that you will be waiting between 18.3 and 19.71 days to get your procedure.\nThen we do the same thing for the other surgery\nt=qt(0.05, 846)\nUB=18+t*9/sqrt(847) 18.5092\nLB=18-t*9/sqrt(847) 17.49078\nNow we can say we are 90% confident that the true wait time for aniography patients is between 17.49 and 18.50 days.\nIn order to find which is narrower we simply do: 19.71-18.3 = 1.41 days\n18.51-17.5 = 1.01 days\nAngiography is a more narrow inverval.\nQuestion 2\nA survey of 1031 adult Americans was carried out by the National Center for Public Policy. Assume that the sample is representative of adult Americans. Among those surveyed, 567 believed that college education is essential for success. Find the point estimate, p, of the proportion of all adult Americans who believe that a college education is essential for success. Construct and interpret a 95% confidence interval for p.\nAnswer\nRemember hear that p hat is the sample proportion. For here we want to say: phat= 567/1031=0.55 n=1031\nRemember that ultimately, we want to construct a confidence interval as this is much more accurate than a point estimate.\nLB < P < UB —->We want to follow this format essentially and plug what we know in\nUB=0.55=1.96+sqrt(0.550.45/1031) LB=0.55-1.96sqrt(0.55*0.45/1031)\n0.52 < P < 0.058\nTrue population proportion of those believing college education is essential for success is in between 0.52 and 0.58 with a 95% confidence level\nQuestion 3\nSuppose that the financial aid office of UMass Amherst seeks to estimate the mean cost of textbooks per quarter for students. The estimate will be useful if it is within $5 of the true population mean (i.e. they want the confidence interval to have a length of $10 or less). The financial aid office is pretty sure that the amount spent on books varies widely, with most values between $30 and $200. They think that the population standard deviation is about a quarter of this range. Assuming the significance level to be 5%, what should be the size of the sample?\nAnswer\nThe important information here is that: Range= 170 Sigma= 170/4 = 42.5 Alpha=5 —->This means that the confidence level = 95% (1-(alpha))\nHere, we are trying to find the size of the sample but remember that we don’t actually know but so much about the data. At this point, we need qnorm() which will give us the z-score of both sides of a normal distribution. We get 0.025 using a z table as this is the number that corresponds to -1.96.\nqnorm(0.025) =-1.96 This tells us that -z = -1.96 and z = 1.96\n21.9642.5/(sqrrtn) = 10 —->We want to solve for n\nWhen we do, we get n=278 We can interpret this as 278 being the ideal sample size based on what we know\nQuestion 4\n(Exercise 6.7, Chapter 6 of SMSS, Agresti 2018) According to a union agreement, the mean income for all senior-level workers in a large service company equals $500 per week. A representative of a women’s group decides to analyze whether the mean income μ for female employees matches this norm. For a random sample of nine female employees, ȳ = $410 and s = 90.\nA. Test whether the mean income of female employees differs from $500 per week. Include assumptions, hypotheses, test statistic, and P-value. Interpret the result. B. Report the P-value for Ha : μ < 500. Interpret. B. Report and interpret the P-value for H a: μ > 500. (Hint: The P-values for the two possible one-sided tests must sum to 1.)\nAnswer\nOur first step is to come up with a test statistic. Then you can take the test statistic and create a t graph where you -t and +t. You then compare your p-value with alpha. Or what you can do is calculate a critical p value or a z value (which corresponds to alpha). Then you would compare your test statistic with your critical t.\nIn this particular case, we will choose the former rather than the latter as we are able to use R to compute the p-value (which are difficult to find by hand).\nHo: M=500 Ha: M(can’t equal)500 n=9 s=90 y(bar)=410 t= y(bar)-M/(s/(root(n))= -3\ndf=8\npt(-3, 8) ^Quantile, remember here that 8 is our degrees of freedom (n-1)\npvalue <- (-3,8)*2 +This gives you area under the curve to the left of -3 pvalue= 0.017 +Here, the p-value is very small. This means that there is no way that you were unlucky and selected a bad sample. This means you can reject your null hypothesis (Ho) We are rejecting M=500 in favor of M(is not equal to)500\n(Alternative way) tc <- qt(0.025, 8) ^probability where degrees of freedom is 8 = -2.31 (critical value) t statistic = -3 Here, we can reject Ho, our t-statistic is in the critical region which means we can reject the null!\nB. Ho = M = 500 Ha = M < 500 P-value = 0.0085 Since this p-value is so small, we can reject the null hypothesis in favor of the alternative hypothesis.\nC. Ho = M < 500 Ha = M > 500 test statistic = -3 pt(-3,8) = 0.99 Here, we fail to reject the null hypothesis. This p-value is huge. This proves that M has to be lower that 500 because we are failing to reject the null hypothesis.\nQuestion 5\n(Exercise 6.23, Chapter 6 of SMSS, Agresti 2018) Jones and Smith separately conduct studies to test H0: μ = 500 against Ha : μ = 500, each with n = 1000. Jones gets ȳ = 519.5, with se = 10.0. Smith gets ȳ = 519.7, with se = 10.0. Show that t = 1.95 and P-value = 0.051 for Jones. Show that t = 1.97 and P-value = 0.049 for Smith. Using α = 0.05, for each study indicate whether the result is “statistically significant.” Using this example, explain the misleading aspects of reporting the result of a test as “P ≤ 0.05” versus “P > 0.05,” or as “reject H0” versus “Do not reject H0 ,” without reporting the actual P-value.\nAnswer\nA. Jones, t = 519-500/10 = 1.95\nse= s/sqrt(n)\nHere, we are conducting a 2-sided test. We want to find the area to the right of 1.95 and the area to the left of -1.95. These two areas together will give us the t-value. We will try and find the area on the left first\ndf=999\np-value = pt(-1.95, 999)*2 = 0.051\nSmith\nt= 519.7-500/10 = 1.97\np-value = pt(-1.97, 999)*2 = 0.049\nB. For Jones, we fail to reject the null hypothesis as the p-value is above 0.051 which means the results are statistically insignificant. For Smith, we can reject the null hypothesis which means that the results are statistically significant.\nC. The p-values are so similar that the results are not desirable. It is not fair to Jones. The results are so close that the basically got the same results but Jones got the shorter end of the stick and only his results are statistically insignificant.\nQuestion 6\nAre the taxes on gasoline very high in the United States? According to the American Petroleum Institute, the per gallon federal tax that was levied on gasoline was 18.4 cents per gallon. However, state and local taxes vary over the same period. The sample data of gasoline taxes for 18 large cities is given below in the variable called gas_taxes.\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\nIs there enough evidence to conclude at a 95% confidence level that the average tax per gallon of gas in the US in 2005 was less than 45 cents? Explain.\nAnswer\n\n\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\n\n\n\nHo: M<45 Ha: M<(less than or equal to) 45\nmean(gas_taxes) sd(gas_taxes)\nt= 40.86-45/9.31/sqrt(18) = -1.89\ndf= pt(-1.89, 17) p-value = 0.038 ^^This is a one-sided test so no need to multiply it\nThe conclusion is that we can reject the null hypothesis which gives us strong evidence to claim that tax rate is less than 45% at 5% significance level.\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-27T23:55:38-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomalexanderhong86870632/",
    "title": "DACSS 603 HW#1",
    "description": "First homework for DACSS 603.",
    "author": [
      {
        "name": "Alexander Hong",
        "url": {}
      }
    ],
    "date": "2022-02-27",
    "categories": [],
    "contents": "\r\n##Question 1\r\nThe time between the date a patient was recommended for heart surgery and the surgery date for cardiac patients in Ontario was collected by the Cardiac Care Network (“Wait Times Data Guide,” Ministry of Health and Long-Term Care, Ontario, Canada, 2006). The sample mean and sample standard deviation for wait times (in days) of patients for two cardiac procedures are given in the accompanying table. Assume that the sample is representative of the Ontario population\r\nSurgical Procedure\r\nSample Size\r\nMean Wait Time\r\nStandard Deviation\r\nBypass\r\n539\r\n19\r\n10\r\nAngiography\r\n847\r\n18\r\n9\r\nConstruct the 90% confidence interval to estimate the actual mean wait time for each of the two procedures. Is the confidence interval narrower for angiography or bypass surgery?\r\n\r\n\r\nbypass_l <- 19 - (1.65 * (10/(539^.5)))\r\nbypass_h <- 19 + (1.65 * (10/(539^.5)))\r\nbypass_diff <- bypass_h - bypass_l\r\n\r\nangio_l <- 18 - (1.65 * (9/(847^.5)))\r\nangio_h <- 18 + (1.65 * (9/(847^.5)))\r\nangio_diff <- angio_h - angio_l\r\n\r\n\r\n\r\nCI for Bypass \\(19 \\pm 1.65 ( 10/sqrt(539) )\\) | Difference = 1.4214106\r\nCI for Angiography \\(18 \\pm 1.65 ( 9/sqrt(847) )\\) | Difference = 1.0205041\r\nThe confidence interval is narrower for angiography surgery.\r\n##Question 2\r\nA survey of 1031 adult Americans was carried out by the National Center for Public Policy. Assume that the sample is representative of adult Americans. Among those surveyed, 567 believed that college education is essential for success. Find the point estimate, p, of the proportion of all adult Americans who believe that a college education is essential for success. Construct and interpret a 95% confidence interval for p.\r\n\r\n\r\np2 = 567 / 1031\r\nn2 = 1031\r\nz2 = 1.96\r\n\r\np2_l <- p2 - (z2*(p2*(1-p2))^.5) / n2\r\np2_h <- p2 + (z2*(p2*(1-p2))^.5) / n2\r\n\r\n\r\n\r\nCI = \\(.55 \\pm 1.96 * sqrt( .55 / 1 -.55 )\\)\r\n95% of confidence intervals calculated would contain If this survery is repeated as many times, it is expected that 95% of those confidence intervals will contain the proportion that almost 55% of adult Americans believe that college education is essential for success.\r\n##Question 3\r\nSuppose that the financial aid office of UMass Amherst seeks to estimate the mean cost of textbooks per quarter for students. The estimate will be useful if it is within $5 of the true population mean (i.e. they want the confidence interval to have a length of $10 or less). The financial aid office is pretty sure that the amount spent on books varies widely, with most values between $30 and $200. They think that the population standard deviation is about a quarter of this range. Assuming the significance level to be 5%, what should be the size of the sample?\r\nz = 1.96\r\nSD = $170 * .25 = $42.5 (The quarter of the range is .25*(200-30) )\r\nMean = Assuming most of the book values of the mean is between $30 and $200, the mean can be derived from ( $200 + $30 / 2 ) = $115\r\n\r\n\r\n\r\nA sample size of 277 textbooks should be needed to estimate the mean cost of textbooks per quarter. Using this sample size, given the standard deviation is $42.5, and the mean price of textbooks is $115, our confidence interval will have a length of $10.01\r\n##Question 4\r\n(Exercise 6.7, Chapter 6 of SMSS, Agresti 2018) According to a union agreement, the mean income for all senior-level workers in a large service company equals $500 per week. A representative of a women’s group decides to analyze whether the mean income μ for female employees matches this norm. For a random sample of nine female employees, ȳ = $410 and s = 90.\r\nTest whether the mean income of female employees differs from $500 per week. Include assumptions, hypotheses, test statistic, and P-value. Interpret the result. Report the P-value for Ha : μ < 500. Interpret. Report and interpret the P-value for H a: μ > 500. (Hint: The P-values for the two possible one-sided tests must sum to 1.)\r\n\r\n\r\nbar = 410\r\ns = 90\r\nn = 9\r\nmu = 500\r\n\r\ntscore <- (bar - mu) / (s / 9^.5)\r\n\r\np_value_l <- pt(tscore, df = n - 1, lower.tail = TRUE)\r\ncat(\"P-value is:\", p_value_l)\r\n\r\n\r\nP-value is: 0.008535841\r\n\r\np_value_h <- pt(tscore, df = n - 1, lower.tail = FALSE)\r\ncat(\"P-value is:\", p_value_h)\r\n\r\n\r\nP-value is: 0.9914642\r\n\r\nHypothesis 1:\r\nHo: μ = 500\r\nHa: μ < 500\r\nTest Statistic: -3\r\n0.0085358\r\nWe reject the null hypothesis and conclude that the mean salaries of female senior employees are not statistically significantly less than the $500 / week of senior employees.\r\nHypothesis 2:\r\nHo: μ = 500\r\nHa: μ > 500\r\nTest Statistic: -3\r\n0.9914642\r\nWe fail to reject the null hypothesis and conclude that the mean salaries of female senior employees are not statistically significantly higher than the $500 / week of senior employees.\r\n##Question 5\r\n(Exercise 6.23, Chapter 6 of SMSS, Agresti 2018) Jones and Smith separately conduct studies to test H0: μ = 500 against Ha : μ ≠ 500, each with n = 1000. Jones gets ȳ = 519.5, with se = 10.0. Smith gets ȳ = 519.7, with se = 10.0. Show that t = 1.95 and P-value = 0.051 for Jones. Show that t = 1.97 and P-value = 0.049 for Smith. Using α = 0.05, for each study indicate whether the result is “statistically significant.” Using this example, explain the misleading aspects of reporting the result of a test as “P ≤ 0.05” versus “P > 0.05”, or as “reject H0” versus “Do not reject H0 ,” without reporting the actual P-value.\r\n\r\n\r\njones_t <- round(pt(q=1.95, df=999, lower.tail = FALSE) * 2, 3)\r\nsmith_t <- round(pt(q=1.97, df=999, lower.tail = FALSE) * 2, 3)\r\n\r\n\r\n\r\nT Statistic for Jones = (519.5 - 500) / 10 = 1.95, p-value = 0.051\r\nT Statistic for Smith = (519.7 - 500) / 10 = 1.97, p-value = 0.049\r\nUsing an α = 0.05\r\nThe Jones study is not considered to be statistically significant, given the p-value for the test statistic is .051, which is barely above the .05 threshold.\r\nThe Smith study considered to be statistically significant, given the p-value for the test statistic is .049, which is barely above the .05 threshold.\r\nFor this example, if a result was listed as “P ≤ 0.05”, the range of p-values for Smith’s study can range from .05 to almost 0, with the actual p-value being .049.. If a result was listed as “P > 0.05”, the range of p-values for Jones’ study can range from .05 to 1, while the actual p-value was .051. These ranges diminish the reality that these studies were barely statistically significant or not, which would lead to possibly diminishing the motivation to look further into these studies and the nuances of the study which led to producing said result.\r\n##Question 6\r\nAre the taxes on gasoline very high in the United States? According to the American Petroleum Institute, the per gallon federal tax that was levied on gasoline was 18.4 cents per gallon. However, state and local taxes vary over the same period. The sample data of gasoline taxes for 18 large cities is given below in the variable called gas_taxes.\r\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\r\nIs there enough evidence to conclude at a 95% confidence level that the average tax per gallon of gas in the US in 2005 was less than 45 cents? Explain.\r\n\r\n\r\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\r\n\r\ngas_m <- mean(gas_taxes)\r\ngas_sd <- (var(gas_taxes))^.5\r\n\r\ngas_l <- gas_m - (1.96 * (gas_sd/length(gas_taxes)^.5))\r\ngas_g <- gas_m + (1.96 * (gas_sd/length(gas_taxes)^.5))\r\n\r\n\r\n\r\nMean = 40.8627778 Standard Deviation = 9.3083168\r\n\\(40.86 \\pm 1.96 (9.31/sqrt(18))\\) = (36.5625548, 45.1630008)\r\nAt the 95% confidence level, there is not enough evidence to conclude that the average tax per gallon of gas was less than $.45. The upper end of the confidence interval is just over $.45.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-27T23:55:59-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomchester870152/",
    "title": "Homework One",
    "description": "DACSS 603",
    "author": [
      {
        "name": "Cynthia Hester",
        "url": {}
      }
    ],
    "date": "2022-02-27",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nQuestion 1\r\nSolution\r\nAnalysis\r\n\r\nQuestion 2\r\nSolution\r\n\r\nQuestion 3\r\nSolution\r\n\r\nQuestion 4\r\nSolution\r\n\r\nQuestion 5\r\nSolution\r\n\r\nQuestion 6\r\nSolution\r\n\r\n\r\nQuestion 1\r\nThe time between the date a patient was recommended for heart surgery and the surgery date for cardiac patients in Ontario was collected by the Cardiac Care Network (“Wait Times Data Guide,” Ministry of Health and Long-Term Care, Ontario, Canada, 2006). The sample mean and sample standard deviation for wait times (in days) of patients for two cardiac procedures are given in the accompanying table. Assume that the sample is representative of the Ontario population.\r\nConstruct the 90% confidence interval to estimate the actual mean wait time for each of the two procedures. Is the confidence interval narrower for angiography or bypass surgery?\r\nSolution\r\nFirst we assign variable names to the sample summary statistics\r\n\r\n\r\nbypass_sample<-539 #bypass_sample\r\nangio_sample<-847  #angiography_sample\r\nbypass_mean<-19    #bypass_sample_wait_time_mean\r\nangio_mean<-18     #angiography_sample_wait_time_mean\r\nbypass_sd<-10      #bypass_standard_deviation\r\nangio_sd<-9        #angiography_standard_deviation\r\n\r\n\r\n\r\nWe then calculate the t-confidence interval or t-score of each sample. To do this we start by calculating the degrees of freedom of each sample (bypass and angiography)\r\nCalculating degrees of freedom of the bypass and angiography samples\r\n\r\n\r\nbypass_df<-bypass_sample - 1  #bypass degrees of freedom\r\nangio_df<-angio_sample - 1    #angiography degrees of freedom\r\n\r\n\r\n\r\nNow that we have degrees of freedom we can calculate the t-critical values or t-score for the respective 90% intervals of each sample.\r\n\r\n\r\n#Calculating the t-critical value for the **angiography** sample\r\n\r\nangio_sample<-847\r\nangio_df<-angio_sample - 1\r\nt_score_angio<-qt(p=0.05, df=angio_df,lower.tail=F)\r\nprint(t_score_angio)\r\n\r\n\r\n[1] 1.646657\r\n\r\n# Calculating the t-critical value for the **bypass** sample\r\n\r\nbypass_sample<-539\r\nbypass_df<-bypass_sample - 1\r\nt_score_bypass<-qt(p=0.05, df=bypass_df,lower.tail=F)\r\nprint(t_score_bypass)\r\n\r\n\r\n[1] 1.647691\r\n\r\n# We now find the margin of error for both samples\r\n\r\n\r\nmargin_angio<- qt(0.05,df=angio_df)*9/sqrt(847)    #margin of error angiography\r\nprint(margin_angio)\r\n\r\n\r\n[1] -0.5092182\r\n\r\nmargin_bypass<-qt(0.05,df=bypass_df)*10/sqrt(539)   #margin of error bypass\r\nprint(margin_bypass)\r\n\r\n\r\n[1] -0.7097107\r\n\r\n# To calculate the lower bound and upper bound of the angiography sample\r\n\r\nlower_bound_angio<-angio_mean-margin_angio\r\nprint(lower_bound_angio)\r\n\r\n\r\n[1] 18.50922\r\n\r\nupper_bound_angio<-angio_mean+margin_angio\r\nprint(upper_bound_angio)\r\n\r\n\r\n[1] 17.49078\r\n\r\n# To calculate the lower bound and upper bound of the bypass sample\r\n\r\nlower_bound_bypass<-bypass_mean-margin_bypass\r\nprint(lower_bound_bypass)\r\n\r\n\r\n[1] 19.70971\r\n\r\nupper_bound_bypass<-bypass_mean+margin_bypass\r\nprint(upper_bound_bypass)\r\n\r\n\r\n[1] 18.29029\r\n\r\nTo determine which confidence interval is narrower I subtract the upper bound from the lower bound of each respective procedure.\r\nAngiography : [17.49,18.51] 18.51-17.49 = 1.02 \r\nBypass : [18.29,19.71] 19.71-18.29 = 1.42 \r\nThe angiography 90% confidence interval is narrower at 1.02 compared to the bypass of 1.42\r\nAnalysis\r\nWe see the mean wait time of the 90% confidence interval is from 17.49 to 18.51 days for the angiography procedure. Whereas the mean wait time of the 90% confidence interval is from 18.29 to 19.71 for the bypass procedure. This results in a narrower wait time of 1.02 days for the angiography compared to the bypass of 1.42 days. This could be attributed to the larger sample size for the angiography of 847 compared to a sample of 539 for the bypass. As well as a smaller standard deviation of 9 for the angiography compared to a standard deviation of 10 for the bypass.\r\nQuestion 2\r\nA survey of 1031 adult Americans was carried out by the National Center for Public Policy. Assume that the sample is representative of adult Americans. Among those surveyed, 567 believed that college education is essential for success.\r\nFind the point estimate, p, of the proportion of all adult Americans who believe that a college education is essential for success.\r\nConstruct and interpret a 95% confidence interval for p.\r\nSolution\r\nFirst, we find the point estimate,p, of the proportion.\r\n\r\n\r\n# Specify sample occurrences (x), sample size(n), and confidence_level\r\n\r\n\r\nx<- 567                     # survey respondents  (successes)\r\nn<- 1031                    # total surveyed\r\nconfidence_level<-0.95      # confidence level\r\npoint_estimate<-x/n         # the point estimate is the sample proportion\r\n\r\n\r\n\r\nNow to determine the 90% confidence interval I must find the alpha,the critical z-value, standard error and the margin of error.\r\n\r\n\r\nalpha<-(1-confidence_level)\r\ncritical_z<-qnorm(1-alpha/2)\r\nstandard_error<-sqrt(point_estimate*(1-point_estimate)/n)\r\nmargin_of_error<-critical_z*standard_error \r\n\r\n\r\n\r\nThe lower bound and upper bound of the confidence interval are calculated.\r\n\r\n\r\nlower_bound<-point_estimate-margin_of_error \r\nupper_bound<-point_estimate+margin_of_error\r\n\r\n\r\n\r\nResults\r\n\r\n\r\nsprintf(\"Point Estimate: %0.3f\", point_estimate)\r\n\r\n\r\n[1] \"Point Estimate: 0.550\"\r\n\r\nsprintf(\"Critical Z-value: %0.3f\", critical_z)\r\n\r\n\r\n[1] \"Critical Z-value: 1.960\"\r\n\r\nsprintf(\"Margin of Error: %0.3f\", margin_of_error)\r\n\r\n\r\n[1] \"Margin of Error: 0.030\"\r\n\r\nsprintf(\"Confidence Interval: [%0.3f,%0.3f]\", lower_bound,upper_bound)\r\n\r\n\r\n[1] \"Confidence Interval: [0.520,0.580]\"\r\n\r\nsprintf(\"The %0.1f%% confidence interval for the population proportion is:\", confidence_level*100)\r\n\r\n\r\n[1] \"The 95.0% confidence interval for the population proportion is:\"\r\n\r\nsprintf(\"between %0.4f and %0.4f\",lower_bound,upper_bound)\r\n\r\n\r\n[1] \"between 0.5196 and 0.5803\"\r\n\r\nConfidence interval interpretation\r\nWe have 95% confidence that the interval from the lower bound to the upper bound,[0.5196,0.5803] actually contains the true value of the population proportion of those in the sample believing a college education is valuable.\r\nQuestion 3\r\nSuppose that the financial aid office of UMass Amherst seeks to estimate the mean cost of textbooks per quarter for students. The estimate will be useful if it is within $5 of the true population mean (i.e. they want the confidence interval to have a length of $10 or less). The financial aid office is pretty sure that the amount spent on books varies widely, with most values between $30 and $200. They think that the population standard deviation is about a quarter of this range. Assuming the significance level to be 5%, what should be the size of the sample?\r\nSolution\r\nHere’s what we know:\r\nmean population error = +/-5\r\nrange of the data - upper range - lower range = 200-30 = 170\r\npopulation standard deviation = Range/a quarter 170/4=42.5 which is sigma\r\nsignificance level or alpha = 0.05\r\nfrom this we can calculate the z-score or critical value\r\n\r\n\r\ncritical_z<-qnorm(1-0.05/2) #using the significance level or alpha we calculate z-score                 \r\nprint(critical_z)\r\n\r\n\r\n[1] 1.959964\r\n\r\n\r\n\r\nn_sample_size<-((1.96*42.5)/5)**2      #n=(z-score*standard deviation)/margin of error)**2\r\nprint(n_sample_size)                   #sample size\r\n\r\n\r\n[1] 277.5556\r\n\r\nThus, we see that we would need a minimum sample of 277.5556 or 278\r\nQuestion 4\r\n(Exercise 6.7, Chapter 6 of SMSS, Agresti 2018) According to a union agreement, the mean income for all senior-level workers in a large service company equals $500 per week. A representative of a women’s group decides to analyze whether the mean income μ for female employees matches this norm. For a random sample of nine female employees, ȳ = $410 and s = 90.\r\na)Test whether the mean income of female employees differs from $500 per week. Include assumptions, hypotheses,test statistic, and P-value. Interpret the result.\r\nb)Report the P-value for Ha : μ < 500. Interpret.\r\nc)Report and interpret the P-value for H a: μ > 500.\r\n(Hint: The P-values for the two possible one-sided tests must sum to 1.)\r\nSolution\r\na)Test whether the mean income of female employees differs from $500 per week. Include assumptions, hypotheses, test statistic, and P-value. Interpret the result.\r\nHere’s what we know:\r\n\\(\\mu\\) mean income for all senior level workers = $500/ week\r\n\\(\\bar{y}\\) random sample of 9 female employees income = $410/week\r\ns standard deviation = 90\r\nn random sample female employees = 9\r\nHypotheses\r\nThe null and alternative hypotheses are:\r\n\\(H_0\\): \\(\\mu\\) = $500 per week\r\nThe null hypothesis weekly income for all senior-level workers is $500 per week\r\n\\(H_a\\): \\(\\mu\\) ≠ $500 per week\r\nThe alternative hypothesis suggests the mean weekly income is ≠ $500 (two-sided)\r\nTest Statistic\r\n\r\n\r\nt_test_income<-(410-500)/(90/sqrt(9))          #Test statistic using t-test\r\nprint(t_test_income)\r\n\r\n\r\n[1] -3\r\n\r\nP-Value\r\n\r\n\r\nn_random_sample<-9                      #random sample female employees\r\ndf_sample<-(n_random_sample-1)          #degrees of freedom\r\nt_test_income<-(410-500)/(90/sqrt(9))   #test statistic\r\np_val<-pt(t_test_income,df_sample)*2    #p-value\r\nprint(p_val)\r\n\r\n\r\n[1] 0.01707168\r\n\r\nInterpretation:\r\npart a\r\nAssuming alpha α = 0.05 and we know the p-value is 0.0171 The p-value 0.0171 < 0.05 , we reject the null hypothesis There is therefore sufficient evidence to claim the mean differs from the weekly income of $500.\r\npart b:\r\nReport the P-value for Ha : μ < 500. Interpret.\r\nHypotheses\r\n\\(H_0\\): \\(\\mu\\) = $500 per week\r\n\\(H_a\\): \\(\\mu\\) < $500 per week (left-tail test)\r\np-value = p(t < t_test_income) p(t < -3)\r\nP-value for \\(H_a\\) < $500 per week (left-tail test)\r\n\r\n\r\n#using the formula: pt(q,df,lower.tail=TRUE,log.p=FALSE) to find the p-value\r\n\r\n\r\nq<-(-3)\r\nn_random_sample<-9\r\ndf_sample<-(n_random_sample-1)                            #degrees of freedom \r\nleft_p_value<-pt(q,df_sample,lower.tail = T,log.p = F)    #p value for alternative hypothesis\r\nprint(left_p_value)         \r\n\r\n\r\n[1] 0.008535841\r\n\r\nInterpretation:\r\npart b\r\nSince the P-value 0.0085 is less than the presumed significance level,alpha α = 0.05 I reject the null hypothesis,\\(H_0\\). What this suggests is that there is sufficient evidence to conclude that the mean is < less than 500.\r\npart c:\r\nReport and interpret the P-value for Ha: μ > 500. (Hint: The P-values for the two possible one-sided tests must sum to 1.)\r\nHypotheses\r\n\\(H_0\\): \\(\\mu\\) = $500 per week\r\n\\(H_a\\): \\(\\mu\\) > $500 per week (right-tail test)\r\np-value = p(t > t_test_income) p(t > -3)\r\nP-value for \\(H_a\\) >$500 per week (right-tail test)\r\n\r\n\r\n#using the formula: pt(q,df,lower.tail=TRUE,log.p=FALSE) to find the p-value\r\n\r\n\r\nq<-(-3)\r\nn_random_sample<-9\r\ndf_sample<-(n_random_sample-1)                                  #degrees of freedom \r\nright_p_value<-pt(q,df_sample,lower.tail = F,log.p = F)         #p-value for alternative hypothesis\r\nprint(right_p_value)   \r\n\r\n\r\n[1] 0.9914642\r\n\r\n#verification sum of left and right tail p-values equal 1\r\n\r\nleft_p_value<-pt(q,df_sample,lower.tail = T,log.p = F) \r\nright_p_value<-pt(q,df_sample,lower.tail = F,log.p = F)\r\nleft_right_sum<-(left_p_value+right_p_value)\r\nprint(left_right_sum)\r\n\r\n\r\n[1] 1\r\n\r\nInterpretation:\r\npart c\r\nSince the p-value 0.9915 is greater than the presumed significance level alpha α = 0.05 \\(H_a\\) > 500,therefore we do not reject the null hypothesis \\(H_0\\). There is insufficient evidence to support the claim \\(\\mu\\) mean is > 500.\r\nQuestion 5\r\n(Exercise 6.23, Chapter 6 of SMSS, Agresti 2018) Jones and Smith separately conduct studies to test H0: μ = 500 against Ha : μ ≠ 500, each with n = 1000. Jones gets ȳ = 519.5, with se = 10.0. Smith gets ȳ = 519.7,with se = 10.0.\r\nShow that t = 1.95 and P-value = 0.051 for Jones. Show that t = 1.97 and P-value = 0.049 for Smith.\r\nUsing α = 0.05, for each study indicate whether the result is “statistically significant.”\r\nUsing this example, explain the misleading aspects of reporting the result of a test as “P ≤ 0.05” versus “P > 0.05,” or as “reject H0” versus “Do not reject H0 ,” without reporting the actual P-value.\r\nSolution\r\nShow that t = 1.95 and P-value = 0.051 for Jones. Show that t = 1.97 and P-value = 0.049 for Smith.\r\nHere’s what we know :\r\nsample_n = 1000 each for Jones and Smith\r\ndf_sample_n<-(1000-1) degrees of freedom\r\nJones\r\n\\(\\bar{y}\\) = 519.5\r\nt = 1.95\r\np-value = 0.051\r\nse = 10.0\r\nSmith\r\n\\(\\bar{y}\\) = 519.7\r\nt = 1.97\r\np-value = 0.049\r\nse = 10.0\r\nHypotheses\r\n\\(H_0\\): \\(\\mu\\) = 500\r\n\\(H_a\\): \\(\\mu\\) ≠ 500\r\nJones We were already given both the test statistic 1.95 and p-value 0.051 for Jones so we are just verifying both.\r\nTest_statistic = (\\(\\bar{y}\\) - \\(\\mu\\))/10\r\n\r\n\r\ndf_sample_n<-(1000-1)  #degrees of freedom\r\n\r\nt_test_jones<-(519.5-500)/10    #Test statistic using t-test\r\nprint(t_test_jones)\r\n\r\n\r\n[1] 1.95\r\n\r\np_value_jones<-pt(t_test_jones,df_sample_n,lower.tail = F,log.p = F)*2\r\nprint(p_value_jones)\r\n\r\n\r\n[1] 0.05145555\r\n\r\nSmith\r\nWe were already given both the test statistic 1.97 and p-value 0.049 for Smith so we are verifying both.\r\nTest_statistic = (\\(\\bar{y}\\) - \\(\\mu\\))/10\r\n\r\n\r\ndf_sample_n<-(1000-1)            #degrees of freedom\r\n\r\nt_test_smith<-(519.7-500)/10    #Test statistic using t-test\r\nprint(t_test_smith)\r\n\r\n\r\n[1] 1.97\r\n\r\np_value_smith<-pt(t_test_smith,df_sample_n,lower.tail = F,log.p = F)*2       #p-value for smith\r\nprint(p_value_smith)                                                         #output smith\r\n\r\n\r\n[1] 0.04911426\r\n\r\nUsing α = 0.05, for each study indicate whether the result is “statistically significant.”\r\nFor α = 0.05 we reject the null hypothesis \\(H_0\\) if the p-value is greater than 0.05 and do not reject if the p-value is equal or greater to => \\(H_0\\). So in the case of Jones since the p-value 0.051 is negligibly larger than alpha, it is not statistically significant and we fail to reject the null hypothesis \\(H_0\\). In the case of Smith, the p-value of 0.049 is less than alpha, α = 0.05 which is less than the level of significance, we reject the null hypothesis since a smaller p-value suggests statistical significance.\r\nUsing this example, explain the misleading aspects of reporting the result of a test as “P ≤ 0.05” versus “P > 0.05,” or as “reject H0” versus “Do not reject H0 ,” without reporting the actual P-value.\r\nIn this study the p-values are negligibly the same between Jones and Smith. However, in spite of this because our predetermined significance p-value is ≤ 0.05 in the case of Smith, the null hypothesis is rejected and we conclude there is statistical evidence for the alternative hypothesis \\(H_a\\). Conversely, if our predetermined significance p-value is greater than 0.05 as in the case of Jones then we fail to reject the null hypothesis. There is insufficient evidence to draw any conclusions.\r\nQuestion 6\r\nAre the taxes on gasoline very high in the United States? According to the American Petroleum Institute, the per gallon federal tax that was levied on gasoline was 18.4 cents per gallon. However, state and local taxes vary over the same period. The sample data of gasoline taxes for 18 large cities is given below in the variable called gas_taxes.\r\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\r\nIs there enough evidence to conclude at a 95% confidence level that the average tax per gallon of gas in the US in 2005 was less than 45 cents? Explain.\r\nSolution\r\nHere’s what we know:\r\nsample_gas_taxes<-18\r\ndf_gas_taxes<-sample_gas_taxes-1\r\n95% confidence level (presumptive)\r\nsignificance level alpha = 0.05 based on a 95% confidence level\r\nz-score = 1.96 based on 95% confidence level\r\nFrom this information we can determine the following:\r\n\r\n\r\n#manual calculation of t-score used for finding the upper and lower interval of gas_tax_sample\r\n\r\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\r\n\r\ngas_taxes_sample<-18                                           #gas taxes sample size\r\n\r\ndf_gas_taxes<-gas_taxes_sample-1                               #degrees of freedom \r\nmean_gas_taxes<-mean(gas_taxes)                                #mean gas taxes\r\nt_score_gas_taxes<-qt(p = 0.05,df=df_gas_taxes,lower.tail = F) #t_score\r\nsd_gas<-sd(gas_taxes)                                          #standard deviation\r\nm_error_gas_taxes<-qt(0.05,df=df_gas_taxes)*sd_gas/sqrt(18)    #margin of error gas taxes\r\n\r\n\r\n\r\n\r\n \r\n#Now that all of the needed parameters for lower and upper bounds have been calculated, I can find the confidence interval for the gas taxes sample.\r\n\r\n\r\n\r\nmean_gas_taxes<-mean(gas_taxes)  \r\nm_error_gas_taxes<-qt(0.05,df=df_gas_taxes)*sd_gas/sqrt(18)\r\n\r\nlower_gas_tax<-(mean_gas_taxes-m_error_gas_taxes) #lower bound using mean and margin of error\r\nprint(lower_gas_tax)\r\n\r\n\r\n[1] 44.67946\r\n\r\nupper_gas_tax<-(mean_gas_taxes+m_error_gas_taxes) #upper bound using mean and margin of error\r\nprint(upper_gas_tax)\r\n\r\n\r\n[1] 37.0461\r\n\r\nThe 95% confidence interval is [37.0461 ,44.6795] using manual calculations.\r\nBecause the average tax per gallon is less than 45 cents, it is within the lower and upper bounds of the 95% confidence interval.We can therefore reasonably conclude that there is sufficient evidence that the confidence interval contains taxes less than 45 cents.\r\nAlternative outcome using t.test:\r\n\r\n\r\ngas_taxes<- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\r\n\r\nmean(gas_taxes)\r\n\r\n\r\n[1] 40.86278\r\n\r\nt.test(gas_taxes,conf.level = 0.95)                            #one sample t-test\r\n\r\n\r\n\r\n    One Sample t-test\r\n\r\ndata:  gas_taxes\r\nt = 18.625, df = 17, p-value = 9.555e-13\r\nalternative hypothesis: true mean is not equal to 0\r\n95 percent confidence interval:\r\n 36.23386 45.49169\r\nsample estimates:\r\nmean of x \r\n 40.86278 \r\n\r\nThe 95% confidence interval is [36.23386 ,45.49169]\r\nThere is not enough evidence to conclude at a 95% confidence level that the average tax per gallon of gas in the US in 2005 was less than 45 cents because 45 cents is inside the confidence interval. The confidence interval contains taxes greater than 45 cents.\r\nPlease note I am not sure why there is a difference between 95% confidence intervals when calculated manually versus the t.test function. I therefore include both outcomes.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-27T23:55:50-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomdacssjoe870700/",
    "title": "603, Homework 1",
    "description": "First homework assignment for DACSS 603",
    "author": [
      {
        "name": "Joe Davis",
        "url": {}
      }
    ],
    "date": "2022-02-27",
    "categories": [],
    "contents": "\nQuestion 1\nConstruct the 90% confidence interval to estimate the actual mean wait time for each of the two procedures. Is the confidence interval narrower for angiography or bypass surgery?\nI wanted to do this one a bit longer-form than necessary, but I also appreciate the chance to practice organizing my R code neatly while solving. I need some good repetition to build those good habits.\nFor this question I assigned all of the values in the table to objects to use in the calculations of each treatment’s t-scores, margins of error, and confidence intervals. I did a quick check of the qnorm(.95) to see if the t-scores had converged to the normal distribution given the relatively high sample sizes of each treatment. Surprisingly, to me at least, rounding at the .000 level they still had very slightly different levels both to the normal distribution and to each others’ scores.\nI know I have the standard deviations, wait time would be a continuous variable, and these samples are larger than n = 30 so I can use qnorm and the 1.645 z critical value clearing those assumptions. But, it seems like I should use the distribution with fatter tails relative to the sample size values from qt regardless if I could assume normality from the other conditions, as to err on the side of caution for analyzing and communicating medical procedure data. I have a note in my code on that point, mostly for my own reference and will solve for the normal distribution values as well. After running the calculations the practical effect would be introducing slightly more uncertainty in the mean wait time for the angiography procedure while still keeping that procedures’ interval narrower, as we’d expect, than that of the bypass procedure. Especially if this was to be used to set patient expectations on wait times, the wider range would be the option a hospital or doctor would communicate, but we do appear to be in the range where t and z distributions are becoming quite similar.\n\n\n## Means, Total N,  and SDs from full question text. B = Bypass A = Angiography\n  #mean wait times for each procedure\n  mean_b <- 19 \n  mean_a <- 18 \n  \n  #standard deviations\n  sd_b <- 10\n  sd_a <- 9\n  \n  #total N\n  n_b <- 539\n  n_a <- 847\n\n## 90% CI score finding. .90 = 1 - a and I need  a/2 for the two tails since I have no theory on why the direction of the error would be important. Did a little side exploring of the t distribution and normal distribution scores below.\n  \n\n#Rounded to 1.645 but not used for calculations. I thought it was a sufficiently large sample size that that qt and qnorm should have returned the same values at .000 rounding, but after checking those, each T rounded up differently at the 3rd digits and for medical data I would rather err on the side of caution  \n\n    #normal z score\n  z_heart <- qnorm(.95) \n  round(z_heart, digits = 3)\n\n\n[1] 1.645\n\n  #check this for t scores\nb_t <- round(qt(.95, df = n_b -1), digits = 3)\na_t <-  round(qt(.95, df = n_a -1), digits = 3)\n  \n  #print them\n  b_t\n\n\n[1] 1.648\n\n  a_t\n\n\n[1] 1.647\n\n## 90% CI standard error of mean/ margin of error\n  #Take the score multiplied by standard deviations and sqrt of Ns, t value\n  mofe_bypass <- b_t*(sd_b/sqrt(n_b))\n  mofe_angiography <- a_t*(sd_a/sqrt(n_b))\n  \n  #doing this with z 1.645\n  mofe_bypass_z <- 1.645*(sd_b/sqrt(n_b))\n  mofe_angiography_z <- 1.645*(sd_a/sqrt(n_a))\n  \n  #print the normal distribution score MoE\n  mofe_bypass_z\n\n\n[1] 0.7085517\n\n  mofe_angiography_z\n\n\n[1] 0.5087058\n\n  # Print them using t value\n  mofe_bypass\n\n\n[1] 0.7098439\n\n  mofe_angiography\n\n\n[1] 0.6384718\n\n## +/- from the data set mean for the range\n  \n  #bypass upper and lower\n  bypass_lower <- mean_b - mofe_bypass\n  bypass_upper <- mean_b + mofe_bypass\n  \n  #combine the upper and lower to list interval\n  ci_bypass <- print(c(bypass_lower, bypass_upper))\n\n\n[1] 18.29016 19.70984\n\n  #angiography upper and lower\n  angio_lower <- mean_a - mofe_angiography\n  angio_upper <- mean_a + mofe_angiography\n  \n\n  \n  #combine the upper and lower to list interval\n  ci_angiography <- print(c(angio_lower, angio_upper))\n\n\n[1] 17.36153 18.63847\n\n#Normal distribution 90% CI\n  #bypass Z\n  bypass_lower_z <- mean_b - mofe_bypass_z\n  bypass_upper_z <- mean_b + mofe_bypass_z\n  \n  ci_bypass_z <- (print(c(bypass_lower_z, bypass_upper_z)))\n\n\n[1] 18.29145 19.70855\n\n  #angiography Z\n  angiography_lower_z <- mean_a - mofe_angiography_z\n  angiography_upper_z <- mean_a + mofe_angiography_z\n  \n  ci_angiography_z <- (print(c(angiography_lower_z, angiography_upper_z)))\n\n\n[1] 17.49129 18.50871\n\nThe confidence interval is narrower for angiography, as we have a larger sample size for that procedure’s wait time and a smaller standard deviation. We would expect this as in theory as the larger sample size mean should be closer to the true population mean, and the smaller standard deviation means we have less variation to begin with. That expectation is shown in both the smaller numerator and the larger denominator produced during the margin or error calculation. For comparison on the denominators, since the standard deviations were already listed in the table: 23.2163735 for bypass and 29.1032644 for angiography. For completeness, the normal distribution CI’s are 17.4912942, 18.5087058 for angiography and 18.2914483, 19.7085517 for the bypass procedure.\nQuestion 2\nA survey of 1031 adult Americans was carried out by the National Center for Public Policy. Assume that the sample is representative of adult Americans. Among those surveyed, 567 believed that college education is essential for success. Find the point estimate, p, of the proportion of all adult Americans who believe that a college education is essential for success. Construct and interpret a 95% confidence interval for p.\nSince we are looking to construct this interval around a proportion, I used the prop.test function to construct the interval using the total sample size as the n input and the 567 raw respondents for college “being essential for success” as the success vector in the function. I decided to use this function versus hand calculating as in question 1.\n\n\nprop_coll_success <- prop.test(567, 1031, conf.level = .95)\nprop_coll_success\n\n\n\n    1-sample proportions test with continuity correction\n\ndata:  567 out of 1031, null probability 0.5\nX-squared = 10.091, df = 1, p-value = 0.00149\nalternative hypothesis: true p is not equal to 0.5\n95 percent confidence interval:\n 0.5189682 0.5805580\nsample estimates:\n        p \n0.5499515 \n\nnames(prop_coll_success)\n\n\n[1] \"statistic\"   \"parameter\"   \"p.value\"     \"estimate\"   \n[5] \"null.value\"  \"conf.int\"    \"alternative\" \"method\"     \n[9] \"data.name\"  \n\nThe point estimate from the survey data is 0.55 The 95% confidence The interval is 0.52, 0.58. This interval means that we could say we are 95% confident that the proportion of American adults who believe that “college education is essential for success” is somewhere between the lower and upper end of our confidence interval – assuming the initial survey was indeed random and representative. Representativeness (and randomness, but that’s already extremely difficult with surveying) would be especially important for this question depending on what variables were used to determine that the initial sample was representative, as beliefs around college education are increasingly subject to the impacts political polarization and thus we could be breaking some of our assumptions needed for our analysis to be accurate depending on which variables were used.\nQuestion 3\nSuppose that the financial aid office of UMass Amherst seeks to estimate the mean cost of textbooks per quarter for students. The estimate will be useful if it is within $5 of the true population mean (i.e. they want the confidence interval to have a length of $10 or less). The financial aid office is pretty sure that the amount spent on books varies widely, with most values between $30 and $200. They think that the population standard deviation is about a quarter of this range. Assuming the significance level to be 5%, what should be the size of the sample?\nFor this problem, I started off assigning all of the elements of the problem to objects as I did for the prior two. The standard deviation problem is shown in sd_books below, as 1/4 of the difference between $200 and $30. The critical z for 5% significance level is shown in finding the qnorm result for half of the alpha level. The margin of error we need to aim for is 5 dollars and that is assigned to book_moe. I assumed it would take a decent sized sample, at least larger than 30, to get within 5 dollars with that large of a standard deviation and the we would be able to randomly collect this sample, so I used the large sample size for estimating mean equation to find the sample size n. It took too long to figure out the fancy letters in Rmarkdown, so I used abbreviations for standard deviation and such, unfortunately. \\[n =  sd ^ {2} (z /  M) ^ {2}\\]\n\n\n#Assign all of the elements of the problem to objects\nsd_books <- (200-30)*.25\nsd_books\n\n\n[1] 42.5\n\nbook_z <- qnorm(.975) \nbook_z\n\n\n[1] 1.959964\n\nbook_moe <- 5\n\n# Formula for n from margin of error calculation, large sample is n = sd^2 * z a/2 / M. Calculate by hand first.\nbook_n_by_hand <- sd_books ^ 2 * (book_z / book_moe) ^ 2\n\nbook_n_by_hand\n\n\n[1] 277.5454\n\n#Use the samplingbook package to confirm.\nbook_n_package <- sample.size.mean(e = book_moe, S = sd_books, level = .95)\n\nbook_n_package\n\n\n\nsample.size.mean object: Sample size for mean estimate\nWithout finite population correction: N=Inf, precision e=5 and standard deviation S=42.5\n\nSample size needed: 278\n\nAfter finding the answer of 278 –rounded up– students in the sample by hand calculating n, I wanted to check my work using the samplingbook package and putting the same elements from the problem into the function. That answer, shown above in book_n_package matched my “hand” calculation of 278 students in the sample needed to have a mean estimate within 5 dollars of the true population mean of textbook costs.\nQuestion 4\nAccording to a union agreement, the mean income for all senior-level workers in a large service company equals $500 per week. A representative of a women’s group decides to analyze whether the mean income μ for female employees matches this norm. For a random sample of nine female employees, ȳ = $410 and s =90. \n-A)Test whether the mean income of female employees differs from $500 per week. Include assumptions, hypotheses, test statistic, and P-value. Interpret the result.\n-B) Report the P-value for Ha : μ < 500. Interpret.\n-C) Report and interpret the P-value for H a: μ > 500. (Hint: The P-values for the two possible one-sided tests must sum to 1.)\nSince this question has several follow up questions to report out, I’m going to dive right in to the code portion of the work, and I’ll have all of the narrative explanations and steps of work described there.\n\n\n#question elements assigned to objects, will use alpha = .05\n  \n  #population\n  all_union_mean <- 500\n  \n  #sample\n  women_mean <- 410\n  women_sd <- 90\n  women_n <- 9\n\n#get the test statistic t\n\n  #estimated standard error\n  women_se <- women_sd / sqrt(women_n)\n  women_se\n\n\n[1] 30\n\n  #test statistic\n  women_t <- (women_mean - all_union_mean) / women_se\n  women_t\n\n\n[1] -3\n\n#find two tail p-value, round to two digits\n  women_p <- round(2*pt(-abs(women_t), df = 8, lower.tail = FALSE ), digits = 2)\n  women_p\n\n\n[1] 1.98\n\n#p for < 500, round to two digits\n  women_lower_p <- round(pt(-abs(women_t), df = 8, lower.tail = TRUE), digits = 2)\n  women_lower_p\n\n\n[1] 0.01\n\n#p for > 500, round to two digits\n  women_greater_p <- round(pt(-abs(women_t), df = 8, lower.tail = FALSE), digits = 2)\n  women_greater_p\n\n\n[1] 0.99\n\nAssumptions: Because this is a small sample, I’m using the two-sided t-test as it is robust when the data may not clear the normality assumptions. Given the smaller sample size of the study, highly skewed data could impact one-tailed tests and the question didn’t explicitly state that they were looking higher or lower than the overall union average\nHypotheses: Null hypothesis is that the mean wage for women = 500 dollars, the same as the contract required mean for all senior workers at the union. The alternative hypothesis is that the mean wage for women =/= 500 dollars.\nTest statistic: The test statistic women_t has a value of -3. Since this is a negative value due to the sample mean being lower than the population mean, it’s important to remember that the absolute value should be used in calculating the p value.\nP value: The two-sided P value from women_t with 8 degrees of freedom equals 1.98.\nInterpreting the results: Since the two-tailed P value is lower than our pre-selected alpha level of .05 by some distance, we can reject the null hypothesis that the mean wage for women is equal to 500 dollars, and accept the alternative hypothesis that it is not equal to 500. The below data points make it seem as though it is very likely below the overall union mean, which lines up with the mean and sd data from their study. If only the very outer bounds of the deviation hits the overall mean, it seems like this all confirms that the female employee mean is < 500 dollars. I would suggest initiating the process of review, confirmation of the study, and the grievance process.\nQuestion B: The P value for the womens’ mean weekly wage being less than 500 is 0.01. This means that if our null hypothesis was true, we would have a 99% chance of getting a value below 500 for our sample mean. Being that the contract specifies an overall mean of 500 and it’s stated that this is a large company so we can assume normality through the Central Limit Theorem, we have a lot of evidence that the mean weekly wage for women is likely lower than what the contract specifies. Being that we have a small sample size it is possible for the one-tailed value to be off with highly skewed data, however. Given the rejection of the null and the one tail results here and below for greater than 500, I think the women’s group would have a strong case that their mean wage is not 500 and most likely lower than 500 dollars.\nQuestion C: The P value for the mean weekly wage for women being greater than 500 is 0.99. This means that if the null hypothesis was true, we would expect to get a mean weekly wage for women greater than the population mean wage 1% of the time. With the same small sample size caveat as above on one tailed results, this split in P values which would have us fail to reject and then reject the null hypothesis respectively, for above and below the population mean is quite extreme and would be another supporting point in the group filing a grievance.\nQuestion 5\nJones and Smith separately conduct studies to test H0: μ = 500 against Ha : μ ≠ 500, each with n = 1000. Jones gets ȳ = 519.5, with se = 10.0. Smith gets ȳ = 519. 7,with se = 10.0.\nA) Show that t = 1.95 and P-value = 0.051 for Jones. Show that t = 1.97 and P-value = 0.049 for Smith. \nB) Using α = 0.05, for each study indicate whether the result is “statistically significant.” \nC)Using this example, explain the misleading aspects of reporting the result of a test as “P ≤ 0.05” versus “P > 0.05,” or as “reject H0” versus “Do not reject H0 ,” without reporting the actual P-value.\nSame as above, I’m going to assign out the objects and then go through the solution steps below the R code chunk. The answer for question A will be in the R code chunk, while I will answer the narrative aspects of the other questions in the text below.\n\n\n#Question Elements\n  #both studies with same n\n  study_n <- 1000\n\n  #null mean = 500\n  #alt mean =/= 500\n\n  #jones study elements\n  jones_mean <- 519.5\n  jones_se <- 10.0\n\n  #smith study elements\n  smith_mean <- 519.7\n  smith_se <- 10.0\n\n\n#Solve for Smith\n  \n  #t for Smith, use two digits and it must equal 1.97\n  smith_t <- round((smith_mean - 500) / smith_se,  digits = 2)\n  smith_t #It's 1.97 like it's supposed to be,  yay!\n\n\n[1] 1.97\n\n  #P for Smith, use three digits and two-tailed \n  smith_p <- round(2 * pt(-abs(smith_t), df = 999), digits = 3)\n  smith_p # It's .049 like it's supposed to be!\n\n\n[1] 0.049\n\n#Solve for Jones\n  \n  #t for Jones, use two digits and it must equal 1.95.\n  jones_t <- round((jones_mean - 500) / jones_se, digits = 2)\n  jones_t #It's 1.95 like it's suppost to be, yay!\n\n\n[1] 1.95\n\n  #P for Jones, use three digits and it must equal .051\n  jones_p <- round(2 * pt(-abs(jones_t), df = 999), digits = 3)\n  jones_p #It's .051 like it's supposed to be!\n\n\n[1] 0.051\n\nQuestion B and C: I thought it made sense to answer these questions in one response versus splitting them up by bullet point. Technically, both studies would be “statistically significant” at the .05 level as rounding .049 and .051 to two digits would take them both to less than or equal to .05. Rounding them without disclosing that would be no good. This is also quite misleading to attribute practical significance to a difference in P values of .002 to our arbitrarily set level of significance. Practically speaking, there is no real difference in the outcomes of these studies.\nWithout rounding, only Smith’s .049 would be below the alpha level and Jones’ .051 would be above. With these fine margins, reporting only whether the null was rejected or if we failed to reject it, or even just listing the “p less than or equal to .05 or p greater than .05” statement without the raw p values included would also ascribe practical significance in difference to these two studies even though they are very nearly identical. The differences could very well be random noise and chance, and reporting out the statement alone would make it harder to asses that.\nChoosing to publish Smith’s study just because it cleared the threshold and not Jones’ as well could make it harder to see the full picture of the parameter they studied or analyze the overall random variability in the experimental findings in a meta analysis setting.\nQuestion 6\nAre the taxes on gasoline very high in the United States? According to the American Petroleum Institute, the per gallon federal tax that was levied on gasoline was 18.4 cents per gallon. However, state and local taxes vary over the same period.\nThe sample data of gasoline taxes for 18 large cities is given below in the variable called gas_taxes.\nIs there enough evidence to conclude at a 95% confidence level that the average tax per gallon of gas in the US in 2005 was less than 45 cents? Explain.\nAfter reading the question, I don’t think our initial sample was collected in a way that would allow us to be confident in a confidence interval constructed from it to look at the average price in the nation as a whole in 2005. If the federal tax is constant at 18.4, it looks like most of the variability from city to city in the sample data is driven by state and local tax levy decisions. The mean for the gas_tax data is 40.86, so over half of our mean amount comes from state and local variables that do not look to be accounted for in the sampling description as is. Most Americans in 2005 (and still today), did not live in very large cities, the amount depending of course on the exact definition of “large.”\nOur sample is only from 18 large cities in the country, and I think it’s reasonable to assume large cities have, or the very least could have, systemically different gas tax policies than other population densities. Some states could have caps or specific legislation that could impact the overall national average, and there’s not enough information about how the 18 large cities were selected or sampled to clear all of the assumptions, even if we didn’t think large cities varied from suburban, exurban or rural geographies in a way that would skew the small sample of data that we do have. Exploring bootstrapping or other approaches would also be impacted by this fact.\nNow, if I’m reading entirely too much into this set up and I should just show that I can evaluate if our mean is below a set level using a confidence interval, I’ll proceed to do that, too! To answer this question, I’ll use the psych package to get the descriptive statistics and look those over for fun and possible use to calculate by hand if the t.test result looks funny. Then I’ll use t.test(gas_tax) and look at the 95% CI range.\nIf the entire confidence interval is below 45 cents we would have enough evidence to say we think it’s 95% likely that the mean gas tax is below the 45 cent level, the equivalent of rejecting the null hypothesis and accepting the alternative hypothesis of gas taxes were likely lower than 45 cents. If the interval includes 45 and/or above that level we don’t have enough information, and would be doing the equivalent of failing to reject the null hypothesis.\n\n\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\n\n#Use describe from the psych package for overview of gas_tax data, could use the variables here to hand calculate the CI.\ngas_tax_summary <- describe(gas_taxes)\ngas_tax_summary\n\n\n   vars  n  mean   sd median trimmed  mad   min   max range  skew\nX1    1 18 40.86 9.31  41.47   41.41 9.72 18.49 54.41 35.92 -0.58\n   kurtosis   se\nX1    -0.32 2.19\n\n#Use t.test on gas_taxes to see the 95% CI\nt.test(gas_taxes)\n\n\n\n    One Sample t-test\n\ndata:  gas_taxes\nt = 18.625, df = 17, p-value = 9.555e-13\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 36.23386 45.49169\nsample estimates:\nmean of x \n 40.86278 \n\nThe 95% interval does contain 45 cents, so we cannot say that we have enough evidence at this confidence level and interval to do the equivalent of rejecting the null hypothesis. Since the null value is at the very very top of the interval, and putting aside the other issues with the sample to begin with, it seems like the sort of result where we could say in practice it was likely lower than 45 cents. Since gas taxes and prices go to the third digit at the pump, our result would have a maximum 95% CI level “at the pump” reading of .455. It feels safe to describe in actual practice with that interval that we’re confident it was 45 cents or lower, even if we’d need a bit more data to say it in specific statistical terms.\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-27T23:56:02-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomegeeslindacss-603-hw1/",
    "title": "HW1_DACSS603",
    "description": "DACSS 603 Homework 1",
    "author": [
      {
        "name": "Eliza Geeslin",
        "url": {}
      }
    ],
    "date": "2022-02-27",
    "categories": [],
    "contents": "\nQuestion 1\nThe time between the date a patient was recommended for heart surgery and the surgery date for cardiac patients in Ontario was collected by the Cardiac Care Network (“Wait Times Data Guide,” Ministry of Health and Long-Term Care, Ontario, Canada, 2006). The sample mean and sample standard deviation for wait times (in days) of patients for two cardiac procedures are given in the accompanying table. Assume that the sample is representative of the Ontario population.\n\n  surgical_procedure sample_size mean_wait_time standard_deviation\n1            Bypasss         539             19                 10\n2        Angiography         847             18                  9\n\nConstruct the 90% confidence interval to estimate the actual mean wait time for each of the two procedures. Is the confidence interval narrower for angiography or bypass surgery?\nI will do the following to calculate the confidence intervals:\nCalculate the mean\nCalculate the standard error of the mean\nCalculate n\nDetermine a confidence level\nFind the t-score\nCalculate interval\nI will start with the values we know.\n\n\n# we already know the mean, sample size, and standard deviation\n# creating variables for all the values we do know\nbypass_n <- 539\nbypass_mean_wait_time <- 19\nbypass_sd <- 10\nangio_n <- 847\nangio_mean_wait_time <- 18\nangio_sd <- 9\n\n\n\nNext, I will specify the confidence level and use that the calculate the tail area.\n\n\n# specify confidence level\n# calculate tail area - we can use this for both the angio and bypass confidence intervals\n\nconfidence_level <- 0.90\ntail_area <- (1 - confidence_level)/2 # divide by two because we care about both sides.\n\ntail_area\n\n\n[1] 0.05\n\nThen I will use the tail areas to calculate the t-scores and confidence intervals. I will start with the bypass surgery.\n\n\n# bypass\n# calculate t-score\nbypass_t_score <- qt(p = 1 - tail_area, df = bypass_n - 1)\n\nbypass_t_score\n\n\n[1] 1.647691\n\n\n\n# bypass \n# calculate confidence internal\n\nbypass_lower <- bypass_mean_wait_time - bypass_t_score * bypass_sd / sqrt(bypass_n)\nbypass_upper <- bypass_mean_wait_time + bypass_t_score * bypass_sd / sqrt(bypass_n)\n\nprint(c(bypass_lower, bypass_upper))\n\n\n[1] 18.29029 19.70971\n\nThe confidence interval for the bypass surgery is between 18.29029 and 19.70971 days.\nNext, I will do the same for the angio surgery.\n\n\n# angio\n# calculate t-score\n\nangio_t_score <- qt(p = 1 - tail_area, df = angio_n - 1)\n\nangio_t_score\n\n\n[1] 1.646657\n\n\n\n# margin of error and confidence interval - angio\n\nangio_lower <- angio_mean_wait_time - angio_t_score * angio_sd / sqrt(angio_n)\nangio_upper <- angio_mean_wait_time + angio_t_score * angio_sd / sqrt(angio_n)\n\nprint(c(angio_lower, angio_upper))\n\n\n[1] 17.49078 18.50922\n\nThe confidence interval for the angiography surgery is between 17.49078 and 18.50922 days.\nWe can calculate that the confidence interval for mean days waiting is narrower for the angiography surgery than for the bypass surgery, but it also may be easier to see in graph form:\n\n\n# add confidence intervals to df\nsurgical_procedure = c('Bypasss', 'Angiography')\nsample_size = c(bypass_n, angio_n)\nmean_wait_time = c(bypass_mean_wait_time, angio_mean_wait_time)\nstandard_deviation = c(bypass_sd, angio_sd)\nlower = c(bypass_lower, angio_lower)\nupper = c(bypass_upper, angio_upper)\n\ndf <- data.frame(surgical_procedure, sample_size, mean_wait_time, standard_deviation, lower, upper)\n\n# compare confidence intervals - plot\n\nggplot(df) +   \n  geom_point(aes(x = surgical_procedure, y = mean_wait_time), color = \"#9784c2\", size = 3) +\n  geom_errorbar(aes(x = surgical_procedure, ymin = lower, ymax = upper), color = \"#9784c2\", width = 0.5) +\n  labs(x = \"Surgical Procedure\", y = \"Mean Wait Time (Days)\") +\n  geom_text(aes(x = surgical_procedure, y = upper, label = round(upper, digits = 2)), \n            family = \"Avenir\", size=3, color = \"#33475b\", hjust = -3) +\n  geom_text(aes(x = surgical_procedure, y = lower, label = round(lower, digits = 2)), \n            family = \"Avenir\", size=3, color = \"#33475b\", hjust = -3) +\n  geom_text(aes(x = surgical_procedure, y = mean_wait_time, label = mean_wait_time), \n            family = \"Avenir\", size=3, color = \"#33475b\", hjust = -1) +\n  theme(axis.text.x = element_text(family = \"Avenir\", color = \"#33475b\", size=10),\n        axis.text.y = element_text(family = \"Avenir\", color = \"#33475b\", size=8),\n        axis.title.y = element_text(family = \"Avenir\", color = \"#33475b\", size=13),\n        axis.title.x = element_text(family = \"Avenir\", color = \"#33475b\", size=13))\n\n\n\n\nQuestion 2\nA survey of 1031 adult Americans was carried out by the National Center for Public Policy. Assume that the sample is representative of adult Americans. Among those surveyed, 567 believed that college education is essential for success. Find the point estimate, p, of the proportion of all adult Americans who believe that a college education is essential for success. Construct and interpret a 95% confidence interval for p.\nFirst, we want to find the point estimate (p) and then construct the confidence interval because that will be much more accurate than a single point.\n\n\n#find the point estimate\n\ncollege_education_essential <- 567\nsurvey_n <- 1031\n\npoint_estimate <- college_education_essential/survey_n\n\npoint_estimate\n\n\n[1] 0.5499515\n\nThe next thing I am going to do is calculate the margin of error on either side of the point estimate. For a 95% confidence interval, the alpha is 0.05, which means that the z-score is 1-(0.05/2) = 0.975). We can use the z-score because we are assuming a normal distribution and the sample size is greater than 30.\n\n\n# calculate the error\n\nerror <- qnorm(0.975)*sqrt(point_estimate*(1-point_estimate)/survey_n)\n\nerror\n\n\n[1] 0.03036761\n\n\n\n# calculate the confidence interval\n\nupper2 <- point_estimate + error\nlower2 <- point_estimate - error\n\nprint(c(lower2, upper2))\n\n\n[1] 0.5195839 0.5803191\n\nprint(c(round(lower2, digits = 3), round(upper2, digits = 3))) # round\n\n\n[1] 0.52 0.58\n\nHere we can see for that our sample proportion our point of estimate is 0.5499515. The 95% confidence interval indicates that the population mean is between .520 and .580. In other words, the percentage of Americans who believe college is important is between 52% and 58%. This means that when a a series of representative samples are created, 95% of the time the true mean should be between .520 and .580 (the result of % of Americans who believe college is important should be between 52% and 58%).\nAlternative Approach\nWe could also use prop.test() using the same numbers that would tell us automatically what the point of estimate and confidence are.\nconf.level = 0.95 (this is also the default for prop.test() but we will still specify)\nx = the number of “successes” (in this case it is the number of survey respondents who say that college education is needed)\nn = number of survey respondents.\n\n\n# calculate the confidence interval\n\nprop.test(x = 567, n = 1031, conf.level = 0.95)\n\n\n\n    1-sample proportions test with continuity correction\n\ndata:  567 out of 1031, null probability 0.5\nX-squared = 10.091, df = 1, p-value = 0.00149\nalternative hypothesis: true p is not equal to 0.5\n95 percent confidence interval:\n 0.5189682 0.5805580\nsample estimates:\n        p \n0.5499515 \n\nNOTE: There is a slight difference in the margin of error (less than .001). I suspect this has to do with how standard deviation is calculated (rounded) by the prop.test() in r. If we assume that we are rounding to the nearest hundredth this might not even be noticed.\nQuestion 3\nSuppose that the financial aid office of UMass Amherst seeks to estimate the mean cost of textbooks per quarter for students. The estimate will be useful if it is within $5 of the true population mean (i.e. they want the confidence interval to have a length of $10 or less). The financial aid office is pretty sure that the amount spent on books varies widely, with most values between $30 and $200. They think that the population standard deviation is about a quarter of this range. Assuming the significance level to be 5%, what should be the size of the sample?\nRight away we know a few key things:\nrange = the difference between $30 and $200 (170)\nz-value = significance level is 5%, the alpha is 0.05, which means that the z-score is 1-(0.05/2) = 0.975)\nmargin = the estimate is useful within $5 on either side, so the margin is 5.\nThe first thing we will do is calculate the standard deviation, which we know is a quarter of the range.\n\n\n#range - difference between $30 and $200\n\nrange <- 170\n\n#significance level is 5%, alpha is 0.5\nz <- qnorm(1-(0.05/2))\n\n#margin within $5 of the true population mean - margin = 5\n\nmargin <- 5\n\n#calculate sd (\"standard deviation is a quarter of the range\")\n\nsd <- range*0.25\n\nsd\n\n\n[1] 42.5\n\nNow that I have the standard deviation, I can calculate the sample size.\n\n\n#Now I can calculate the sample size with the formula n = (z-value/margin)^2.\n\nsample_size <- ((1.96*sd)/margin)^2\n\nsample_size\n\n\n[1] 277.5556\n\nround(sample_size, digits = 0) #round to the nearest whole person\n\n\n[1] 278\n\nRounding to the nearest whole person, we get 278. Interpreting that, in order for the financial aid office to estimate the mean cost of textbooks (+ or - $5) with a significance level of 5%, they should sample 278 students.\nQuestion 4\n(Exercise 6.7, Chapter 6 of SMSS, Agresti 2018) According to a union agreement, the mean income for all senior-level workers in a large service company equals $500 per week. A representative of a women’s group decides to analyze whether the mean income μ for female employees matches this norm. For a random sample of nine female employees, ȳ = $410’and s = 90.\nTest whether the mean income of female employees differs from $500 per week. Include assumptions, hypotheses, test statistic, and P-value. Interpret the result.\nReport the P-value for Ha : μ < 500. Interpret.\nReport and interpret the P-value for H a: μ > 500. (Hint: The P-values for the two possible one-sided tests must sum to 1.)\nAssumptions:\nnull hypothesis (H0) is that the mean weekly earnings for the population of women at the company is $500 per week: μ = 500\nalternative hypothesis (Ha) is that the mean weekly earnings for the population of women at the company is not $500 per week: μ =/= 500\nsample size = 9\nsample mean = 410\nsample standard deviation = 90\nFirst, I will find the t-score and then I will calculate the p-value. I will assume a 95% confidence level. t-statistic and use it to find the p-value. We can use t = (sample mean - hypothesized mean)/ (sample standard deviation / sqrt(n))\n\n\n# start with what we know\n\nsalary_mean <- 410\nsalary_sd <- 90\nsalary_n <- 9\n\n# find the t-score t = (sample mean - hypothesized mean) / (sample standard deviation / sqrt(n))\n# hypothesized mean = null hypothesis = 500\n\nsalary_t_score <- (salary_mean - 500)/(salary_sd/sqrt(salary_n))\n\nsalary_t_score\n\n\n[1] -3\n\n# now I will find the p-value using pt()\n\npt(q = salary_t_score, df = salary_n-1)*2 # multiplied by two because this is a two-tailed test\n\n\n[1] 0.01707168\n\nAt the 95% confidence interval we can reject the null hypothesis that mean income is $500 based on the alternate hypothesis that mean income is not $500 because the p value is less than .05. Additionally, we see that, at the 95% confidence interval, the null hypothesis ($500) falls outside of the interval.\nNow we’ll look at the p-value if the alternative hypothesis is μ < 500.\n\n\n#p-value of the right side only (less than 500)\n\npt(q = salary_t_score, df = salary_n-1)\n\n\n[1] 0.008535841\n\nAt the 95% confidence interval we can reject the null hypothesis that mean income is $500 based on the alternate hypothesis that mean income is less than $500 because the p value 0.001, which is less than 0.05.\nNow we’ll look at if the alternative hypothesis is μ < 500.\n\n\n#p-value of the left side only\n\npt(q = salary_t_score, df = salary_n-1, lower.tail = FALSE)\n\n\n[1] 0.9914642\n\nAt the 95% confidence interval we cannot reject the null hypothesis that mean income is $500 based on the alternate hypothesis that mean income is greater than $500 because the p value 0.99, which is greater than 0.05 and is not significant at that level.\nQuestion 5\n(Exercise 6.23, Chapter 6 of SMSS, Agresti 2018) Jones and Smith separately conduct studies to test H0: μ = 500 against Ha : μ ≠ 500, each with n = 1000. Jones gets ȳ = 519.5, with se = 10.0. Smith gets ȳ = 519. 7,with se = 10.0.\nShow that t = 1.95 and P-value = 0.051 for Jones. Show that t = 1.97 and P-value = 0.049 for Smith.\nUsing α = 0.05, for each study indicate whether the result is “statistically significant.”\nUsing this example, explain the misleading aspects of reporting the result of a test as “P ≤ 0.05” versus “P > 0.05,” or as “reject H0” versus “Do not reject H0 ,” without reporting the actual P-value.\nStarting with Jones, we will find the t and p values:\nt = (sample mean - null hypothesis)/(sample standard error).\nse = 10\nsample mean = 519.5\nnull hypothesis = 500\nWe will find the p-value using pt(). Since this is a two-tailed test, we will multiply the result by two.\n\n\n# t = (y-hat - H0)/se\n#Jones got population mean of 519.5 with standard error of 10.0\n\njones_t <- (519.5-500)/10\n\n# now we are conducting a 2-sided test. Find the area to the right of 1.95 and the area to the left of -1.95 to get p-value\n# use pt(); degrees of freedom are n-1 = 999\n# pt() finds the area to the left of a value\ndf <- 999\n\njones_p <- pt(q = -1.95, df = 999) + pt(q = 1.95, df = 999, lower.tail = FALSE) #lower tail + upper tail\n\njones_t\n\n\n[1] 1.95\n\njones_p\n\n\n[1] 0.05145555\n\nWe get the same results as the ones we are given; t = 1.95, p = 0.51.\nNow we will verify the t and p values for Smith:\nt = (sample mean - null hypothesis)/(sample standard error).\nse = 10\nsample mean = 519.7\nnull hypothesis = 500\nWe will find the p-value using pt(). Since this is a two-tailed test, we will multiply the result by two.\n\n\n# Smith got population mean of 519.7 with standard error of 10.0\n\nsmith_t <- (519.7-500)/10\n\n# now we are conducting a 2-sided test. Find the area to the right of 1.97 and the area to the left of -1.97 to get p-value\n\nsmith_p <- pt(q = -1.97, df = 999) + pt(q = 1.97, df = 999, lower.tail = FALSE) #lower tail + upper tail\n\nsmith_t\n\n\n[1] 1.97\n\nsmith_p\n\n\n[1] 0.04911426\n\nWe get the same results as the ones we are given; t = 1.97, p = 0.49.\nUsing a significance level of 0.05, Jones will not be able to reject the null hypothesis because his p-value is greater than 0.05 (0.051), and his results are deemed “not statistically significant. Smith, with a p-value of 0.049 is able to reject the null hypothesis and say his results are”statistically significant.\"\nThe issue is that both of these studies are have such similar results, but because one p-value is less than 0.05, that study is deemed significant and would get published, while the other one may not. Additionally, Smith reporting a result of “p < 0.05” rather than the actual p-value can be misleading because it is so close to 0.05, and the reader of the study may assume that the result is more significant than it actual is if they don’t know the actual p-value.\nQuestion 6\nAre the taxes on gasoline very high in the United States? According to the American Petroleum Institute, the per gallon federal tax that was levied on gasoline was 18.4 cents per gallon. However, state and local taxes vary over the same period. The sample data of gasoline taxes for 18 large cities is given below in the variable called gas_taxes.\n\n\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\n\n\n\nIs there enough evidence to conclude at a 95% confidence level that the average tax per gallon of gas in the US in 2005 was less than 45 cents? Explain.\nFirst we calculate what we can and use those values to calculate the t-score. We will assume that p = 0.05 because we are looking at a 95% confidence interval.\n\n\n# calculate values that we can\n\nmean_gt <- mean(gas_taxes) # mean\nsd_gt <- sd(gas_taxes) # standard deviation\nn_gt <- 18 # sample size\nse_gt <-(sd_gt/sqrt(18)) # standard error\n\n# calculate t-score using qt()\n# we know that the p = 0.05 because we are looking for the 95% confidence interval.\n# df = 18 - 1\n# we are looking for the lower.tail, which is the default (\"less than 45%\")\n\nt_gt <- qt(p = 0.05, df = 17)\n\nt_gt\n\n\n[1] -1.739607\n\nFrom here we can calculate the error margin on each side of the mean: error = t * sd/sqrt(n)\n\n\n# calculate margin of error t * sd/sqrt(n)\n\nme_gt <- t_gt * sd_gt/sqrt(n_gt)\n\n# then we get the upper and lower bounds of the confidence interval\n\nupper3 <- mean_gt + me_gt\nlower3 <- mean_gt - me_gt\n\nprint(c(upper3, lower3))\n\n\n[1] 37.04610 44.67946\n\nBased on the sample from the 18 cities, the 95% confidence interval for the average tax per gallon of gas in the US is between 37.05 cents and 44.68 cents.\nIf the null hypothesis is the average tax per gallon of gas is the US in 2005 45 cents (μ = 45), we reject the null hypothesis because the upper bound of the 95% confidence interval is 44.68 cents. If the alternate hypothesis is that the average tax per gallon of gas in the US in 2005 was less than 45 cents (μ < 45) than we accept the alternate hypothesis.\n\n\n\n",
    "preview": "posts/httpsrpubscomegeeslindacss-603-hw1/distill-preview.png",
    "last_modified": "2022-02-27T23:55:46-05:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/httpsrpubscomektracy866318/",
    "title": "HW1 V2",
    "description": "603 Homework 1",
    "author": [
      {
        "name": "Erin Tracy",
        "url": {}
      }
    ],
    "date": "2022-02-27",
    "categories": [],
    "contents": "\r\nQUESTION 1\r\nThe time between the date a patient was recommended for heart surgery and the surgery date for cardiac patients in Ontario was collected by the Cardiac Care Network (“Wait Times Data Guide,” Ministry of Health and Long-Term Care, Ontario, Canada, 2006). The sample mean and sample standard deviation for wait times (in days) of patients for two cardiac procedures are given in the accompanying table. Assume that the sample is representative of the Ontario population.\r\nConstruct the 90% confidence interval to estimate the actual mean wait time for each of the two procedures.\r\n\r\n\r\nconfidence_level <- 0.9\r\ns_size_bypass <- 539\r\ns_size_angio <- 847\r\nS_mean_bypass <- 19\r\ns_mean_angio <- 18\r\ns_sd_bypass <- 10\r\ns_sd_angio <- 9\r\n\r\ntail_area <- (1-confidence_level)/2\r\ntail_area\r\n\r\n\r\n[1] 0.05\r\n\r\nt_score_bypass <- qt(p = 1-tail_area, df = s_size_bypass-1)\r\nt_score_bypass\r\n\r\n\r\n[1] 1.647691\r\n\r\nt_score_angio <- qt(p = 1-tail_area, df = s_size_angio-1)\r\nt_score_angio\r\n\r\n\r\n[1] 1.646657\r\n\r\nCI_bypass <- c(S_mean_bypass - t_score_bypass * s_sd_bypass / sqrt(s_size_bypass),\r\n        S_mean_bypass + t_score_bypass * s_sd_bypass / sqrt(s_size_bypass))\r\n\r\nCI_bypass\r\n\r\n\r\n[1] 18.29029 19.70971\r\n\r\nCI_angio <- c(s_mean_angio - t_score_angio * s_sd_angio / sqrt(s_size_angio),\r\n       s_mean_angio + t_score_angio * s_sd_angio / sqrt(s_size_angio))\r\n\r\nprint(CI_bypass)\r\n\r\n\r\n[1] 18.29029 19.70971\r\n\r\nprint(CI_angio)\r\n\r\n\r\n[1] 17.49078 18.50922\r\n\r\n19.70971-18.29029\r\n\r\n\r\n[1] 1.41942\r\n\r\n18.50922-17.49078\r\n\r\n\r\n[1] 1.01844\r\n\r\nI followed the instructions to “Calculate Confidence Interval Manually” from the Tutorial to get to the following conclusions:\r\nThe 90% Confidence Interval for Bypass Surgery Wait Time Mean is 18.29029 to 19.70971 days\r\nThe 90% Confidence Interval for Angiography Surgery Wait Time Mean is 17.49078 to 18.50922 days\r\nIs the confidence interval narrower for angiography or bypass surgery?\r\nThe confidence interval is more narrow for angiography.\r\nQUESTION 2\r\nA survey of 1031 adult Americans was carried out by the National Center for Public Policy. Assume that the sample is representative of adult Americans. Among those surveyed, 567 believed that college education is essential for success. Find the point estimate, p, of the proportion of all adult Americans who believe that a college education is essential for success. Construct and interpret a 95% confidence interval for p.\r\n\r\n\r\nconfidence_level <- 0.95\r\nx <- 567\r\ns_size2 <- 1031\r\np <- x/s_size2\r\np\r\n\r\n\r\n[1] 0.5499515\r\n\r\n?prop.test\r\nprop.test(x,s_size2)\r\n\r\n\r\n\r\n    1-sample proportions test with continuity correction\r\n\r\ndata:  x out of s_size2, null probability 0.5\r\nX-squared = 10.091, df = 1, p-value = 0.00149\r\nalternative hypothesis: true p is not equal to 0.5\r\n95 percent confidence interval:\r\n 0.5189682 0.5805580\r\nsample estimates:\r\n        p \r\n0.5499515 \r\n\r\nBased on the sample, approximately 55% of adult Americans believe that college education is essential for success. p=0.55\r\nThe 95% confidence interval is 0.5189682 to 0.5805580.\r\nWe are 95% confident that between 51.9% and 58.1% of adult Americans believe that college education is essential for success.\r\nQUESTION 3\r\nSuppose that the financial aid office of UMass Amherst seeks to estimate the mean cost of textbooks per quarter for students. The estimate will be useful if it is within $5 of the true population mean (i.e. they want the confidence interval to have a length of $10 or less). The financial aid office is pretty sure that the amount spent on books varies widely, with most values between $30 and $200. They think that the population standard deviation is about a quarter of this range.\r\nAssuming the significance level to be 5%, what should be the size of the sample?\r\n\r\n\r\n#n=?\r\n\r\nz <- 1.96\r\nM <-5\r\nsd <- 170/4\r\nsd\r\n\r\n\r\n[1] 42.5\r\n\r\n(sd)*(sd)*(z/M)*(z/M)\r\n\r\n\r\n[1] 277.5556\r\n\r\nI found this formula in section 5.4 of the Agresti test book.\r\nSample size should be at least 278 books.\r\nQUESTION 4 (Exercise 6.7, Chapter 6 of SMSS, Agresti 2018) According to a union agreement, the mean income for all senior-level workers in a large service company equals $500 per week. A representative of a women’s group decides to analyze whether the mean income μ for female employees matches this norm. For a random sample of nine female employees, ȳ = $410 and s = 90.\r\nTest whether the mean income of female employees differs from $500 per week. Include assumptions, hypotheses, test statistic, and P-value. Interpret the result. Report the P-value for Ha : μ < 500. Interpret. Report and interpret the P-value for H a: μ > 500. (Hint: The P-values for the two possible one-sided tests must sum to 1.)\r\nH0= Mean=500 HA= Mean does not equal 500\r\n\r\n\r\ns_mean4 <- 500\r\ns_mean_alt <- 410\r\ns <- 90\r\nn4 <- 9\r\ndf4<- n4-1\r\ndf4\r\n\r\n\r\n[1] 8\r\n\r\nt.score4 <- (s_mean_alt - s_mean4)/(s*(sqrt(9)))\r\nt.score4\r\n\r\n\r\n[1] -0.3333333\r\n\r\np.value <- 2*pt(-abs(t.score4),df4)\r\np.value\r\n\r\n\r\n[1] 0.747451\r\n\r\ngreater_p.value <- pt(t.score4, df4, lower= FALSE)\r\ngreater_p.value\r\n\r\n\r\n[1] 0.6262745\r\n\r\nless_p.value <- pt(t.score4, df4, lower= TRUE)\r\nless_p.value\r\n\r\n\r\n[1] 0.3737255\r\n\r\ngreater_p.value+ less_p.value\r\n\r\n\r\n[1] 1\r\n\r\nI started by calculating T Score = (sample mean - population mean)/ (Standard Deviation/ Square Root of Sample Size). The T Score is -0.33333\r\nI got a little lost and used google to help my find the formulat to use the T Score to find the (2 sided) P Value , specifically https://www.cyclismo.org/tutorial/R/pValues.html and followed the example in section 10.2 since it seemed similar, to calculate the p.value.\r\nI multiplied 2 (since 2 sided) by the pt calculation using the T Score and Degrees of Freedom. The result was a p value of 0.7475. This is a large P Value, so this result suggests that we should not reject the original hypothesis that $500 is the mean income.\r\nI then calculated the p value in the case that the hypothesis is that the Mean income is greater than $500, the result was 0.6268. I then calculated the p value in the case that the hypothesis is that the Mean income is less than $500, the result was 0.3737. In both of these situations, there is not enough information to reject the original hypothesis. (However it seems more likely that the mean is actuallyless than $500 than it is more than $500.)\r\nThe sum of both p-values in this calculation is 1.\r\nQUESTION 5\r\n(Exercise 6.23, Chapter 6 of SMSS, Agresti 2018) Jones and Smith separately conduct studies to test H0: μ = 500 against Ha : μ ≠ 500, each with n = 1000. Jones gets ȳ = 519.5, with se = 10.0. Smith gets ȳ = 519.7, with se = 10.0. Show that t = 1.95 and P-value = 0.051 for Jones. Show that t = 1.97 and P-value = 0.049 for Smith. Using α = 0.05, for each study indicate whether the result is “statistically significant.” Using this example, explain the misleading aspects of reporting the result of a test as “P ≤ 0.05” versus “P > 0.05,” or as “reject H0” versus “Do not reject H0 ,” without reporting the actual P-value.\r\nH0 = Mean = 500 Ha = Mean does not equal 500 Sample Size = 1000\r\n\r\n\r\npopulation_mean <- 500\r\nn5 <- 1000\r\njones_mean <- 519.5\r\njones_Se <- 10\r\n\r\n\r\njones_t <- (jones_mean - population_mean)/(jones_Se)\r\njones_t\r\n\r\n\r\n[1] 1.95\r\n\r\n?pt\r\njones_pvalue <-2*pt(jones_t,(n5-1), lower.tail= FALSE)\r\njones_pvalue\r\n\r\n\r\n[1] 0.05145555\r\n\r\nsmith_mean <- 519.7\r\nsmith_se <- 10\r\n\r\nsmith_t <- (smith_mean - population_mean)/smith_se\r\nsmith_t\r\n\r\n\r\n[1] 1.97\r\n\r\nsmith_pvalue <-2*pt(smith_t,(n5-1), lower.tail= FALSE)\r\nsmith_pvalue\r\n\r\n\r\n[1] 0.04911426\r\n\r\nThe formulas above do indicate that t = 1.95 and P-value = 0.051 for Jones and t = 1.97 and P-value = 0.049 for Smith.\r\nTechnically the Jones p-value indicates that the Jones results are statistically significant, however they are very close to being insignificant- that should be noted. The Smith p-value indicates that the Smith results are not statistically significant since they are less than 0.05\r\nQUESTION 6\r\nAre the taxes on gasoline very high in the United States? According to the American Petroleum Institute, the per gallon federal tax that was levied on gasoline was 18.4 cents per gallon. However, state and local taxes vary over the same period. The sample data of gasoline taxes for 18 large cities is given below in the variable called gas_taxes.\r\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\r\nIs there enough evidence to conclude at a 95% confidence level that the average tax per gallon of gas in the US in 2005 was less than 45 cents? Explain.\r\n\r\n\r\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\r\n\r\nn6 <- 18\r\n\r\nsummary(gas_taxes)\r\n\r\n\r\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \r\n  18.49   35.95   41.48   40.86   47.95   54.41 \r\n\r\ngas_taxes_mean <- mean(gas_taxes)\r\ngas_taxes_mean\r\n\r\n\r\n[1] 40.86278\r\n\r\ngas_taxes_sd <- sd(gas_taxes)\r\ngas_taxes_sd\r\n\r\n\r\n[1] 9.308317\r\n\r\nconfidence_level6 <- 0.95\r\n\r\ntail_area6 <- (1 - confidence_level6)/2\r\ntail_area6\r\n\r\n\r\n[1] 0.025\r\n\r\nt_score6 <- qt(p = 1-tail_area, df = n6-1)\r\nt_score6\r\n\r\n\r\n[1] 1.739607\r\n\r\nCI <- c(gas_taxes_mean - t_score6 * gas_taxes_sd / sqrt(n6),\r\n        gas_taxes_mean + t_score6 * gas_taxes_sd / sqrt (n6))\r\n\r\nCI\r\n\r\n\r\n[1] 37.04610 44.67946\r\n\r\nI’m assuming this data is from 2005, though that’s not incredibly obvious. I’m assuming the sample of gas prices is the sum of local, state and federal.\r\nThe mean gas tax from the sample group is 40.86 cents.\r\nI again used the formula from our tutorial for calculating Confidence Interval Manually.\r\nI calculated the Confidence Interval of 95% based on the sample data provided. The CI is between 36.23 and 45.49\r\nSo I am 95% confident that the average gas tax per gallon in the US for the given time period was between 36.23 cents and 45.49 cents.\r\nBeing conservative, I don’t think it’s correct to say that I am 95% confident that the mean for all of the US gas taxes is less than 45 cents.\r\nR Markdown\r\nThis is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\r\nWhen you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:\r\nNote that the echo = FALSE parameter was added to the code chunk to prevent printing of the R code that generated the plot.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-27T23:56:06-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscommegangeorgesdacss603-hw1/",
    "title": "DACSS 603: Homework 1",
    "description": "Homework # 1 questions and answers for DACSS 603: Introduction to Quantitative Analysis",
    "author": [
      {
        "name": "Megan Georges",
        "url": {}
      }
    ],
    "date": "2022-02-27",
    "categories": [],
    "contents": "\r\nQuestion 1:\r\nThe time between the date a patient was recommended for heart surgery and the surgery date for cardiac patients in Ontario was collected by the Cardiac Care Network (“Wait Times Data Guide,” Ministry of Health and Long-Term Care, Ontario, Canada, 2006). The sample mean and sample standard deviation for wait times (in days) of patients for two cardiac procedures are given in the accompanying table. Assume that the sample is representative of the Ontario population. Construct the 90% confidence interval to estimate the actual mean wait time for each of the two procedures. Is the confidence interval narrower for angiography or bypass surgery?\r\n\r\n\r\nprocedure <- c('Bypass', 'Angiography')\r\nsamplesize <- c(539, 847)\r\nmeanwait <- c(19, 18)\r\nstandev <- c(10, 9)\r\n\r\nsurgdata <- data.frame(procedure, samplesize, meanwait, standev)\r\n\r\nkable(surgdata, col.names = c(\"Surgical Procedure\", \"Sample Size\", \"Mean Wait Time\", \"Standard Deviation\"), \r\n      align = c('c', 'c', 'c', 'c')) %>%\r\n    kable_styling(fixed_thead = TRUE)%>%\r\n  scroll_box(width = \"100%\", height = \"100%\")\r\n\r\n\r\n\r\n\r\nSurgical Procedure\r\n\r\n\r\nSample Size\r\n\r\n\r\nMean Wait Time\r\n\r\n\r\nStandard Deviation\r\n\r\n\r\nBypass\r\n\r\n\r\n539\r\n\r\n\r\n19\r\n\r\n\r\n10\r\n\r\n\r\nAngiography\r\n\r\n\r\n847\r\n\r\n\r\n18\r\n\r\n\r\n9\r\n\r\n\r\n\r\nAnswer:\r\nWe have the sample size, mean, and standard deviation and can assume the sample is representative of the Ontario population. We do not know the population mean or standard deviation. We will use the t-distribution to produce an interval estimate for the true mean wait times of the two procedures. According to the text (SMSS, section 5.6), “confidence intervals using the t-distribution apply with any n but assume a normal population distribution.”.\r\nUsing formula to calculate confidence intervals:\r\nI will use qt() to calculate the t-score since we know the sample distribution\r\nI will set p to .05 which accounts for .05 right tail and .05 left tail calculations to achieve the 90% confidence interval\r\ndf=n-1 for t-score\r\n\\(\\bar{y}\\) ± t(se)\r\n\r\n\r\n# Bypass procedure\r\nybarB <- 19\r\ntB <- qt(.05, df=539-1)\r\nseB <- 10/sqrt(539)\r\n\r\nybarB + tB*seB\r\n\r\n\r\n[1] 18.29029\r\n\r\nybarB - tB*seB\r\n\r\n\r\n[1] 19.70971\r\n\r\n# Angiography procedure\r\nybarA <- 18\r\ntA <- qt(.05, df=847-1)\r\nseA <- 9/sqrt(847)\r\n\r\nybarA + tA*seA\r\n\r\n\r\n[1] 17.49078\r\n\r\nybarA - tA*seA\r\n\r\n\r\n[1] 18.50922\r\n\r\nReporting the confidence intervals:\r\nWe can be 90% confident that the population mean wait time for the bypass procedure is between 18.29029 and 19.70971 minutes.\r\nWe can be 90% confident that the population mean wait time for the angiography procedure is between 17.49078 and 18.50922 minutes.\r\nWhich confidence interval is narrower?\r\n\r\n\r\n# Bypass confidence interval difference\r\n(ybarB - tB*seB)-(ybarB + tB*seB)\r\n\r\n\r\n[1] 1.419421\r\n\r\n# Angiography confidence interval difference\r\n(ybarA - tA*seA)-(ybarA + tA*seA)\r\n\r\n\r\n[1] 1.018436\r\n\r\nThe confidence interval for the angiography procedure is narrower than the confidence interval for the bypass procedure.\r\nQuestion 2:\r\nA survey of 1031 adult Americans was carried out by the National Center for Public Policy. Assume that the sample is representative of adult Americans. Among those surveyed, 567 believed that college education is essential for success. Find the point estimate, p, of the proportion of all adult Americans who believe that a college education is essential for success. Construct and interpret a 95% confidence interval for p.\r\nAnswer:\r\nSince the data is that of proportions, we will use prop.test() to calculate p and the 95% confidence interval.\r\n\r\n\r\nprop.test(567, 1031, conf.level = .95)\r\n\r\n\r\n\r\n    1-sample proportions test with continuity correction\r\n\r\ndata:  567 out of 1031, null probability 0.5\r\nX-squared = 10.091, df = 1, p-value = 0.00149\r\nalternative hypothesis: true p is not equal to 0.5\r\n95 percent confidence interval:\r\n 0.5189682 0.5805580\r\nsample estimates:\r\n        p \r\n0.5499515 \r\n\r\nThe point estimate, p, of the proportion of all adult Americans who believe that a college education is essential for success is 0.5499515.\r\nWe can be 95% confident that the population proportion who believe that a college education is essential for success is between 0.5189682 and 0.5805580.\r\nQuestion 3:\r\nSuppose that the financial aid office of UMass Amherst seeks to estimate the mean cost of textbooks per quarter for students. The estimate will be useful if it is within $5 of the true population mean (i.e. they want the confidence interval to have a length of $10 or less). The financial aid office is pretty sure that the amount spent on books varies widely, with most values between $30 and $200. They think that the population standard deviation is about a quarter of this range. Assuming the significance level to be 5%, what should be the size of the sample?\r\nAnswer:\r\nThe formula used to determine the sample size for estimating mean is n=\\(σ^{2}\\) (\\(\\frac{z}{M})^{2}\\).\r\nThe financial aid office estimates the population standard deviation to be about a quarter or the range, which is \\(\\frac{(200-30)}{4}\\).\r\nThe office wants the confidence interval to have a length of 10 dollars or less. Since confidence interval = point estimate ± margin of error, the margin of error in this case will be \\(\\frac{10}{2}\\).\r\nWith the significance level set at 5%, z=1.96.\r\n\r\n\r\n# Computing sample size\r\nstdevBooks <- (200-30)/4\r\nmargerrorBooks <- (10/2)\r\nzBooks <- 1.96\r\n\r\nstdevBooks^2 * (zBooks/margerrorBooks)^2\r\n\r\n\r\n[1] 277.5556\r\n\r\nTo achieve an estimate of the mean cost of books with the range of a 95% confidence interval equal to or less than $10, the sample size should be at least 278.\r\nQuestion 4:\r\n(Exercise 6.7, Chapter 6 of SMSS, Agresti 2018) According to a union agreement, the mean income for all senior-level workers in a large service company equals $500 per week. A representative of a women’s group decides to analyze whether the mean income μ for female employees matches this norm. For a random sample of nine female employees, ȳ = $410 and s = 90.\r\nTest whether the mean income of female employees differs from $500 per week. Include assumptions, hypotheses, test statistic, and P-value. Interpret the result.\r\nReport the P-value for Ha : μ < 500. Interpret.\r\nReport and interpret the P-value for H a: μ > 500.\r\n(Hint: The P-values for the two possible one-sided tests must sum to 1.)\r\nAnswer:\r\na.\r\nTo test whether the mean income of female employees differs from $500, we will perform a one-sample two-sided significance test for a mean (which uses t-statistic).\r\nWe assume that the sample is random and that the population has a normal distribution.\r\nNull hypothesis: \\(H_{0}\\): μ = 500\r\nAlternative hypothesis: \\(H_{a}\\): μ ≠ 500\r\nThe test statistic is t=\\(\\frac{ȳ-μ_{0}}{se}\\), where se=\\(\\frac{s}{\\sqrt{n}}\\)\r\nWe will reject the null hypothesis at a p-value less than or equal to α=.05\r\n\r\n\r\n# Calculate t-statistic:\r\n(410-500)/(90/sqrt(9))\r\n\r\n\r\n[1] -3\r\n\r\n# Calculate p-value\r\npt(-3, 8)*2 \r\n\r\n\r\n[1] 0.01707168\r\n\r\n# Multiply by 2 to account for two-tails\r\n\r\n\r\n\r\nThe test statistic is t=-3 and the p-value is P=0.01707168. With an α-level of .05, the p-value is substantially less than .05, thus we will reject the null hypothesis. There is strong evidence that the mean income of female employees is not equal to $500.\r\nb.\r\n\r\n\r\n# Calculate p-value for Ha: μ < 500\r\npt(-3, 8, lower.tail = TRUE)\r\n\r\n\r\n[1] 0.008535841\r\n\r\nThe p-value for \\(H_{a}\\): μ < 500 is P=0.008535841. With an α-level of .05, the p-value is substantially less than .05, thus we will reject the null hypothesis. There is evidence that the mean income of female employees is less than $500.\r\nc.\r\n\r\n\r\n# Calculate p-value for Ha: μ > 500\r\npt(-3, 8, lower.tail = FALSE)\r\n\r\n\r\n[1] 0.9914642\r\n\r\nThe p-value for \\(H_{a}\\): μ > 500 is P=0.9914642. With an α-level of .05, we fail to reject the null hypothesis. It is highly unlikely that the mean income of female employees is greater than $500.\r\nQuestion 5:\r\n(Exercise 6.23, Chapter 6 of SMSS, Agresti 2018) Jones and Smith separately conduct studies to test H0: μ = 500 against Ha : μ ≠ 500, each with n = 1000. Jones gets ȳ = 519.5, with se = 10.0. Smith gets ȳ = 519.7, with se = 10.0.\r\nShow that t = 1.95 and P-value = 0.051 for Jones. Show that t = 1.97 and P-value = 0.049 for Smith.\r\nUsing α = 0.05, for each study indicate whether the result is ‘statistically significant.’\r\nUsing this example, explain the misleading aspects of reporting the result of a test as “P ≤ 0.05” versus “P > 0.05,” or as “reject H0” versus “Do not reject H0 ,” without reporting the actual P-value.\r\nAnswer:\r\na.\r\n\r\n\r\n# Jones t=1.95, P=.051\r\nJonesT <- (519.5-500)/10\r\nJonesT\r\n\r\n\r\n[1] 1.95\r\n\r\nJonesP <- pt(1.95, 999, lower.tail = FALSE)*2\r\nJonesP\r\n\r\n\r\n[1] 0.05145555\r\n\r\n\r\n\r\n# Smith t=1.97, P=.049\r\nSmithT <- (519.7-500)/10\r\nSmithT\r\n\r\n\r\n[1] 1.97\r\n\r\nSmithP <- pt(1.97, 999, lower.tail = FALSE)*2\r\nSmithP\r\n\r\n\r\n[1] 0.04911426\r\n\r\nb.\r\nWith an α-level of .05, the p-values that both Jones (P=.051) and Smith (P=.049) found are very close to equivalent. Although Jones’ P-value is slightly greater than α=.05 and Smith’s P-value is slightly less than α=.05, the proximity of the results should yield the same conclusion. Both P-values provide moderate evidence to reject the null hypothesis and indicate that the mean is not equal to 500. If we were to technically interpret the P-values, then Jones’ test would fail to reject the null hypothesis, and Smith’s test would reject the null hypothesis.\r\nc.\r\nIf we fail to report the P-value and simply state whether the P-value is less than/equal to or greater than the defined significance level of the test, one cannot determine the strength of the conclusion. For example, a P-value of .009 for a significance level of .05 provides much stronger evidence to reject the null than a P-value of .045, however both values allow for rejection of the null at the significance level .05. In the Jones/Smith example, reporting the results only as “P ≤ 0.05” versus “P > 0.05” will lead to different conclusions about very similar results (rejecting versus failing to reject the null).\r\nQuestion 6:\r\nAre the taxes on gasoline very high in the United States? According to the American Petroleum Institute, the per gallon federal tax that was levied on gasoline was 18.4 cents per gallon. However, state and local taxes vary over the same period. The sample data of gasoline taxes for 18 large cities is given below in the variable called gas_taxes.\r\n\r\n\r\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\r\n\r\n\r\n\r\nIs there enough evidence to conclude at a 95% confidence level that the average tax per gallon of gas in the US in 2005 was less than 45 cents? Explain.\r\nAnswer:\r\n\r\n\r\nt.test(gas_taxes, mu = 18.4, conf.level = .95)\r\n\r\n\r\n\r\n    One Sample t-test\r\n\r\ndata:  gas_taxes\r\nt = 10.238, df = 17, p-value = 1.095e-08\r\nalternative hypothesis: true mean is not equal to 18.4\r\n95 percent confidence interval:\r\n 36.23386 45.49169\r\nsample estimates:\r\nmean of x \r\n 40.86278 \r\n\r\nThe 95% confidence interval for the mean tax per gallon is 36.23386 through 45.49169. We cannot conclude with 95% confidence that the mean tax is less than 45 cents, since the 95% confidence interval contains values above 45 cents (up to 45.49169).\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-27T23:55:42-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomtpaske870606/",
    "title": "Homework 1",
    "description": "Q1-Q6",
    "author": [
      {
        "name": "Tyler Paske",
        "url": {}
      }
    ],
    "date": "2022-02-27",
    "categories": [],
    "contents": "\r\nQuestion 1\r\nThe time between the date a patient was recommended for heart surgery and the surgery date for cardiac patients in Ontario was collected by the Cardiac Care Network (“Wait Times Data Guide,” Ministry of Health and Long-Term Care, Ontario, Canada, 2006). The sample mean and sample standard deviation for wait times (in days) of patients for two cardiac procedures are given in the accompanying table. Assume that the sample is representative of the Ontario population\r\nConstruct the 90% confidence interval to estimate the actual mean wait time for each of the two procedures. Is the confidence interval narrower for angiography or bypass surgery?\r\nAnswer\r\nTo construct the 90% confidence interval, we first need one piece of missing information, the “Z” value. A 90% confidence interval corresponds to a z value of 1.645 (within 2 standard deviations of the mean by convention). With all the needed pieces of the formula we can now compute the formula in R as shown with the code provided.\r\n                                              Bypass: [18.29,19.71] \r\nDifference = 1.42\r\nR-Code:\r\n\r\nqnorm(.95)\r\n\r\nHow I got .95 was by knowing the corresponding z value. A 90% confidence interval provides tails of .95, .10/2 = .5+.90 = .95 = z value of 1.645\r\n1.644854\r\ncenter <- 19\r\nstddev <-10\r\nn <- 539\r\nerror <- qnorm(0.95)*stddev/sqrt(n)\r\nerror 0.7084886\r\nlower_bound <- center - error\r\nlower_bound 18.29151\r\nupper_bound <- center + error\r\nupper_bound 19.70849\r\n                                           Angiography: [17.49,18.51]\r\nDifference = 1.02\r\nR-Code:\r\ncenter <-18\r\nstddev <-9\r\nn <- 847\r\nerror <- qnorm(0.95)*stddev/sqrt(n)\r\nerror 0.5086606\r\nlower_bound <- center - error\r\nlower_bound 17.49134\r\nupper_bound <- center + error\r\nupper_bound 18.50866\r\n• As we can see the confidence interval is narrower for Angiography. Bypass surgy being .4 more in difference than Angiography makes the confidence interval narrower for Angiography.\r\nQuestion 2\r\nA survey of 1031 adult Americans was carried out by the National Center for Public Policy. Assume that the sample is representative of adult Americans. Among those surveyed, 567 believed that college education is essential for success. Find the point estimate, p, of the proportion of all adult Americans who believe that a college education is essential for success. Construct and interpret a 95% confidence interval for p.\r\nAnswer\r\nUsing division (567/1031), I found that the point estimate “p” is 0.54995 of American Adults believed that college is essential for success while those that don’t are 45% of the population. To construct and interpret a 95% confidence interval for “p” requires further research using the following elements.\r\nSample proportion; 0.54995 = p\r\nThe sample size; 567 = x\r\nTotal Adults; 1031 = n\r\n\r\nprop.test(x=567, n=1031, p=0.54995, correct=FALSE)\r\n\r\n1-sample proportions test without continuity correction\r\ndata: 567 out of 1031,null probability 0.54995 X-squared = 9.415e-09, df = 1, p-value = 0.9999 alternative hypothesis: true p is not equal to 0.54995 95 percent confidence interval: [0.52, 0.58] sample estimates: p = 0.5499515\r\n                              Lower <- 0.52 Upper <-  0.58\r\nThe confidence interval at 95% has an interval of [.52, .58] which contains the difference between proportions. To further interpret, there are between 51-59% Americans who believe that a college education is essential for success when estimating the proportion.\r\n• The difference in this question from question 1 is that we didn’t have the standard deviation. Not having the standard deviation, we use the Confidence Interval for a Proportion Formula.\r\nQuestion 3\r\nSuppose that the financial aid office of UMass Amherst seeks to estimate the mean cost of textbooks per quarter for students. The estimate will be useful if it is within 5 dollars of the true population mean (i.e. they want the confidence interval to have a length of 10 dollars or less). The financial aid office is pretty sure that the amount spent on books varies widely, with most values between 30 dollars and $200. They think that the population standard deviation is about a quarter of this range. Assuming the significance level to be 5%, what should be the size of the sample?\r\nAnswer\r\nTo find the size of the sample you need the following.\r\nN = population size = 170\r\nz = z-score = 1.96\r\ne = margin of error = 95% or 10 as they want a confidence interval of 10\r\np = standard of deviation = 170/4 = 42.5\r\nSample mean = 170*.5 = 85\r\nNext we use the following standard formula to solve for the Sample Size.\r\n                             Sample Size = {(z*sd)/5}2 = 277.5556 \r\nQuestion 4\r\n(Exercise 6.7, Chapter 6 of SMSS, Agresti 2018) According to a union agreement, the mean income for all senior-level workers in a large service company equals 500 dollars per week. A representative of a women’s group decides to analyze whether the mean income μ for female employees matches this norm. For a random sample of nine female employees, ȳ = $410 and s = 90.\r\n##PART A Test whether the mean income of female employees differs from $500 per week. Include assumptions, hypotheses, test statistic, and P-value. Interpret the result.\r\n##Answer Assumptions\r\nType of data: Quantitative as the question represents amounts rather than groupings\r\nRandomization: As the question stands our random sample stands to hold a random sample of 9 female employees.\r\nPopulation distribution: Normal distribution.\r\nSample size “n”: 9 Population Mean: 500 Standard Deviation “s”: 90 Sample mean “y”:410\r\nHypothesis The hypothesis is as follows.\r\nHo : μ=$500 H1: μ≠$500\r\nHo is the null hypothesis and represents the population mean which is $500 H1 is the alternative hypothesis and represents the population proportion not equal to $500\r\n                                    Test Statistic & P – Value\r\n• To find the answer I turn to the one sample t-Test.\r\nPopulation Mean = 500 Sample Mean = 410 Sample Size = 9 Sample Standard Deviation = 90\r\n• Assuming the data is normally distributed and the significance of the test is .05\r\nT = (Xbar – μ) / sd / sqrt(n)\r\n(410-500) / 90 / sqrt(9) = -3\r\nThe probability the t value being -3 is less than 1 percent; .85% and since the alternative hypothesis (isn’t equal), we’ll need a two-tailed probability.\r\nq = t-score = -3\r\ndf = degrees of freedom (sample size “n”-1) = 9-1 = 8\r\nLeft-tailed test in R:\r\n                        p_value=pt(q=-3, df=8, lower.tail = TRUE)\r\n0.00853584\r\nThe P-value is as follows due to that we’re calculating a two tailed test,\r\n                                     2 * 0.0085 = 0.0171\r\nWith the P-Value of 0.0171 (lower than the significance level of .05) we can say that there is significance at p <.05 between women and senior level workers making the seniors pay “rejected”. There is enough evidence to say that the women aren’t paid as much.\r\nQuestion 4 B\r\nReport the P-value for Ha : μ < 500. Interpret.\r\nAnswer\r\nRemembering that this is calculated assuming the null hypothesis is true, we look further to the left sided tail test. The P-Value itself validates if a null hypothesis is true or not. The p value is a kind of “credibility rating” of a null hypothesis in light of evidence.\r\n• To find the p-value we must first get the following values\r\nq = t-score = -3 df = degrees of freedom (sample size “n”-1) = 9-1 = 8 Left-tailed test in R:\r\n                              p_value=pt(q=-3, df=8, lower.tail = TRUE)\r\n\r\np_value P-Value: 0.008535841\r\n\r\nIn this case, the p-value is significant. This shows that we can reject the null hypothesis or in other words reject the hypothesis that was claimed.\r\nQuestion 4 C\r\nReport and interpret the P-value for H a: μ > 500. (Hint: The P-values for the two possible one-sided tests must sum to 1.)\r\n##Answer Right-tailed test in R:\r\n                            p_value=pt(q=-3,df=8, lower.tail=FALSE)\r\n\r\np_value P-Value: 0.9914642\r\n\r\n                                  0.008535841 + 0.9914642 = 1\r\n    \r\nHaving the P-values for the two possible one-sided tests must sum to 1 I know that I came to right conclusion.\r\nQuestion 5A\r\n(Exercise 6.23, Chapter 6 of SMSS, Agresti 2018) Jones and Smith separately conduct studies to test H0: μ = 500 against Ha : μ ≠ 500, each with n = 1000. Jones gets ȳ = 519.5, with se = 10.0. Smith gets ȳ = 519.7, with se = 10.0\r\nShow that t = 1.95 and P-value = 0.051 for Jones. Show that t = 1.97 and P-value = 0.049 for Smith.\r\nAnswer\r\nTo first show the t test I used the test statistic formula: t = ȳ - μ / se\r\nJones <- (519.5 - 500) / 10\r\n                                   T-Test for Jones = 1.95\r\nSmith <- (519.7 – 500)/10\r\n                                   T-Test for Smith = 1.97 \r\nNow that we have the T-Tests for both Jones and smith we can solve for the P-Value. Remembering the formula used in question 4 we need the degrees of freedom and p = standard error. Degrees of freedom being n – 1 we find that df = 999.\r\np_value=pt(q=1.95, df=999, lower.tail = FALSE) Multiplied by 2 = .051\r\n                                    Jones P Value = 0.051\r\nPerforming the same operation for Smith we find the following, p_value=pt(q=1.97, df=999, lower.tail = FALSE) Multiplid by 2 = 0.049\r\n                                  Smiths P Value = 0.049\r\nQuestion 5B\r\nUsing α = 0.05, for each study indicate whether the result is “statistically significant.”\r\nAnswer\r\nWith a significance level α = 0.05, we can not reject the null hypothesis for Jones as his P Value is .051. The P Value being larger for Jones than the significance level also shows that the results are not statistically significant. Smith on the other hand is the opposite where his P-Value is less than the significance level and can reject the null hypothesis and are statistically significant.\r\nQuestion 5C\r\nUsing this example, explain the misleading aspects of reporting the result of a test as “P ≤ 0.05” versus “P > 0.05,” or as “reject H0” versus “Do not reject H0 ,” without reporting the actual P-value.\r\nAnswer\r\nThe misleading aspects of reporting the results of a test as “P ≤ 0.05” versus “P > 0.05,” or as “reject H0” versus “Do not reject H0 ,” without reporting the actual P-value is that they are based on arbitrary evaluations. Being presented with statistics that are based on random choice only shows one aspects of a situation where there can be an infinite number of outcomes. As an example, and to conclude my explanation we can’t have a binary justification as to reject or not reject a hypothesis as statistics can take a quick snapshot of a scenario in time but does not in any way describe the entire story. However, should we decide to look at a situation, snapshot or circumstance in time, the p-value does provide the best insight for the outcomes significance.\r\nQuestion 6\r\nAre the taxes on gasoline very high in the United States? According to the American Petroleum Institute, the per gallon federal tax that was levied on gasoline was 18.4 cents per gallon. However, state and local taxes vary over the same period. The sample data of gasoline taxes for 18 large cities is given below in the variable called gas_taxes.\r\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\r\nIs there enough evidence to conclude at a 95% confidence level that the average tax per gallon of gas in the US in 2005 was less than 45 cents? Explain.\r\nAnswer\r\n95% Confidence interval has a 5% significance level and 1.960 Z Value\r\n• We use the Z value amongst the following values to solve for the confidence interval\r\nConfidence interval Formula: X (+or–) Z s/sqrt(n)\r\n• X is the mean = 40.86278 • Z is the chosen Z-value from the table above = 1.960 • s is the standard deviation = 9.308317 • n is the number of observations = 18\r\nR CODE used\r\n\r\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\r\n\r\n\r\nmean(gas_taxes) [1] 40.86278\r\n\r\n• The last thing that we need in order to find the confidence interval is the standard deviation.\r\n\r\nsd(gas_taxes) [1] 9.308317\r\n\r\nThe value we derived from the formula for the confidence interval is the margin or error. [36.6, 45.2] We can conclude that yes, with 95% confidence the population mean is between 36.6 and 45.2, based on only 18 samples.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-27T23:55:55-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomclairebattagliahomework-1-603/",
    "title": "Homework 1",
    "description": "Statistical Inference",
    "author": [
      {
        "name": "Claire Battaglia",
        "url": "https://rpubs.com/clairebattaglia"
      }
    ],
    "date": "2022-02-24",
    "categories": [],
    "contents": "\n\nContents\nQuestion 1\nQuestion\nAnswer\nSolution\n\nQuestion 2\nQuestion\nAnswer\nSolution\n\nQuestion 3\nQuestion\nAnswer\nSolution\n\nQuestion 4\nQuestion\nAnswer\nSolution\n\nQuestion 5\nQuestion\nSolution\n\nQuestion 6\nQuestion\nAnswer\nSolution\n\n\nQuestion 1\nQuestion\nThe time between the date a patient was recommended for heart surgery and the surgery date for cardiac patients in Ontario was collected by the Cardiac Care Network (“Wait Times Data Guide,” Ministry of Health and Long-Term Care, Ontario, Canada, 2006). The sample mean and sample standard deviation for wait times (in days) of patients for two cardiac procedures are given in the accompanying table. Assume that the sample is representative of the Ontario population.\nSurgical Procedure\nSample Size (\\(n\\))\nMean Wait Time (\\(\\overline{x}\\))\nStandard Deviation (\\(s\\))\nbypass\n539\n19\n10\nangiography\n847\n18\n9\nConstruct the 90% confidence interval to estimate the actual mean wait time for each of the two procedures. Is the confidence interval narrower for angiography or bypass surgery?\nAnswer\nFor those undergoing bypass surgery the estimated mean wait time is between 18.29 and 19.71 days (19 \\(\\pm\\) .71 days).\nFor those undergoing angiography surgery the estimated mean wait time is between 17.49 and 18.51 days (18 \\(\\pm\\) .51 days).\nThe confidence interval is narrower for the population of patients undergoing angiography surgery.\nSolution\nThere are two populations: patients who have undergone bypass surgery and those who have undergone angiography surgery. I have a sample from each population and the mean and standard deviation of each sample.\nWhile I don’t know the sampling method(s), I am told each sample is representative of its corresponding population and I can see that each is large (\\(n>30\\)). Because the variable wait time is measured in days, I am working with discrete interval data, which I need to know in order to construct the confidence interval correctly.\nA confidence interval is essentially a “best guess” of a population parameter (called the point estimate), plus or minus a margin of error. The confidence level, which is frequently expressed as a percentage, is the proportion of trials in which the confidence interval would contain the true population mean. As a statement of proportion in the long run, it is only meaningful within the frequentist approach to statistics.\nThe confidence interval (\\(CI\\)) is a \\[{point\\;estimate}\\pm{margin\\;of\\;error}\\] where the \\[{margin\\;of\\;error} = t*{standard\\;error}\\] and the \\[{standard\\;error} = \\frac{\\sigma}{\\sqrt{n}}\\] Because I don’t know the true population mean (\\(\\mu\\)), I’ll use the sample mean (\\(\\overline{x}\\)) as my estimator (\\(\\hat{\\mu}\\)) of the population mean. Similarly, because I don’t know the true population standard deviation (\\(\\sigma\\)), I’ll use the sample standard deviation (\\(s\\)) as my estimator (\\(\\hat{\\sigma}\\)) of the population standard deviation. Because I don’t know the population standard deviation and am instead using the sample standard deviation as an estimate, I’m going to use the \\(t\\) distribution, which means I’ll be using a \\(t\\)-score instead of a \\(z\\)-score. It’s worth noting, however, that both samples are large enough that the \\(t\\) distribution will be essentially identical to the standard normal distribution.\nThis finally gives me the formula \\[CI=\\overline{x}\\;\\pm\\;\\left(t*\\frac{s}{\\sqrt{n}}\\right)\\] To calculate the \\(t\\)-score for a 90% confidence interval, I’m going to use R. Because the confidence interval is 90% (.9), the error probability (\\(\\alpha\\)) is .1. \\(\\alpha/2=5\\)%, or .05 on the right tail and .05 on the left tail.\n\n\nShow code\n\n# calculate quantile for t distribution\ntScoreBypass <- qt(p = .95, df = 538)\n\n# view\ntScoreBypass\n\n\n[1] 1.647691\n\nSo the final equation is \\[CI_{90}={19}\\;\\pm\\;\\left(1.647691*\\frac{10}{\\sqrt{539}}\\right)\\]\n\n\nShow code\n\n# calculate lower bound\nlowerBypass <- 19 - (1.647691*(10/sqrt(539)))\n\n# calculate upper bound\nupperBypass <- 19 + (1.647691*(10/sqrt(539)))\n\n# calculate range\nrangeBypass <- upperBypass - lowerBypass\n\n\n\nThe lower bound is 18.29029 and upper bound is 19.70971, making the range 1.41942.\nI’ll do the same calculations for my second population (patients who have undergone angiography surgery).\n\n\nShow code\n\n# calculate quantile for t distribution\ntScoreAngio <- qt(p = .95, df = 846)\n\n# view\ntScoreAngio\n\n\n[1] 1.646657\n\nSo the final equation is \\[CI_{90}={18}\\;\\pm\\;\\left(1.646657*\\frac{9}{\\sqrt{847}}\\right)\\]\n\n\nShow code\n\n# calculate lower bound\nlowerAngio <- 18 - (1.646657*(9/sqrt(847)))\n\n# calculate upper bound\nupperAngio <- 18 + (1.646657*(9/sqrt(847)))\n\n# calculate range\nrangeAngio <- upperAngio - lowerAngio\n\n\n\nThe lower bound is 17.49078 and the upper bound is 18.50922, making the range 1.01844.\nThis means that if I were to sample repeatedly from these two populations, 90% of the intervals created with these models would contain the true populations means.\nThe confidence interval is narrower for the angiography population (1.01844 \\(<\\) 1.41942). This is to be expected because the angiography sample size is larger and the standard deviation is smaller.\nQuestion 2\nQuestion\nA survey of 1031 adult Americans was carried out by the National Center for Public Policy. Assume that the sample is representative of adult Americans. Among those surveyed, 567 believed that college education is essential for success. Find the point estimate, p, of the proportion of all adult Americans who believe that a college education is essential for success. Construct and interpret a 95% confidence interval for p.\nAnswer\nThe point estimate is 0.55 and the 95% confidence interval is 0.52 to 0.58. That is, the estimated proportion of adult Americans who believe that college education is essential for success is 55% \\(\\pm\\) 3%.\nSolution\nThe population is all adult Americans and I have a representative sample (\\(n\\)) of 1031. Of those sampled, 567 believe that a college education is essential for success. This is enough information to calculate the sample proportion (\\(\\hat{\\pi}\\)), which I’ll then use to construct a 95% confidence interval for the true population proportion.\nTo construct the confidence interval, I’ll be using the formula \\[CI=\\hat{\\pi}\\;\\pm\\;z\\sqrt{\\left(\\frac{\\hat{\\pi}\\;(1-\\hat{\\pi})}{n}\\right)}\\] First, I’ll calculate the sample proportion, which will serve as my estimator for the true population proportion.\n\n\nShow code\n\n# calculate sample proportion\nsampProp <- 567/1031\n\n\n\nThus the sample proportion is 0.5499515\nIn a standard normal distribution 95% of all values fall within 1.96 standard deviations of the mean. Because I’m constructing a 95% confidence interval, then, the \\(z\\)-score I’ll be using is 1.96.\nThus \\[CI_{95}=0.5499515\\;\\pm\\;1.96\\sqrt{\\left(\\frac{0.5499515\\;(1-0.5499515)}{1031}\\right)}\\]\n\n\nShow code\n\n# calculate lower bound\nlowerBound <- sampProp - (1.96 * sqrt(((sampProp * (1-sampProp)/1031))))\n\n# calculate upper bound\nupperBound <- sampProp + (1.96 * sqrt(((sampProp * (1-sampProp)/1031))))\n\n\n\nThus the lower bound of the confidence interval is 0.52 and the upper bound is 0.58.\nThis means that using the sample proportion of 0.5499515 as the estimator (\\(\\hat{\\pi}\\)) for the true population proportion and constructing a 95% confidence interval, I can expect that 95% of trials would contain the true population mean within the interval of 0.52 and 0.58 (\\(\\pi\\pm.0304\\)).\nAlternatively, I can use the R function prop.test to calculate everything needed to answer this question. Since I’ve already calculated everything, I’ll simply use it to validate my calculations.\n\n\nShow code\n\n# calculate prop test\nprop.test(567, 1031, p = 0.5499515)\n\n\n\n    1-sample proportions test with continuity correction\n\ndata:  567 out of 1031, null probability 0.5499515\nX-squared = 0, df = 1, p-value = 1\nalternative hypothesis: true p is not equal to 0.5499515\n95 percent confidence interval:\n 0.5194543 0.5800778\nsample estimates:\n        p \n0.5499515 \n\nQuestion 3\nQuestion\nSuppose that the financial aid office of UMass Amherst seeks to estimate the mean cost of textbooks per quarter for students. The estimate will be useful if it is within $5 of the true population mean (i.e. they want the confidence interval to have a length of $10 or less). The financial aid office is pretty sure that the amount spent on books varies widely, with most values between $30 and $200. They think that the population standard deviation is about a quarter of this range. Assuming the significance level to be 5%, what should be the size of the sample?\nAnswer\nThe sample size should be 278.\nSolution\nThe formula for determining the sample size for estimating a population mean (\\(\\mu\\)) is \\[n=\\sigma^2\\left(\\frac{z}{M}\\right)^2\\] where \\(n\\) is the sample size (what I’m trying to find), \\(\\sigma\\) is the population standard deviation, \\(z\\) is the \\(z\\)-score for the chosen confidence level, and \\(M\\) is the margin of error.\nWhile I don’t know the true population standard deviation (\\(\\sigma\\)), I am given an estimate, which will suffice. The suspected range is 170 and I am told the population standard deviation is estimated to be about a quarter of that, which is 42.50.\nIf the significance level (\\(\\alpha\\)) is 5%, then the confidence level is 95% (\\(1-{confidence\\;level}=\\alpha\\)). Assuming a normal distribution, the \\(z\\)-score for a 95% confidence level is 1.96.\nThe margin of error is 5.\nThus \\[n=42.5^2\\left(\\frac{1.96}{5}\\right)^2\\]\n\n\nShow code\n\n# calculate sample size\nn <- (42.5^2)*((1.96/5)^2)\n\n\n\nwhich indicates that a sample size of 277.5556 is required to estimate the population mean with a 95% confidence interval.\nBecause the units in the sample are people (i.e. a discrete unit), I’ll round up to the nearest whole number, giving me a total of 278.\n\nBecause I need a minimum of 277.5556, I would round up to the nearest whole number regardless of what the normal rule for rounding would indicate.\nThis means that I would need to sample a minimum of 278 people to estimate the mean cost of textbooks per student per quarter within plus or minus $5. If I repeatedly sample at least this number of people, 95% of the intervals constructed would contain the true population mean.\nQuestion 4\nQuestion\nAccording to a union agreement, the mean income for all senior-level workers in a large service company equals $500 per week. A representative of a women’s group decides to analyze whether the mean income μ for female employees matches this norm. For a random sample of nine female employees, ȳ = $410 and s = 90.\nTest whether the mean income of female employees differs from $500 per week. Include assumptions, hypotheses, test statistic, and P-value. Interpret the result.\nReport the P-value for Ha : μ < 500. Interpret.\nReport and interpret the P-value for Ha: μ > 500. (Hint: The P-values for the two possible one-sided tests must sum to 1.)\nAnswer\nThere is sufficient evidence to reject the null hypothesis and thereby accept the alternative hypothesis that the mean income for female employees does not equal $500 per week. The test statistic is -3. The \\(P\\)-value is .017.\nFor \\(H_a:\\mu<500\\), the \\(P\\)-value is .009. Because the \\(P\\)-value is less than the most stringent significance level of .01, we can reject the null hypothesis (\\(H_0:\\mu\\ge500\\)) and thereby accept the alternative hypothesis.\nFor \\(H_a:\\mu>500\\), the \\(P\\)-value is .991. Because the \\(P\\)-value is greater than the significance level of .01 (and even the more lenient .05), we cannot reject the null hypothesis (\\(H_0:\\mu\\le500\\)) at this time.\nSolution\nTo solve this problem, I’m going to assume:\nA normal population distribution.\nThe sample of female employees is sufficiently large.\nTo begin, I’ll identify the null hypothesis (\\(H_0\\)) and alternative hypothesis (\\(H_a\\)).\nThe null hypothesis is that there is no difference between the mean for female employees and the mean for all employees. That is, the mean for female employees is also 500.\n\\[{H_0:}\\;\\mu = 500\\] The alternative hypothesis is that there is a difference. That is, the mean for female employees is not 500. Because I’m interested in any kind of difference (\\(\\mu < 500\\) or \\(\\mu > 500\\)), I’ll be using a two-sided test.\n\\[{H_a:}\\;\\mu\\neq 500\\] Conducting a hypothesis test asks whether what we’ve observed (\\(\\overline{y}=410\\)) would be so unlikely if the null hypothesis (\\(H_0=500\\)) were true that we are obligated to reject it. If we find that what we observed is not that unlikely and could reasonably be explained by sample variability, we will not be able to reject the null hypothesis at this time.\nThe formula for calculating the test statistic is \\[t=\\frac{\\overline{y}-\\mu_0}{se}\\] where \\[se=\\frac{s}{\\sqrt{n}}\\] Thus the standard error is \\[se=\\frac{90}{\\sqrt{9}}\\] and \\[t=\\frac{410-500}{30}\\]\n\n\nShow code\n\n# calculate estimated standard error\nse <- 90/sqrt(9)\n\n# calculate test statistic\ntestStat <- (410-500)/se\n\n\n\n\\(t=\\) -3 and \\(|t|=\\) 3\nNext I’ll calculate the \\(P\\)-value.\n\n\nShow code\n\n# calculate 2-sided P value\npValue <- 2 * (1-pt(q = 3, df = 8))\n\n\n\nThus the \\(P\\)-value \\(=\\) 0.0170717\nThis indicates a 0.0170717 probability that we would observe the sample mean (\\(\\overline{y}\\)) of 410 if the null hypothesis were true. That is, if the mean for female employees (\\(\\mu\\)) were really 500. While this finding isn’t significant at the .01 level, it is significant at the .05 level and I can conclude that if the mean for female employees were 500, I’d be rather unlikely to end up with a sample mean of 410. I feel comfortable, then, in rejecting the null hypothesis and accepting the alternative hypothesis.\nNow I’ll look at the probabilities that the sample mean would be above or below the population mean separately.\n\n\nShow code\n\n# calculate P value for Ha > 500, right-tail\npValueG <- 1-pt(q = 3, df = 8, lower.tail = FALSE)\n\n# calculate P value for Ha < 500, left-tail\npValueL <- 1-pValueG\n\n\n\nFor \\(H_a:\\mu<500\\), \\(P=\\) 0.009. This indicates a 0.009 probability that we would have observed a \\(t\\)-score equal to or lesser than what we what we did in fact observe if the null hypothesis (\\(H_0:\\mu\\ge500\\)) were true. Put more simply, if the null hypothesis were true, it is highly unlikely we would have observed what we observed. We can reject the null hypothesis.\nFor \\(H_a:\\mu>500\\), \\(P=\\) 0.991. This indicates a 0.991 probability that we would have observed a \\(t\\)-score equal to or greater than what we did in fact observe if the null hypothesis (\\(H_0:\\mu\\le500\\)) were true. That is, if the null hypothesis were true, it is highly likely we would have observed what we observed. We can accept the null hypothesis.\nTaken together these lend strong support to the claim that the mean income for female employees is less than the mean for all employees.\nQuestion 5\nQuestion\nJones and Smith separately conduct studies to test H0: μ = 500 against Ha : μ ≠ 500, each with n = 1000. Jones gets ȳ = 519.5, with se = 10.0. Smith gets ȳ = 519.7, with se = 10.0.\nShow that t = 1.95 and P-value = 0.051 for Jones. Show that t = 1.97 and P-value = 0.049 for Smith.\nUsing α = 0.05, for each study indicate whether the result is “statistically significant.”\nUsing this example, explain the misleading aspects of reporting the result of a test as “P ≤ 0.05” versus “P > 0.05,” or as “reject H0” versus “Do not reject H0 ,” without reporting the actual P-value.\nSolution\nThe formula for calculating the test statistic is \\[t=\\frac{\\overline{y}-\\mu_0}{se}\\] Since they both assume the population mean (\\(\\mu\\)) to be 500 (the null hypothesis) and they both got a standard error of 10, the only difference between their tests is the mean of each of their samples (\\(\\overline{y}\\)).\nThus Jones’s test statistic is \\[t=\\frac{{519.5}-{500}}{10}\\] and Smith’s is \\[t=\\frac{{519.7}-{500}}{10}\\]\n\n\nShow code\n\n# calculate test stat Jones\ntStatJ <- (519.5-500)/10\n\n# calculate test stat Smith\ntStatS <- (519.7-500)/10\n\n\n\nFor Jones, \\(t=\\) 1.95\nFor Smith, \\(t=\\) 1.97\nNow I’ll calculate the \\(P\\)-value for each of them. This will tell me the probability of observing the data they actually observed if the null hypothesis is true. Since the alternative hypothesis is non-directional, I’ll calculate the two-sided probability.\n\n\nShow code\n\n# calculate P value Jones\npJones <- 2*pt(q = tStatJ, df = 999, lower.tail=FALSE)\n\n# calculate P value Smith\npSmith <- 2*pt(q = tStatS, df = 999, lower.tail=FALSE)\n\n\n\nFor Jones, \\(P=\\) 0.051\nFor Smith, \\(P=\\) 0.049\nSince the significance level (\\(\\alpha\\)) is .05, Jones is unable to reject the null hypothesis at this time (\\(.051>.05\\)) and his/her results are not statistically significant. Smith, however, is able to reject the null hypothesis (\\(.049<.05\\)) and can claim that his/her results are statistically significant (at the level of .05).\nThis example illustrates the danger of living and dying by whether or not the \\(P\\)-value is statistically significant. For example, if a statistically significant finding is requisite for publishing, then only Smith’s finding would make its way to a larger audience. If the \\(P\\)-value were not included, the reader might wrongly assume that the evidence for rejecting the null hypothesis is strong, when in reality it only nudges us towards that conclusion.\nAlternatively, if both findings were published and the \\(P\\)-values were not included, the reader would see that Jones does not reject the null hypothesis but that Smith does and might wrongly believe that their findings were contradictory. Including the \\(P\\)-values, however, would allow the reader to see that the findings are actually not contradictory.\nIt’s important to remember that the significance level is an arbitrary demarcation. This is ultimately a problem of using a binary framework (reject/fail to reject) in a world in which very few things (if any) are actually binary. Maintaining a larger perspective is paramount—statistics can and should inform our understanding of the world but significance testing is not a substitute for critical thinking.\nQuestion 6\nQuestion\nAre the taxes on gasoline very high in the United States? According to the American Petroleum Institute, the per gallon federal tax that was levied on gasoline was 18.4 cents per gallon. However, state and local taxes vary over the same period. The sample data of gasoline taxes for 18 large cities is given below in the variable called gas_taxes.\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\nIs there enough evidence to conclude at a 95% confidence level that the average tax per gallon of gas in the US in 2005 was less than 45 cents? Explain.\nAnswer\nYes, there is sufficient evidence to reject the null hypothesis and thereby accept the alternative hypothesis that in 2005 the average gas tax in the United States was less than 45.00 cents.\nSolution\nTo answer this question, I’m going to conduct a one-sided significance test. To do so, I’m going to assume a random sample and normal distribution.\nThe null hypothesis is that the average tax per gallon is 45.00 cents. \\[H_0:\\mu=45.00\\] The alternative hypothesis is that the average tax per gallon is less than 45.00 cents. \\[H_a:\\mu<45.00\\] Conducting a hypothesis test asks whether the observed data (the gas taxes for the 18 cities in our sample) would be so unlikely if the null hypothesis were true that we are forced to reject it.\nFirst I’ll load the given sample data and calculate some summary statistics.\n\n\nShow code\n\n# create vector of sample data\ngasTaxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\n\n# calculate mean\nsampMean <- mean(gasTaxes)\n\n# calculate sd\nsampSD <- sd(gasTaxes)\n\n\n\nThe sample mean (\\(\\overline{y}\\)) is 40.8627778 and the sample standard deviation (\\(s\\)) is 9.3083168.\nThe formula for calculating the test statistic is \\[t=\\frac{\\overline{y}-\\mu_0}{se}\\] where \\[se=\\frac{s}{\\sqrt{n}}\\] Thus \\[se=\\frac{9.3083168}{\\sqrt{18}}\\] and \\[t=\\frac{40.8627778-45.00}{2.193991}\\]\n\n\nShow code\n\n# calculate standard error\nse <- 9.3083168/sqrt(18)\n\n# calculate t statistic\ntStatGas <- (40.8627778-45.00)/se\n\n\n\nThus the test statistic is -1.8857058.\nFinally, I’ll calculate the \\(P\\)-value.\n\n\nShow code\n\n# calculate P value\npGas <- pt(q = tStatGas, df = 17, lower.tail=TRUE)\n\n\n\nThus the \\(P\\)-value is 0.038\nThis means that if the null hypothesis were true there is a 0.038 probability of observing the data we observed or data more extreme.\nA 95% confidence interval means a significance level of .05 (\\(1-{confidence\\;level}=\\alpha\\)). Given that the \\(P\\)-value is less than the significance level of .05, I can say that, yes, given a 95% confidence interval there is sufficient evidence to reject the null hypothesis and accept the alternative hypothesis that in 2005 the average gas tax in the United States was less than 45.00 cents.\nAlternatively, I can use the R function t.test to calculate everything needed to answer this question. Since I’ve already calculated everything, I’ll simply use it to validate my calculations.\n\n\nShow code\n\nt.test(gasTaxes, mu = 45.00, alternative = \"less\")\n\n\n\n    One Sample t-test\n\ndata:  gasTaxes\nt = -1.8857, df = 17, p-value = 0.03827\nalternative hypothesis: true mean is less than 45\n95 percent confidence interval:\n     -Inf 44.67946\nsample estimates:\nmean of x \n 40.86278 \n\nAnother approach to hypothesis testing is constructing the appropriate confidence interval and determining whether the mean of the null hypothesis is contained within that interval or not.\nThe t.test function has returned the confidence interval and since I’m looking at it only to confirm my decision to reject the null hypothesis, I won’t calculate it manually. Because the alternative hypothesis is directional, the confidence interval is likewise one-sided. In this case it is [-\\(\\infty\\), 44.67946]. This interval does not contain the mean of the null hypothesis, which confirms my decision to reject the null hypothesis.\n\nIt’s worth noting that the upper bound of the interval is close to 45.00. This raises the question of whether the difference has any practical significance. I don’t follow conversations about gas tax policy so I can’t comment on how meaningful it is to say that the average tax is less than 45.00 cents if it could reasonably be 44.68 cents.\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-24T15:25:17-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomjflattery870090/",
    "title": "Homework 1",
    "description": "My HW 1 for 603",
    "author": [
      {
        "name": "Justin Flattery",
        "url": {}
      }
    ],
    "date": "2022-02-24",
    "categories": [],
    "contents": "\n\n\nknitr::opts_chunk$set(echo = TRUE)\n\n\n\nQuestion 1\nFor each procedure we will construct a confidence interval around our estimate of the actual mean by fitting the sample about a t distribution. We can do this since we have the sample mean, sample size (thus degrees of freedom) and sample standard deviation\nBYPASS Confidence Interval\nFirst we will find the T score associated with the degrees of freedom and level of confidence\n\n\nqt(p = .9, df = 538)\n\n\n[1] 1.283127\n\nWe will now plug this t score into the formula to find the standard error,\n\n\n(1.283127 * (10/(sqrt(539))))\n\n\n[1] 0.5526819\n\nWe will now add/subtract the sample mean from the standard error to produce our 90% confidence interval\n\n\n19 + (1.283127 * (10/(sqrt(539))))\n\n\n[1] 19.55268\n\n\n\n19 - (1.283127 * (10/(sqrt(539))))\n\n\n[1] 18.44732\n\nTherefore the 90% confidence interval for bypass surgery is [18.45,19.55]\nAngiography Procedure\nAgain we will find the T score associated with the degrees of freedom and level of confidence)\n\n\nqt(p = .9, df = 846)\n\n\n[1] 1.282553\n\nWe will now plug this t score into the formula to find the standard error\n\n\n(1.282553 * (9/(sqrt(847))))\n\n\n[1] 0.3966214\n\nWe will now add/subtract the sample mean from the standard error to produce our 90% confidence interval\n\n\n18 + (1.282553 * (9/(sqrt(847))))\n\n\n[1] 18.39662\n\n18 - (1.282553 * (9/(sqrt(847))))\n\n\n[1] 17.60338\n\nTherefore the 90% confidence interval for angiography surgery is [17.6,18.40]\nWhich is narrower?\nAngiography - 17.60 - 18.39 Bypass - 18.45 - 19.55\nAngiography surgery because it has a smaller range to its interval (0.79 vs 1.1)\nQuestion 2 n=1031 567=success 95% confidence\n\n\n567/1031\n\n\n[1] 0.5499515\n\nPoint estimate: 0.55 - 55% of americans believe\nI will use r’s prop test formula to find the 95% confidence interval for p, using the knowledge of 567 believed in a 1031 sample.\n\n\nprop.test(567,1031,conf.level = 0.95)$conf.int\n\n\n[1] 0.5189682 0.5805580\nattr(,\"conf.level\")\n[1] 0.95\n\nQuestion 3 First I will find the population standard deviation based on information about range\n\n\nsigma = (200-30)/4\n\n\n\nNext, given the information above, assuming we have the population standard deviation, we can assume a normal distribution of the sample. So I will find the z value based on a significance level of 5%. Since this will be a two tailed sample, this will leave 2.5% on each side, so I will find for (0.975)\n\n\nzstar = qnorm(.975)\n#I will input 42.5 as my sigma (population sd variable)\nsigma = 42.5\n#E is my desired width/range of my confidence interval\nE = 10\n\n\n\nI will now input these variables into the appropriate formula - z^2 * sigma^2 / (E^2) to find the necessary sample size\n\n\n(zstar*zstar) * (sigma*sigma)/ (E*E)\n\n\n[1] 69.38635\n\nSince the value is 69.38, we will round up to the next whole number, 70 in order to ensure we have a large enough sample to estimate the mean\nQuestion 4 In order to evaluate if the mean income is different for female employees, we must set up a hypothesis test. In order to evaluate whether it is NOT $500 we will set a null hypothesis that the mean income = $500 per week. The alternative hypothesis will be the opposite of this, that it is different from $500 a week so:\nH0: mu= $500 Ha mu not = 500\nTest assumes data obtained through randomization and sample is representative of larger population.\nFirst we will find the value of the test statistic (tscore), (how far the sample distance is from the mean in a t distribution)\n\n\n(410 - 500)/((90/3))\n\n\n[1] -3\n\nWe will next use r to find the value of p (the probability of observing this occurrence assuming the null hypothesis)for a two tailed test, inputting our test statistic of -3 and df (9-1)\n\n\n2*pt(q=-3, df=8, log = FALSE)\n\n\n[1] 0.01707168\n\nThis produces a p value of 0.017. Since this is a very small number ( less than 0.05), it indicates a very small probability of occurrence and that we can reject the null hypothesis that the population mean is 500 at the 5% significance level.\nB For part b) We will set up a different hypothesis: H0: mu> $500 Ha mu < $500\nWe will plug in the same values (t statistic, df) but use a one tailed test:\n\n\npt(q=-3, df=8,lower.tail = TRUE)\n\n\n[1] 0.008535841\n\nThis produces a p value of 0.008. Since this is a very small number ( less than 0.05), it indicates a very small probability of occurrence and that we can reject the null hypothesis that the population mean is greater than 500 at the 5% significance level.\nC\nFor part c) We will set up a different hypothesis:\nH0: mu< $500 Ha mu > $500\n\n\npt(q=-3, df=8, lower.tail = FALSE)\n\n\n[1] 0.9914642\n\nThis produces a p value of 0.99. Since this is a very large number/close to one and greater than significance level of 0.05, it indicates a very high probability of occurrence and therefore we cannot reject the null hypothesis that the population mean is less than 500 at the 5% significance level.\nQuestion 5 H0: μ = 500 Ha : μ = 500, each with n = 1000. Jones has ȳ = 519.5, with se = 10.0. Smith has ȳ = 519.7, with se = 10.0.\nFirst I will find the t statistic for Jones using formula used in previous questions\n\n\n(519.5 - 500)/(10)\n\n\n[1] 1.95\n\nJones calculating p value\n\n\n2*pt(q=1.95, df=499, lower.tail=FALSE)\n\n\n[1] 0.05173574\n\nNow I will find the t statistic for Smith using formula used in previous questions\n\n\n(519.7 - 500)/(10)\n\n\n[1] 1.97\n\nSmithh calcultaing p value\n\n\n2*pt(q=1.97, df=499, lower.tail=FALSE)\n\n\n[1] 0.04939092\n\nThe result for Smith is statistically significant at the 5% level (since the value of p is 0.049 <.05), the result for Jones it is not statistically significant at 5% level (p = 0.051>.05)\nWithout reporting the actual p value , data can be manipulated to state the sample is significant for example, for Jones, it would be misleading to round down 0.051 to 0.05 and report that p is less than or equal to 0.05, and thus statistically significant. By reporting instead as the reality that P>0.05 (with p included) is much more transparent. Additionally, the p value should be reported along with the significance level when making a statement around rejecting the null hypothesis. For example, we could reject the null hypothesis at the 10% level for Smith - but this would be manipulating the data from our original planned significance level.\nQuestion 6\nFirst I will load in the dataset of gas_taxes based on the sample\n\n\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\n\n\n\nNext, I used r to calculate a t test of the data set under a 95% confidence level\n\n\nt.test(gas_taxes, conf.level = 0.95)$conf.int\n\n\n[1] 36.23386 45.49169\nattr(,\"conf.level\")\n[1] 0.95\n\nConclusion - No - the upper bound of a 95% confidence interval is over 45 cents, therefore we can not definitively say that the average tax per gallon was less than 45C.\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-24T15:25:20-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomkbec864954/",
    "title": "Homework 1 DACSS 603",
    "description": "Descriptive Statistics, Probability, Statistical Inference, and Comparing Two Means",
    "author": [
      {
        "name": "Kristina Becvar",
        "url": {}
      }
    ],
    "date": "2022-02-24",
    "categories": [],
    "contents": "\r\nQuestion 1\r\nSurgical Procedure - Representative Sample\r\nSurgical Procedure\r\nSample Size\r\nMean Wait Time\r\nStandard Deviation\r\nBypass\r\n539\r\n19\r\n10\r\nAngiography\r\n847\r\n18\r\n9\r\nConstruct the 90% confidence interval to estimate the actual mean wait time for each of the two procedures.\r\nIs the confidence interval narrower for angiography or bypass surgery?\r\nAnswer 1\r\nI calculated the answer by first calculating the standard error for each procedure given the mean, standard deviation, and sample size for each. I do so using 0.95 for the qnorm function so that I can determine the 5% confidence level for both the right and left side of the normal distribution, since the sample is larger than n=30. By calculating the 5% margin for each side of the distribution, this gives me the effective 90% confidence interval overall.\r\n\r\n\r\n#Calculate the actual mean wait time for the bypass:\r\n\r\nxbar1 <- 19 #sample mean\r\nsd1a <- 10 #sample standard deviation\r\nn1a <- 539 #sample size\r\n\r\nerror1a <- qnorm(0.95)*sd1a/sqrt(n1a)\r\nerror1a\r\n\r\n\r\n[1] 0.7084886\r\n\r\nlower1a <- xbar1-error1a\r\nupper1a <- xbar1+error1a\r\n\r\nlower1a\r\n\r\n\r\n[1] 18.29151\r\n\r\nupper1a\r\n\r\n\r\n[1] 19.70849\r\n\r\n\r\n\r\n#Calculate the actual mean wait time for the angiography:\r\n\r\nxbar1b <- 18 #sample mean\r\nsd1b <- 9 #sample standard deviation\r\nn1b <- 847 #sample size\r\n\r\nerror1b <- qnorm(0.95)*sd1b/sqrt(n1b)\r\nerror1b\r\n\r\n\r\n[1] 0.5086606\r\n\r\nlower1b <- xbar1b-error1b\r\nupper1b <- xbar1b+error1b\r\n\r\nlower1b\r\n\r\n\r\n[1] 17.49134\r\n\r\nupper1b\r\n\r\n\r\n[1] 18.50866\r\n\r\nNext, I created a data frame with the information.\r\n\r\n\r\nShow code\r\n\r\n#Create a data frame with the information:\r\n\r\ndf1 <- data.frame( c('Bypass', 'Angiography')\r\n                   ,c(19, 18)\r\n                   ,c(539, 847)\r\n                   ,c(10, 9)\r\n                   ,c(18.29151, 17.49134)\r\n                   ,c(19.70849, 18.50866))\r\nnames(df1) <- c('Procedure', 'Mean', 'Sample', 'SD', 'Lower', 'Upper')\r\n\r\ndf1\r\n\r\n\r\n    Procedure Mean Sample SD    Lower    Upper\r\n1      Bypass   19    539 10 18.29151 19.70849\r\n2 Angiography   18    847  9 17.49134 18.50866\r\n\r\nFinally, I created a plot to visualize the results. The visualization communicates that for each procedure, there is a range of values where we can expect 90% of the estimates to include the population mean given the sample mean and standard deviation.\r\n\r\n\r\nShow code\r\n\r\ngg1 <- ggplot(data = df1)\r\ngg1 <- gg1 + geom_point(aes(x = Procedure, y = Mean), size = 5, color = \"blue\")\r\ngg1 <- gg1 + geom_errorbar(aes(x = Procedure, y = Mean, ymin=Lower, ymax=Upper), width=.1, color = \"blue\")\r\ngg1 <- gg1 + geom_text(aes(x = Procedure, y = Lower, label = round(Lower, 2)), hjust = -1)\r\ngg1 <- gg1 + geom_text(aes(x = Procedure, y = Upper, label = round(Upper, 2)), hjust = -1)\r\ngg1 <- gg1 + geom_text(aes(x = Procedure, y = Mean, label = round(Mean, 2)), hjust = -0.5)\r\ngg1 <- gg1 + labs(x = \"Procedure\", y = \"Mean\")\r\ngg1 <- gg1 + labs(title = \"Chart Showing Mean With Upper and Lower Confidence Intervals at 90%\")\r\ngg1 <- gg1 + theme_classic()\r\n\r\ngg1\r\n\r\n\r\n\r\n\r\nFor the angiography, we can be 90% sure that the population mean for the wait time to the procedure falls between 17.49 and 18.51 days.\r\nFor the bypass, we can be 90% sure that the population mean for the wait time to the procedure falls between 18.29 and 19.71 days.\r\nThe confidence interval was narrower for the angiography surgery.\r\nQuestion 2\r\nA survey of 1031 adult Americans was carried out by the National Center for Public Policy. Assume that the sample is representative of adult Americans. Among those surveyed, 567 believed that college education is essential for success.\r\nFind the point estimate, p, of the proportion of all adult Americans who believe that a college education is essential for success.\r\nConstruct and interpret a 95% confidence interval for p.\r\nAnswer 2\r\nTo construct the 95% confidence interval, I began by calculating the point sample estimate of the population proportion:\r\n\r\n\r\n#Calculate the point sample estimate of the population proportion using (p = x/n)\r\n\r\nx2 = 567 #affirmative response size\r\nn2 = 1031 #sample size - survey participants\r\n\r\np2 <- x2/n2\r\np2\r\n\r\n\r\n[1] 0.5499515\r\n\r\nThis tells me that the sample proportion of those who believe a college education is essential for success is ~45%.\r\nSince np >= 5 and n(1-p) >= 5, I know that I will calculate the confidence interval of that population proportion as follows: p +/- z * square root of (p) x (1-p)/n\r\n\r\n\r\n#Calculate the confidence interval for p:\r\n\r\nerror2 <-qnorm(0.975)*sqrt(p2*(1-p2)/n2)\r\nerror2\r\n\r\n\r\n[1] 0.03036761\r\n\r\nlower2 <- p2-error2\r\nupper2 <- p2+error2\r\n\r\nlower2\r\n\r\n\r\n[1] 0.5195839\r\n\r\nupper2\r\n\r\n\r\n[1] 0.5803191\r\n\r\nThis tells me that we can be 95% confident that the proportion of adult Americans who believe that a college education is essential for success lies between 51.96% and 58.03% of the population.\r\nAlternatively, using the R prop.test function, I can compare the calculation to my manual calculation and find it is the same for finding the point, but slightly different (at 4 decimal points) on the calculation of the confidence interval.\r\n\r\n\r\nprop.test(x2, n2)\r\n\r\n\r\n\r\n    1-sample proportions test with continuity correction\r\n\r\ndata:  x2 out of n2, null probability 0.5\r\nX-squared = 10.091, df = 1, p-value = 0.00149\r\nalternative hypothesis: true p is not equal to 0.5\r\n95 percent confidence interval:\r\n 0.5189682 0.5805580\r\nsample estimates:\r\n        p \r\n0.5499515 \r\n\r\nQuestion 3\r\nSuppose that the financial aid office of UMass Amherst seeks to estimate the mean cost of textbooks per quarter for students. The estimate will be useful if it is within $5 of the true population mean (i.e. they want the confidence interval to have a length of $10 or less). The financial aid office is pretty sure that the amount spent on books varies widely, with most values between $30 and $200. They think that the population standard deviation is about a quarter of this range.\r\nAssuming the significance level to be 5%, what should be the size of the sample?\r\nAnswer 3\r\nI will start by taking the information given and calculating the variables I need to know.\r\nIf the aid office believes the amount spent on books is between $30 and $200, I have a range of $170 to consider.\r\nI want to be 95% confident that the interval estimate contains the population mean, so my z = 1.96.\r\nI also know that the margin of error should be no more than +/- $5 on each end of the estimate, so my margin of error = 5\r\n\r\n\r\nerror3 <- (5)\r\n\r\n#I need to calculate the standard deviation at the given estimate that it is a quarter of the range:\r\n\r\nsd3 <- 170*0.25 #range * 25%\r\nsd3 #standard deviation = 42.5\r\n\r\n\r\n[1] 42.5\r\n\r\n#Now I can calculate the sample size with the formula n=(zσ/M)2.\r\n\r\nss3 <- ((1.96*sd3)/error3)^2\r\nss3 #sample size\r\n\r\n\r\n[1] 277.5556\r\n\r\nUsing these calculations, I can estimate that the financial aid office will need to use a sample size of 278 people.\r\nQuestion 4\r\nAccording to a union agreement, the mean income for all senior-level workers in a large service company equals $500 per week. A representative of a women’s group decides to analyze whether the mean income μ for female employees matches this norm. For a random sample of nine female employees, ȳ = $410 and s = 90.\r\nA. Test whether the mean income of female employees differs from $500 per week. Include assumptions, hypotheses, test statistic, and P-value. Interpret the result.\r\nB. Report the P-value for Ha : μ < 500. Interpret.\r\nC. Report and interpret the P-value for H a: μ > 500.\r\n(Hint: The P-values for the two possible one-sided tests must sum to 1.)\r\nAnswer 4\r\nA. I will start by taking the information given and determining my hypotheses:\r\nH0: The mean weekly earnings for the population of women at the company is μ=$500#\r\nHa: The mean weekly earnings for the population of women at the company is μ≠$500\r\nI cannot assume that the population distribution is normal as I have a low sample size of 9 and it is not stated it is a random sample, but a representative sample.\r\nMy other assumptions are:\r\npopulation mean (mu4) = 500\r\nsample size (n4) = 9\r\nsample mean (xbar4) = 410\r\nsample standard deviation (sd4) = 90\r\nI also need to make a decision about using a significance level of 5%.\r\nI will use the test statistic formula to find the t-value: [t = (x̄) - (μ) / (sd/sqrt(n)]\r\n\r\n\r\na4 <- 500\r\nn4 <- 9\r\nxbar4 <- 410\r\nsd4 <- 90\r\n\r\n#Test statistic:\r\n\r\nt4 <-(xbar4-a4)/(sd4/sqrt(n4))\r\n\r\nt4\r\n\r\n\r\n[1] -3\r\n\r\nGiven that my test statistic = (-3), I can determine the p-value is .00135*2 (to get the sum of both tail probabilities) or 0.0027.\r\nSince my confidence level is 0.05 and my p-value of 0.0027 < 0.05, I can reject the null hypothesis that the mean weekly earnings for the population of women at the company is μ=$500.\r\n\r\n\r\n#Then I take the t-statistic result (-3) and the degrees of freedom by taking \"sample size - 1\" or (\"9\" - 1) = 8.\r\n\r\npval4a <- pt(-3, 8)\r\n\r\npval4a\r\n\r\n\r\n[1] 0.008535841\r\n\r\nB. For the alternative hypothesis Ha: μ < 500:\r\n\r\n\r\npval4b <- pt(-3, 8, lower.tail=FALSE)\r\n\r\npval4b\r\n\r\n\r\n[1] 0.9914642\r\n\r\nPer the hint, I can confirm that these are logical answers by adding the two probabilities together and confirming they equal 1:\r\n\r\n\r\npval4a+pval4b\r\n\r\n\r\n[1] 1\r\n\r\nQuestion 5\r\nJones and Smith separately conduct studies to test H0: μ = 500 against Ha : μ ≠ 500, each with n = 1000.\r\nJones gets ȳ = 519.5, with se = 10.0. Smith gets ȳ = 519.7.\r\nA. Show that t = 1.95 and P-value = 0.051 for Jones. Show that t = 1.97 and P-value = 0.049 for Smith.\r\nB. Using α = 0.05, for each study indicate whether the result is “statistically significant.”\r\nC. Using this example, explain the misleading aspects of reporting the result of a test as “P ≤ 0.05” versus “P > 0.05,” or as “reject H0” versus “Do not reject H0 ,” without reporting the actual P-value.\r\nAnswer 5\r\nA. To show the t-scores, I will use the test statistic [t = (ybar) - (μ) / (se)] given the results for each:\r\n\r\n\r\n#Test statistic for Jones:\r\n\r\nybar5a <- 519.5\r\nn5 <- 1000\r\na5 <- 500\r\nse5 <- 10.0\r\n\r\nt5a <-(ybar5a-a5)/(se5)\r\n\r\nt5a\r\n\r\n\r\n[1] 1.95\r\n\r\n#Test statistic for Smith:\r\n\r\nybar5b <- 519.7\r\nn5 <- 1000\r\na5 <- 500\r\nse5 <- 10.0\r\n\r\nt5b <-(ybar5b-a5)/(se5)\r\n\r\nt5b\r\n\r\n\r\n[1] 1.97\r\n\r\nTo show the p-values, I will use the pt() function and use the t-statistic results from each of the tests and the degrees of freedom by taking “sample size - 1” or (“100” - 1) = 999. I will need to multiply each result by 2 to account for the probabilities in each tail of the normal distribution.\r\n\r\n\r\n#For Jones' results:\r\n\r\npval5a <- pt(1.95, 999, lower.tail = FALSE) * 2\r\n\r\npval5a\r\n\r\n\r\n[1] 0.05145555\r\n\r\n#For Smith's results:\r\n\r\npval5b <- pt(1.97, 999, lower.tail = FALSE) * 2\r\n\r\npval5b\r\n\r\n\r\n[1] 0.04911426\r\n\r\nB. To use α = 0.05 and look at each result and whether it is “statistically significant”, I can compare the p-values directly to the confidence level of 0.5. Jones’ results gave a p-value of 0.5145, which is just over the threshold of the confidence level given of 0.5. Smith’s results gave a p-value of 0.4911, which is just under the threshold of the confidence level given of 0.5.\r\nHypothesis tests tell us that if the p-value < α, we reject H0 and if p-value ≥ α, we do not reject H0. Given this general statistical guidance, only Smith’s results would be considered “statistically significant”.\r\nC. The results in this example could be very misleading if only whether the results were reported as simply “rejecting” or “not rejecting” H0 or being “statistically significant” or not because that is leaving out vital information on how close the results were to the confidence level used. If the actual p-values were reported instead, they would reflect how marginally “significant” the results really were. The confidence is an artificial threshold that is subjectively applied, and in this case, the results were close enough that they should not be statistically reported as significally different. This is why we need to be sure we report the full p-values and confidence intervals.\r\nQuestion 6\r\nAre the taxes on gasoline very high in the United States? According to the American Petroleum Institute, the per gallon federal tax that was levied on gasoline was 18.4 cents per gallon. However, state and local taxes vary over the same period. The sample data of gasoline taxes for 18 large cities is given below in the variable called gas_taxes.\r\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\r\nIs there enough evidence to conclude at a 95% confidence level that the average tax per gallon of gas in the US in 2005 was less than 45 cents? Explain.\r\nAnswer\r\nTo answer whether there is enough evidence to conclude at a 95% confidence level that the average tax per gallon of gas in the US in 2005 was less than 45 cents, we need to use a left-tailed t-test. We will use the sample data in the variable “gas_taxes” in the t.test function. We know that the t.test() function uses the 95% confidence interval as a default, but it also uses a two-sided test as the default, so we need to provide the alternative argument “less”, indicating a left-sided test.\r\n\r\n\r\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\r\n\r\nt.test(gas_taxes, alternative = \"less\")\r\n\r\n\r\n\r\n    One Sample t-test\r\n\r\ndata:  gas_taxes\r\nt = 18.625, df = 17, p-value = 1\r\nalternative hypothesis: true mean is less than 0\r\n95 percent confidence interval:\r\n     -Inf 44.67946\r\nsample estimates:\r\nmean of x \r\n 40.86278 \r\n\r\nThis t-test gives us a confidence interval of [inf - 44.67946]. Since the confidence interval includes amounts that are all less than 45 cents, we have enough evidence to conclude that, at that confidence level, the average tax was less than 45 cents.\r\n\r\n\r\n\r\n",
    "preview": "posts/httpsrpubscomkbec864954/distill-preview.png",
    "last_modified": "2022-02-24T15:25:24-05:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/httpsrpubscomowenvespa865400/",
    "title": "Statistical Inference II & Comparing two means",
    "description": "DACSS 603 Homework 1",
    "author": [
      {
        "name": "Rhowena Vespa",
        "url": {}
      }
    ],
    "date": "2022-02-24",
    "categories": [],
    "contents": "\r\nQuestion 1\r\nThe time between the date a patient was recommended for heart surgery and the surgery date for cardiac patients in Ontario was collected by the Cardiac Care Network (“Wait Times Data Guide,” Ministry of Health and Long-Term Care, Ontario, Canada, 2006). The sample mean and sample standard deviation for wait times (in days) of patients for two cardiac procedures are given in the accompanying table. Assume that the sample is representative of the Ontario population\r\n\r\n\r\nlibrary(distill)\r\nlibrary(dplyr)\r\nlibrary(tidyverse)\r\nProblem1<- read.csv('homework1_prob1.csv',TRUE,',',na.strings = \"N/A\")\r\nProblem1\r\n\r\n\r\n  ï..Surgical.Procedure Sample.Size Mean.Wait.Time Standard.Deviation\r\n1                Bypass         539             19                 10\r\n2           Angiography         847             18                  9\r\n\r\nConstruct the 90% confidence interval to estimate the actual mean wait time for each of the two procedures. Is the confidence interval narrower for angiography or bypass surgery?\r\nFor Bypass group:\r\n\r\n\r\n#Our values are: \r\nBypass.mean<- 19\r\nBypass.sd<-10\r\nBypass.n<-539\r\nBypass.se <- Bypass.sd/sqrt(Bypass.n) #This is standard error of the mean\r\n\r\n\r\n\r\n\r\n\r\n#Find the t.score for CI 90%\r\nalpha = 0.1\r\ndegrees.freedom = Bypass.n - 1\r\nBypass.t.score = qt(p=alpha/2, df=degrees.freedom,lower.tail=F)\r\nprint(Bypass.t.score)\r\n\r\n\r\n[1] 1.647691\r\n\r\n\r\n\r\n#Calculate margin of error\r\nBypass.margin.error <- Bypass.t.score * Bypass.se\r\nprint(Bypass.margin.error)\r\n\r\n\r\n[1] 0.7097107\r\n\r\n\r\n\r\n#Calculate the 90% confidence interval for Bypass\r\n  lower.bound <- Bypass.mean - Bypass.margin.error\r\n  upper.bound <- Bypass.mean + Bypass.margin.error\r\n  print(c(lower.bound,upper.bound))\r\n\r\n\r\n[1] 18.29029 19.70971\r\n\r\nFor Angiography group:\r\n\r\n\r\n#Our values are: \r\nAngio.mean<- 18\r\nAngio.sd<-9\r\nAngio.n<-847\r\nAngio.se <- Angio.sd/sqrt(Angio.n) #This is standard error of the mean\r\n\r\n\r\n\r\n\r\n\r\n#Find the t.score for CI 90%\r\nalpha = 0.1\r\ndegrees.freedomA = Angio.n - 1\r\nAngio.t.score = qt(p=alpha/2, df=degrees.freedomA,lower.tail=F)\r\nprint(Angio.t.score)\r\n\r\n\r\n[1] 1.646657\r\n\r\n\r\n\r\n#Calculate margin of error\r\nAngio.margin.error <- Angio.t.score * Angio.se\r\nprint(Angio.margin.error)\r\n\r\n\r\n[1] 0.5092182\r\n\r\n\r\n\r\n#Calculate the 90% confidence interval for Angiography\r\n  lower.boundA <- Angio.mean - Angio.margin.error\r\n  upper.boundA <- Angio.mean + Angio.margin.error\r\n  print(c(lower.boundA,upper.boundA))\r\n\r\n\r\n[1] 17.49078 18.50922\r\n\r\nAnswer for Question #1-Is the confidence interval narrower for angiography or bypass surgery?:\r\nAngiography patients, at 90% confidence interval, had between (17.49078 and 18.50922) wait time in days which is NARROWER compared to the bypass patients wait time which is between (18.29029 and 19.70971)\r\nQuestion 2\r\nA survey of 1031 adult Americans was carried out by the National Center for Public Policy. Assume that the sample is representative of adult Americans. Among those surveyed, 567 believed that college education is essential for success. Find the point estimate, p, of the proportion of all adult Americans who believe that a college education is essential for success. Construct and interpret a 95% confidence interval for p.\r\n\r\n\r\n#Point Estimate, p\r\nn<-1031\r\nk<-567\r\np<-k/n\r\np\r\n\r\n\r\n[1] 0.5499515\r\n\r\nInterpretation of point estimate p:\r\nThe sample proportion of adult Americans who believed that college education is essential for success is 0.5499515 or 55%. This represents our point estimate for the population (adult Americans) proportion.\r\n\r\n\r\n#Construct 95% confidence interval for p\r\n\r\nS.margin <- qnorm(0.975)*sqrt(p*(1-p)/n)  #calculate margin of error\r\n  S.lower.bound <- p-S.margin\r\n  S.upper.bound <- p+S.margin\r\n  print(c(S.lower.bound,S.upper.bound))\r\n\r\n\r\n[1] 0.5195839 0.5803191\r\n\r\nInterpretation of 95% confidence interval for p:\r\nThe 95% confidence interval for the population (adult Americans) proportion is [0.5195839 0.5803191]. This means between 51.9% to 58% of adult Americans believed that college education is essential for success.\r\nQuestion 3\r\nSuppose that the financial aid office of UMass Amherst seeks to estimate the mean cost of textbooks per quarter for students. The estimate will be useful if it is within $5 of the true population mean (i.e. they want the confidence interval to have a length of $10 or less). The financial aid office is pretty sure that the amount spent on books varies widely, with most values between $30 and $200. They think that the population standard deviation is about a quarter of this range. Assuming the significance level to be 5%, what should be the size of the sample?\r\nn= square of ((Z 0.05/2 * sd of pop)/within $5 of true pop mean\r\n\r\n\r\nsd_of_pop =(200-30)/4 #This is standard deviation of population\r\nsd_of_pop\r\n\r\n\r\n[1] 42.5\r\n\r\nsample_size=((1.96*sd_of_pop)/5)**2  #Using Z score 1.96 for significance level 5%\r\nsample_size\r\n\r\n\r\n[1] 277.5556\r\n\r\nANSWER: Sample size needed to achieve significance level of 95% is 278.\r\nQuestion 4\r\n(Exercise 6.7, Chapter 6 of SMSS, Agresti 2018) According to a union agreement, the mean income for all senior-level workers in a large service company equals $500 per week. A representative of a women’s group decides to analyze whether the mean income μ for female employees matches this norm. For a random sample of nine female employees, ȳ = $410 and s = 90.\r\nTest whether the mean income of female employees differs from $500 per week. Include assumptions, hypotheses, test statistic, and P-value. Interpret the result.\r\nassumption: seed set at 123, using rnorm\r\nHo mu=500\r\nHa mu≠500\r\nMean y_hat =410\r\nsd = 90\r\nn =9\r\n\r\n\r\nset.seed(123)\r\nMean_income <- c(rnorm(9, mean = 410, sd = 90)) \r\nMean_income\r\n\r\n\r\n[1] 359.5572 389.2840 550.2837 416.3458 421.6359 564.3558 451.4825\r\n[8] 296.1445 348.1832\r\n\r\n\r\n\r\nt.test(Mean_income, mu = 500) # Ho: mu=500\r\n\r\n\r\n\r\n    One Sample t-test\r\n\r\ndata:  Mean_income\r\nt = -2.6213, df = 8, p-value = 0.03059\r\nalternative hypothesis: true mean is not equal to 500\r\n95 percent confidence interval:\r\n 353.2313 490.6071\r\nsample estimates:\r\nmean of x \r\n 421.9192 \r\n\r\nInterpretation of one sample t-test result:\r\nAt p-value 0.03, considered statistically significant, we reject the null hypothesis. We can conclude that mean income for female employees is not 500.\r\nReport the P-value for Ha : μ < 500. Interpret.\r\n\r\n\r\nt.test(Mean_income, mu=500, alternative = 'less') # Ha: mu<500\r\n\r\n\r\n\r\n    One Sample t-test\r\n\r\ndata:  Mean_income\r\nt = -2.6213, df = 8, p-value = 0.01529\r\nalternative hypothesis: true mean is less than 500\r\n95 percent confidence interval:\r\n     -Inf 477.3087\r\nsample estimates:\r\nmean of x \r\n 421.9192 \r\n\r\nInterpretation of Ha : μ < 500:\r\nAt p-value 0.01529, considered statistically significant, we reject the null hypothesis and accept the alternative hypothesis. We can conclude that mean income for female employees is less than 500.\r\nReport and interpret the P-value for Ha: μ > 500.\r\n\r\n\r\nt.test(Mean_income, mu=500, alternative = \"greater\") # Ha: mu>500\r\n\r\n\r\n\r\n    One Sample t-test\r\n\r\ndata:  Mean_income\r\nt = -2.6213, df = 8, p-value = 0.9847\r\nalternative hypothesis: true mean is greater than 500\r\n95 percent confidence interval:\r\n 366.5297      Inf\r\nsample estimates:\r\nmean of x \r\n 421.9192 \r\n\r\nInterpretation of Ha: μ > 500:\r\nAt p-value 0.9847, considered statistically NOT significant, we fail to reject the null hypothesis. We can reject the alternative hypothesis that mean income for female employees is greater than 500.\r\n(Hint: The P-values for the two possible one-sided tests must sum to 1.)\r\n\r\n\r\ntotal_p_value=0.9847+0.01529\r\nprint(c(\"Total p-values for the two possible one-sided tests is\",total_p_value))\r\n\r\n\r\n[1] \"Total p-values for the two possible one-sided tests is\"\r\n[2] \"0.99999\"                                               \r\n\r\nQuestion 5\r\n(Exercise 6.23, Chapter 6 of SMSS, Agresti 2018) Jones and Smith separately conduct studies to test H0: μ = 500 against Ha : μ ≠ 500, each with n = 1000. Jones gets ȳ = 519.5, with se = 10.0. Smith gets ȳ = 519.7, with se = 10.0.\r\n\r\n\r\ntab <- matrix(c(519.5, 519.7, 10, 10), ncol=2, byrow=TRUE)\r\ncolnames(tab) <- c(\"Jones\",\"Smith\")\r\nrownames(tab) <- c(\"y_hat\",\"se\")\r\ntab <- as.table(tab)\r\nprint(tab)\r\n\r\n\r\n      Jones Smith\r\ny_hat 519.5 519.7\r\nse     10.0  10.0\r\n\r\nCalculate t and p-value\r\nt.stat <- (y_hat - mu)/sample.se\r\np.value = pt(q=abs(t.stat), df=degrees.freedom,lower.tail=F) 2 *\r\nShow that t = 1.95 and P-value = 0.051 for Jones.\r\n\r\n\r\nt.stat <- (519.5 - 500)/10\r\nprint(c(\"t.stat\",t.stat))\r\n\r\n\r\n[1] \"t.stat\" \"1.95\"  \r\n\r\n\r\n\r\ndegrees.freedom = 1000 - 1\r\np.value = pt(q=abs(t.stat), df=degrees.freedom,lower.tail=F) * 2\r\nprint(c(\"Two-sided p-value\",p.value))\r\n\r\n\r\n[1] \"Two-sided p-value\"  \"0.0514555476459477\"\r\n\r\nShow that t = 1.97 and P-value = 0.049 for Smith.\r\n\r\n\r\nSmith.t.stat <- (519.7 - 500)/10\r\nprint(c(\"t.stat\",Smith.t.stat))\r\n\r\n\r\n[1] \"t.stat\" \"1.97\"  \r\n\r\n\r\n\r\ndegrees.freedom = 1000 - 1\r\nSmith.p.value = pt(q=abs(Smith.t.stat), df=degrees.freedom,lower.tail=F) * 2\r\nprint(c(\"Two-sided p-value\",Smith.p.value))\r\n\r\n\r\n[1] \"Two-sided p-value\"  \"0.0491142565416521\"\r\n\r\nUsing α = 0.05, for each study indicate whether the result is “statistically significant.”\r\n  α = 0.05\r\n  H0: μ = 500\r\n  Ha : μ ≠ 500\r\n  \r\nFor Jones Data: Since p=0.051, we fail to reject the null hypothesis (H0: μ = 500) and reject the alternative hypothesis (Ha : μ ≠ 500). The p-value is NOT statistically significant.\r\nFor Smith Data: Since p=0.049, we reject the null hypothesis (H0: μ = 500) and accept the alternative hypothesis. We conclude that μ ≠ 500. P-value is statistically significant.\r\nUsing this example, explain the misleading aspects of reporting the result of a test as “P ≤ 0.05” versus “P > 0.05,” or as “reject H0” versus “Do not reject H0 ,” without reporting the actual P-value.\r\n\r\n\r\nprint(tab)\r\n\r\n\r\n      Jones Smith\r\ny_hat 519.5 519.7\r\nse     10.0  10.0\r\n\r\n#α = 0.05\r\n#H0: μ = 500\r\n#Ha : μ ≠ 500\r\n#Zc= 1.96\r\n\r\n\r\n\r\nCalculate z-score= (y_hat -μ )/ se\r\n\r\n\r\nJones.z <- (519.5-500)/10\r\nJones.z\r\n\r\n\r\n[1] 1.95\r\n\r\n\r\n\r\nSmith.z <- (519.7-500)/10\r\nSmith.z\r\n\r\n\r\n[1] 1.97\r\n\r\nInterpretation without reporting the actual P-value:\r\nReporting the result of a test using p-values could be misleading. We can avoid this by using z-score to report the results, using z-score =1.96 as the same 95% confidence level. Jones z-score of 1.95 < 1.96 means we fail to reject the null hypothesis (H0: μ = 500) and reject the alternative hypothesis (Ha : μ ≠ 500). Smith z-score of 1.97 > 1.96 we reject the null hypothesis (H0: μ = 500) and accept the alternative hypothesis(Ha : μ ≠ 500).\r\nQuestion 6\r\nAre the taxes on gasoline very high in the United States? According to the American Petroleum Institute, the per gallon federal tax that was levied on gasoline was 18.4 cents per gallon. However, state and local taxes vary over the same period. The sample data of gasoline taxes for 18 large cities is given below in the variable called gas_taxes.\r\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\r\nIs there enough evidence to conclude at a 95% confidence level that the average tax per gallon of gas in the US in 2005 was less than 45 cents? Explain.\r\n#H0: μ = 45\r\n#Ha : μ ≠ 45, specifically μ < 45 assuming one-sided using argument alternative= \"lesser\"\r\n\r\n\r\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\r\nt.test(gas_taxes,mu=45, alternative = 'less')\r\n\r\n\r\n\r\n    One Sample t-test\r\n\r\ndata:  gas_taxes\r\nt = -1.8857, df = 17, p-value = 0.03827\r\nalternative hypothesis: true mean is less than 45\r\n95 percent confidence interval:\r\n     -Inf 44.67946\r\nsample estimates:\r\nmean of x \r\n 40.86278 \r\n\r\nInterpretation of one sample t-test:\r\nYes, there is enough evidence to conclude at a 95% confidence level that the average tax per gallon of gas in the US in 2005 was less than 45 cents. With the p-value of 0.03827 < α = 0.05, we reject the null hypothesis that μ = 45 and accept the alternative hypothesis that μ < 45 cents.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-02-24T15:25:10-05:00",
    "input_file": {}
  },
  {
    "path": "posts/httpsrpubscomrhyslong96870303/",
    "title": "Homework 1",
    "description": "Here is my submission for homework 1.",
    "author": [
      {
        "name": "Rhys Long",
        "url": {}
      }
    ],
    "date": "2022-02-24",
    "categories": [],
    "contents": "\n\n\n##QUESTION 1##\n#Sample Size\nAngiography_Sample=847\nBypass_Sample=539\n\n#Mean\nAngiography_Mean=18\nBypass_Mean=19\n\n#Standard Deviation\nAngiography_STD=9\nBypass_STD=10\n\n#Standard Error\nAngiography_SE=Angiography_STD/sqrt(Angiography_Sample)\nBypass_SE=Bypass_STD/sqrt(Bypass_Sample)\n\n#Tail Area\nConfidence_Level=0.9\nTail_Area=(1-Confidence_Level)/2\n\n#T Scores\nAngiography_T=qt(p=0.95,df=(Angiography_Sample-1))\nBypass_T=qt(p=0.95,df=(Bypass_DF=Bypass_Sample-1))\n\n#Margin Of Error\nAngiography_MOE=Angiography_T*Angiography_SE\nBypass_MOE=Bypass_T*Bypass_SE\n\n#Angiography Confidence Interval\nLower_Angiography=Angiography_Mean-Angiography_MOE\nUpper_Angiography=Angiography_Mean+Angiography_MOE\nAngiography_CI=c(Lower_Angiography, Upper_Angiography)\nc(\"Angiography Confidence Interval:\", Angiography_CI)\n\n\n[1] \"Angiography Confidence Interval:\"\n[2] \"17.4907818376895\"                \n[3] \"18.5092181623105\"                \n\n#Bypass Confidence Interval\nLower_Bypass=Bypass_Mean-Bypass_MOE\nUpper_Bypass=Bypass_Mean+Bypass_MOE\nBypass_CI=c(Lower_Bypass, Upper_Bypass)\nc(\"Bypass Confidence Interval:\", Bypass_CI)\n\n\n[1] \"Bypass Confidence Interval:\" \"18.2902893200424\"           \n[3] \"19.7097106799576\"           \n\n#Comparing The Confidence Interval Widths\nAngiography_Width=Upper_Angiography-Lower_Angiography\nBypass_Width=Upper_Bypass-Lower_Bypass\nc(\"Angiography Confidence Interval Width:\", Angiography_Width)\n\n\n[1] \"Angiography Confidence Interval Width:\"\n[2] \"1.01843632462099\"                      \n\nc(\"Bypass Confidence Interval Width:\", Bypass_Width)\n\n\n[1] \"Bypass Confidence Interval Width:\"\n[2] \"1.41942135991513\"                 \n\nThe actual mean wait for angiographies is around 17.4907818376895 to 18.5092181623105 days and the actual mean wait for bypasses is 18.2902893200424 to 19.7097106799576. To find out the confidence interval for both procedures, I first found the standard error, since I already knew the sample sizes and standard deviations. From there I determined the t scores for both procedures. Even though the samples for both procedures exceeded 30, I used a t score instead of a z score because the sample standard deviations were different and the population standard deviation was unspecified. In order to figure out the correct t score, I used qt() with p set to 0.95 because each tail has an area of 0.05 when the confidence level is 90%. Once I had the t scores, I determined the margin of error and confidence intervals. To figure out which procedure has the narrower confidence interval, I subtracted the upper bound value by the lower bound value for each respective procedure. The angiography has a narrower confidence interval than the bypass.\n\n\n##QUESTION 2##\n#Sample Size\nSample=1031\n\n#Pro-College vs Anti-College Proportions\nPro_College=567/Sample\nAnti_College=1-Pro_College\n\n#Z Score, Standard Error, And Margin Of Error\nZ=1.96\nSE=sqrt((Pro_College*Anti_College)/Sample)\nMOE=Z*SE\n\n#Confidence Interval\nLower_Bound=Pro_College-MOE\nUpper_Bound=Pro_College+MOE\nConfidence_Interval <- c(Lower_Bound,Upper_Bound)\nConfidence_Interval \n\n\n[1] 0.5195833 0.5803197\n\nThe 95% confidence interval for p is 51.95833-58.03197%. Based on the fact that 567/1031 adults in the survey believed that college education is essential for success, I was able to conclude that 464/1031 adults in the survey disagreed with that mindset. From there, I used sqrt((Pro College Proportion*Anti College Proportion)/Sample Size) to find the standard error since I don’t need a standard deviation to find the standard error of a proportion. Next, I multiplied the standard error by 1.96, otherwise known as the 95% confidence level z score, to find the margin of error. The reason why I used a z score instead of a t score is because the instructions specify that I should assume that the results are reflective of the entire population. Finally, I subtracted the margin of error from the pro-college proportion to find the lower bound confidence interval limit and I added the margin of error to the pro-college proportion to find the upper bound confidence interval limit.\n\n\n##QUESTION 3##\n#Determining Standard Deviation\nRange=200-30\nSTD=Range/4\nSTD\n\n\n[1] 42.5\n\n#Determnining Margin Of Error And Z Score\nM=5\nZ=1.96\n\n#Determnining Sample Size\nZ_Div_M=Z/M\nSize=(STD*STD)*(Z_Div_M*Z_Div_M)\nSize\n\n\n[1] 277.5556\n\n#Checking Work\nM_Check=Z*(STD/sqrt(278))\nM_Check\n\n\n[1] 4.996002\n\nThe ideal sample size for an experiment with the specifications of question 3 is at least 278. Before figuring out the ideal sample size, I had to find the standard deviation and the margin of error. Based on the question 3 instructions, I could conclude that the standard deviation is 42.5 the spending range is 170 (200-30) and the population standard deviation is the spending range divided by 4. I could also conclude that the margin of error is 5 because the confidence interval length should be 10 dollars or less and the margin of error is half the confidence interval length. In order to determine the ideal sample size, I first divided the margin of error by 1.96, otherwise known as the 5% significance level z score. I used a z score instead of a t score because the population standard deviation is known. From there, I multiplied the standard deviation squared by (Margin of Error/Z Score) squared and got 277.5556, which can be rounded up to 278. To check my work, I used the M=Z*(STD/sqrt(N)).\n\n\n##QUESTION 4##\n#Mean And Standard Deviation\nPopulation_Mean=500\nWomen=9\nWoman_Mean=410\nSTD=90\nSE=STD/sqrt(Women)\n\n#T-Score\nT_Score=(Woman_Mean-Population_Mean)/SE\nT_Score\n\n\n[1] -3\n\n#A: Find Two Tail P Value\nTwo_Tail_P=2*pt(q=T_Score,df=(Women-1))\nTwo_Tail_P\n\n\n[1] 0.01707168\n\n#B: Left Tail P Value\nLeft_Tail_P=pt(q=T_Score,df=(Women-1),lower.tail=TRUE)\nLeft_Tail_P\n\n\n[1] 0.008535841\n\n#C: Right Tail P Value\nRight_Tail_P=pt(q=T_Score,df=(Women-1),lower.tail=FALSE)\nRight_Tail_P\n\n\n[1] 0.9914642\n\nFor question 4 part A, I concluded that there is a statistically significant difference between the income of women and the mean income. The null hypothesis is that the income of women is equal to that of everyone else. The alternative hypothesis is that hypothesis is that the income of women isn’t equal to that of everyone else. In order to figure out whether there is a statistically significant difference, I had to figure out the T-Score. The T-Score I got from dividing the difference between the women’s mean and the population mean by the standard error is -3. Even though I know that a T-Score of -3 is probably reflective of statistically significant differences, I still determined the two tailed p value by using 2*pt(q=T_Score,df=(Women-1)). I multiplied pt(q=T_Score,df=(Women-1)) by 2 because the pt() function is used for determining 1 tail p values and I was interested in finding the 2 tail p value. The p value I got was p=0.01707168, which is considered statistically significant when using the p<0.05 significance level. To find the left tail P value, I used pt(q=T_Score,df=(Amount of Women-1),lower.tail=TRUE) and I got p=0.008535841, which supports the alternative hypothesis of mu<500 to a highly significant extent. To find the right tail P value, I used Right_Tail_P=pt(q=T_Score,df=(Women-1),lower.tail=FALSE) and I got 0.9914642, which is indicative of mu>500 being false.\n\n\n##QUESTION 5##\n#Null Mean And Sample Size\nNull_Mean=500\nN=1000\n\n#Jones Mean And Standard Error\nJones_Mean=519.5\nJones_SE=10.0\n\n#Jones T\nJones_T=(Jones_Mean-Null_Mean)/Jones_SE\nJones_T\n\n\n[1] 1.95\n\n#Jones P\nJones_P=2*pt(q=Jones_T,df=(N-1),lower.tail=FALSE)\nJones_P\n\n\n[1] 0.05145555\n\n#Smith Mean And Standard Error\nSmith_Mean=519.7\nSmith_SE=10.0\n\n#Smith T\nSmith_T=(Smith_Mean-Null_Mean)/Jones_SE\nSmith_T\n\n\n[1] 1.97\n\n#Smith P\nSmith_P=2*pt(q=Smith_T,df=(N-1),lower.tail=FALSE)\nSmith_P\n\n\n[1] 0.04911426\n\nAccording to alpha=0.05, Smith’s results are statistically significant, but Jones’s results are not. The reason why neglecting to report the p value is so misleading when reporting results is because there is no indication of how close the results are to being statistically significant. Jones’s p value of 0.05145555 comes extremely close to being statistically significant when the significance level is set to p<=0.05 and if the significance level was set to p<=0.1, Jones’s results would undoubtedly be classified as statistically significant. If I say Jones’s results are not statistically significant with p<=0.05 and that I can’t reject the null hypothesis, nobody will know that Jones’s results come extremely close to being statistically significance and that could lead to type 2 errors.\n\n\n##QUESTION 6##\n#Dataset\ngas_taxes <- c(51.27, 47.43, 38.89, 41.95, 28.61, 41.29, 52.19, 49.48, 35.02, 48.13, 39.28, 54.41, 41.66, 30.28, 18.49, 38.72, 33.41, 45.02)\n#T-Test\nt.test(gas_taxes, mu=45, alternative=\"less\")\n\n\n\n    One Sample t-test\n\ndata:  gas_taxes\nt = -1.8857, df = 17, p-value = 0.03827\nalternative hypothesis: true mean is less than 45\n95 percent confidence interval:\n     -Inf 44.67946\nsample estimates:\nmean of x \n 40.86278 \n\nEven though the sample size is only 18, there is enough evidence to conclude that the gas prices in 2005 were less than 45 cents with a 95% confidence interval. Given that the data is provided, I was able to use the t test function to figure out the answer. In this context, the null hypothesis is that the average tax per gallon is equal to 45 cents, so I set mu to mu=45. For the alternative= component, I used alternative=“less” because the alternative hypothesis is that the true mean of the gas prices is less than 45 cents. When I ran the t-test, I got a p value of 0.03827, which is considered statistically significant because a 95% confidence interval calls for a p value that is less than or equal to 0.05.\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-24T15:25:35-05:00",
    "input_file": {}
  },
  {
    "path": "posts/welcome/",
    "title": "Welcome to DACSS 601",
    "description": "Welcome to DACSS 603! We hope you enjoy the class!",
    "author": [
      {
        "name": "Omer Yalcin",
        "url": "http://umass.edu/sbs/dacss"
      }
    ],
    "date": "2022-02-24",
    "categories": [
      "welcome"
    ],
    "contents": "\n\n\n\n",
    "preview": {},
    "last_modified": "2022-02-24T15:14:40-05:00",
    "input_file": {}
  }
]
